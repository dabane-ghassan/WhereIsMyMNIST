{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "This notebook introduces the problem addressed in this paper:\n",
      "\n",
      " - localizating an object in a large image\n",
      " - foveation\n",
      " - action (saccade)\n",
      "       \n",
      "      \n",
      "{'w': 28, 'minibatch_size': 100, 'train_batch_size': 50000, 'test_batch_size': 10000, 'noise_batch_size': 1000, 'mean': 0.1307, 'std': 0.3081, 'what_offset_std': 15, 'what_offset_max': 25, 'N_pic': 128, 'offset_std': 30, 'offset_max': 34, 'noise': 0.75, 'contrast': 0.7, 'sf_0': 0.1, 'B_sf': 0.1, 'do_mask': True, 'N_theta': 6, 'N_azimuth': 24, 'N_eccentricity': 10, 'N_phase': 2, 'rho': 1.41, 'bias_deconv': True, 'p_dropout': 0.0, 'dim1': 1000, 'dim2': 1000, 'lr': 0.005, 'do_adam': True, 'bn1_bn_momentum': 0.5, 'bn2_bn_momentum': 0.5, 'momentum': 0.3, 'epochs': 60, 'num_processes': 1, 'no_cuda': False, 'log_interval': 100, 'verbose': 1, 'filename': '../data/2020-07-01', 'seed': 2019, 'N_cv': 10, 'do_compute': True, 'save_model': True}\n",
      "Overwriting train.py\n",
      "2020-06-30T09:51:09+00:00\n",
      "\n",
      "CPython 3.6.9\n",
      "IPython 7.9.0\n",
      "\n",
      "numpy 1.19.0\n",
      "matplotlib 3.1.2\n",
      "torch 1.5.1\n",
      "\n",
      "compiler   : GCC 8.4.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-108-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : inv-ope-de06\n",
      "Git hash   : dcdca09e8930f5d817ad813dd32a8c0fd7bfcad4\n",
      "Git repo   : https://github.com/laurentperrinet/WhereIsMyMNIST\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "%run 0_parameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "figname = '../figures/fig_methods_sup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 28,\n",
       " 'minibatch_size': 100,\n",
       " 'train_batch_size': 50000,\n",
       " 'test_batch_size': 10000,\n",
       " 'noise_batch_size': 1000,\n",
       " 'mean': 0.1307,\n",
       " 'std': 0.3081,\n",
       " 'what_offset_std': 15,\n",
       " 'what_offset_max': 25,\n",
       " 'N_pic': 128,\n",
       " 'offset_std': 30,\n",
       " 'offset_max': 34,\n",
       " 'noise': 0.75,\n",
       " 'contrast': 0.7,\n",
       " 'sf_0': 0.1,\n",
       " 'B_sf': 0.1,\n",
       " 'do_mask': True,\n",
       " 'N_theta': 6,\n",
       " 'N_azimuth': 24,\n",
       " 'N_eccentricity': 10,\n",
       " 'N_phase': 2,\n",
       " 'rho': 1.41,\n",
       " 'bias_deconv': True,\n",
       " 'p_dropout': 0.0,\n",
       " 'dim1': 1000,\n",
       " 'dim2': 1000,\n",
       " 'lr': 0.005,\n",
       " 'do_adam': True,\n",
       " 'bn1_bn_momentum': 0.5,\n",
       " 'bn2_bn_momentum': 0.5,\n",
       " 'momentum': 0.3,\n",
       " 'epochs': 60,\n",
       " 'num_processes': 1,\n",
       " 'no_cuda': False,\n",
       " 'log_interval': 100,\n",
       " 'verbose': 1,\n",
       " 'filename': '../data/2020-07-01',\n",
       " 'seed': 2019,\n",
       " 'N_cv': 10,\n",
       " 'do_compute': True,\n",
       " 'save_model': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the accuracy of the classifier (What) wrt to spatial shifts\n",
    "\n",
    "On commence par la fonction de base apprise de la librairie torch, cf https://raw.githubusercontent.com/pytorch/examples/master/mnist/main.py :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type        Data/Info\n",
      "-------------------------------------\n",
      "args            EasyDict    {'w': 28, 'minibatch_size<...>True, 'save_model': True}\n",
      "code            QRCode      QRCode(content=b'https://<...>version=6, mode='binary')\n",
      "dpi_export      int         600\n",
      "fig_width_pt    int         1024\n",
      "figname         str         ../figures/fig_methods_sup\n",
      "figwidth        float       14.169088141690882\n",
      "inches_per_pt   float       0.013837000138370002\n",
      "init            function    <function init at 0x7f7b8ef36d90>\n",
      "np              module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "os              module      <module 'os' from '/usr/lib/python3.6/os.py'>\n",
      "phi             float64     1.618033988749895\n",
      "plt             module      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "ppi             float       72.27\n",
      "pq              module      <module 'pyqrcode' from '<...>es/pyqrcode/__init__.py'>\n",
      "torch           module      <module 'torch' from '/ho<...>kages/torch/__init__.py'>\n",
      "tqdm            function    <function tqdm_notebook at 0x7f7b8ef36a60>\n",
      "url             str         https://github.com/lauren<...>tperrinet/WhereIsMyMNIST/\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from what import WhatNet\n",
    "model = WhatNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On apprend une matrice de poids qui est fix√©e dans la suite et que nous allons utiliser pour la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:35.317080Z",
     "start_time": "2018-02-16T19:37:35.297625Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"../data/MNIST_cnn.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../data/MNIST_cnn.pt': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "%ls -ltr {model_path}\n",
    "#%rm -f {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:35.317080Z",
     "start_time": "2018-02-16T19:37:35.297625Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning\n",
      "use_cuda True\n",
      "Training the What model\n",
      "Train Epoch: 1/60 [0/60000 (0%)]\tLoss: 2.302170\n",
      "Train Epoch: 1/60 [10000/60000 (17%)]\tLoss: 2.302622\n",
      "Train Epoch: 1/60 [20000/60000 (33%)]\tLoss: 2.297431\n",
      "Train Epoch: 1/60 [30000/60000 (50%)]\tLoss: 2.303493\n",
      "Train Epoch: 1/60 [40000/60000 (67%)]\tLoss: 2.292274\n",
      "Train Epoch: 1/60 [50000/60000 (83%)]\tLoss: 2.302521\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 2/60 [0/60000 (0%)]\tLoss: 2.291935\n",
      "Train Epoch: 2/60 [10000/60000 (17%)]\tLoss: 2.293992\n",
      "Train Epoch: 2/60 [20000/60000 (33%)]\tLoss: 2.296294\n",
      "Train Epoch: 2/60 [30000/60000 (50%)]\tLoss: 2.296739\n",
      "Train Epoch: 2/60 [40000/60000 (67%)]\tLoss: 2.306677\n",
      "Train Epoch: 2/60 [50000/60000 (83%)]\tLoss: 2.305442\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 3/60 [0/60000 (0%)]\tLoss: 2.294444\n",
      "Train Epoch: 3/60 [10000/60000 (17%)]\tLoss: 2.297145\n",
      "Train Epoch: 3/60 [20000/60000 (33%)]\tLoss: 2.302402\n",
      "Train Epoch: 3/60 [30000/60000 (50%)]\tLoss: 2.306619\n",
      "Train Epoch: 3/60 [40000/60000 (67%)]\tLoss: 2.311404\n",
      "Train Epoch: 3/60 [50000/60000 (83%)]\tLoss: 2.299656\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 4/60 [0/60000 (0%)]\tLoss: 2.299441\n",
      "Train Epoch: 4/60 [10000/60000 (17%)]\tLoss: 2.313113\n",
      "Train Epoch: 4/60 [20000/60000 (33%)]\tLoss: 2.296300\n",
      "Train Epoch: 4/60 [30000/60000 (50%)]\tLoss: 2.305544\n",
      "Train Epoch: 4/60 [40000/60000 (67%)]\tLoss: 2.300251\n",
      "Train Epoch: 4/60 [50000/60000 (83%)]\tLoss: 2.301724\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 5/60 [0/60000 (0%)]\tLoss: 2.292831\n",
      "Train Epoch: 5/60 [10000/60000 (17%)]\tLoss: 2.293259\n",
      "Train Epoch: 5/60 [20000/60000 (33%)]\tLoss: 2.301229\n",
      "Train Epoch: 5/60 [30000/60000 (50%)]\tLoss: 2.305738\n",
      "Train Epoch: 5/60 [40000/60000 (67%)]\tLoss: 2.301269\n",
      "Train Epoch: 5/60 [50000/60000 (83%)]\tLoss: 2.291744\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 6/60 [0/60000 (0%)]\tLoss: 2.298245\n",
      "Train Epoch: 6/60 [10000/60000 (17%)]\tLoss: 2.311902\n",
      "Train Epoch: 6/60 [20000/60000 (33%)]\tLoss: 2.306968\n",
      "Train Epoch: 6/60 [30000/60000 (50%)]\tLoss: 2.296989\n",
      "Train Epoch: 6/60 [40000/60000 (67%)]\tLoss: 2.310636\n",
      "Train Epoch: 6/60 [50000/60000 (83%)]\tLoss: 2.304579\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 7/60 [0/60000 (0%)]\tLoss: 2.292933\n",
      "Train Epoch: 7/60 [10000/60000 (17%)]\tLoss: 2.301055\n",
      "Train Epoch: 7/60 [20000/60000 (33%)]\tLoss: 2.302297\n",
      "Train Epoch: 7/60 [30000/60000 (50%)]\tLoss: 2.295755\n",
      "Train Epoch: 7/60 [40000/60000 (67%)]\tLoss: 2.299679\n",
      "Train Epoch: 7/60 [50000/60000 (83%)]\tLoss: 2.300771\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "Train Epoch: 8/60 [0/60000 (0%)]\tLoss: 2.303116\n",
      "Train Epoch: 8/60 [10000/60000 (17%)]\tLoss: 2.293061\n",
      "Train Epoch: 8/60 [20000/60000 (33%)]\tLoss: 2.295948\n",
      "Train Epoch: 8/60 [30000/60000 (50%)]\tLoss: 2.302579\n",
      "Train Epoch: 8/60 [40000/60000 (67%)]\tLoss: 2.305673\n",
      "Train Epoch: 8/60 [50000/60000 (83%)]\tLoss: 2.309774\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 9/60 [0/60000 (0%)]\tLoss: 2.303767\n",
      "Train Epoch: 9/60 [10000/60000 (17%)]\tLoss: 2.303232\n",
      "Train Epoch: 9/60 [20000/60000 (33%)]\tLoss: 2.302728\n",
      "Train Epoch: 9/60 [30000/60000 (50%)]\tLoss: 2.296794\n",
      "Train Epoch: 9/60 [40000/60000 (67%)]\tLoss: 2.298907\n",
      "Train Epoch: 9/60 [50000/60000 (83%)]\tLoss: 2.302363\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 10/60 [0/60000 (0%)]\tLoss: 2.308477\n",
      "Train Epoch: 10/60 [10000/60000 (17%)]\tLoss: 2.299305\n",
      "Train Epoch: 10/60 [20000/60000 (33%)]\tLoss: 2.310234\n",
      "Train Epoch: 10/60 [30000/60000 (50%)]\tLoss: 2.304441\n",
      "Train Epoch: 10/60 [40000/60000 (67%)]\tLoss: 2.292053\n",
      "Train Epoch: 10/60 [50000/60000 (83%)]\tLoss: 2.305756\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 11/60 [0/60000 (0%)]\tLoss: 2.302441\n",
      "Train Epoch: 11/60 [10000/60000 (17%)]\tLoss: 2.302311\n",
      "Train Epoch: 11/60 [20000/60000 (33%)]\tLoss: 2.315677\n",
      "Train Epoch: 11/60 [30000/60000 (50%)]\tLoss: 2.290581\n",
      "Train Epoch: 11/60 [40000/60000 (67%)]\tLoss: 2.305585\n",
      "Train Epoch: 11/60 [50000/60000 (83%)]\tLoss: 2.299893\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 12/60 [0/60000 (0%)]\tLoss: 2.294465\n",
      "Train Epoch: 12/60 [10000/60000 (17%)]\tLoss: 2.284240\n",
      "Train Epoch: 12/60 [20000/60000 (33%)]\tLoss: 2.301818\n",
      "Train Epoch: 12/60 [30000/60000 (50%)]\tLoss: 2.310539\n",
      "Train Epoch: 12/60 [40000/60000 (67%)]\tLoss: 2.302171\n",
      "Train Epoch: 12/60 [50000/60000 (83%)]\tLoss: 2.294456\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 13/60 [0/60000 (0%)]\tLoss: 2.302726\n",
      "Train Epoch: 13/60 [10000/60000 (17%)]\tLoss: 2.308930\n",
      "Train Epoch: 13/60 [20000/60000 (33%)]\tLoss: 2.304640\n",
      "Train Epoch: 13/60 [30000/60000 (50%)]\tLoss: 2.309464\n",
      "Train Epoch: 13/60 [40000/60000 (67%)]\tLoss: 2.301328\n",
      "Train Epoch: 13/60 [50000/60000 (83%)]\tLoss: 2.292706\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 14/60 [0/60000 (0%)]\tLoss: 2.310334\n",
      "Train Epoch: 14/60 [10000/60000 (17%)]\tLoss: 2.297662\n",
      "Train Epoch: 14/60 [20000/60000 (33%)]\tLoss: 2.300799\n",
      "Train Epoch: 14/60 [30000/60000 (50%)]\tLoss: 2.308416\n",
      "Train Epoch: 14/60 [40000/60000 (67%)]\tLoss: 2.298797\n",
      "Train Epoch: 14/60 [50000/60000 (83%)]\tLoss: 2.301859\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 15/60 [0/60000 (0%)]\tLoss: 2.311772\n",
      "Train Epoch: 15/60 [10000/60000 (17%)]\tLoss: 2.305984\n",
      "Train Epoch: 15/60 [20000/60000 (33%)]\tLoss: 2.314564\n",
      "Train Epoch: 15/60 [30000/60000 (50%)]\tLoss: 2.305361\n",
      "Train Epoch: 15/60 [40000/60000 (67%)]\tLoss: 2.315123\n",
      "Train Epoch: 15/60 [50000/60000 (83%)]\tLoss: 2.299494\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 16/60 [0/60000 (0%)]\tLoss: 2.307227\n",
      "Train Epoch: 16/60 [10000/60000 (17%)]\tLoss: 2.301142\n",
      "Train Epoch: 16/60 [20000/60000 (33%)]\tLoss: 2.295062\n",
      "Train Epoch: 16/60 [30000/60000 (50%)]\tLoss: 2.300306\n",
      "Train Epoch: 16/60 [40000/60000 (67%)]\tLoss: 2.294961\n",
      "Train Epoch: 16/60 [50000/60000 (83%)]\tLoss: 2.295324\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 17/60 [0/60000 (0%)]\tLoss: 2.291798\n",
      "Train Epoch: 17/60 [10000/60000 (17%)]\tLoss: 2.292331\n",
      "Train Epoch: 17/60 [20000/60000 (33%)]\tLoss: 2.299292\n",
      "Train Epoch: 17/60 [30000/60000 (50%)]\tLoss: 2.291694\n",
      "Train Epoch: 17/60 [40000/60000 (67%)]\tLoss: 2.308158\n",
      "Train Epoch: 17/60 [50000/60000 (83%)]\tLoss: 2.298943\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 18/60 [0/60000 (0%)]\tLoss: 2.293362\n",
      "Train Epoch: 18/60 [10000/60000 (17%)]\tLoss: 2.295037\n",
      "Train Epoch: 18/60 [20000/60000 (33%)]\tLoss: 2.313445\n",
      "Train Epoch: 18/60 [30000/60000 (50%)]\tLoss: 2.300227\n",
      "Train Epoch: 18/60 [40000/60000 (67%)]\tLoss: 2.304648\n",
      "Train Epoch: 18/60 [50000/60000 (83%)]\tLoss: 2.303648\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 19/60 [0/60000 (0%)]\tLoss: 2.300070\n",
      "Train Epoch: 19/60 [10000/60000 (17%)]\tLoss: 2.298706\n",
      "Train Epoch: 19/60 [20000/60000 (33%)]\tLoss: 2.295944\n",
      "Train Epoch: 19/60 [30000/60000 (50%)]\tLoss: 2.297363\n",
      "Train Epoch: 19/60 [40000/60000 (67%)]\tLoss: 2.296178\n",
      "Train Epoch: 19/60 [50000/60000 (83%)]\tLoss: 2.300672\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 20/60 [0/60000 (0%)]\tLoss: 2.301700\n",
      "Train Epoch: 20/60 [10000/60000 (17%)]\tLoss: 2.300332\n",
      "Train Epoch: 20/60 [20000/60000 (33%)]\tLoss: 2.295600\n",
      "Train Epoch: 20/60 [30000/60000 (50%)]\tLoss: 2.297542\n",
      "Train Epoch: 20/60 [40000/60000 (67%)]\tLoss: 2.299893\n",
      "Train Epoch: 20/60 [50000/60000 (83%)]\tLoss: 2.295919\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 21/60 [0/60000 (0%)]\tLoss: 2.311928\n",
      "Train Epoch: 21/60 [10000/60000 (17%)]\tLoss: 2.303350\n",
      "Train Epoch: 21/60 [20000/60000 (33%)]\tLoss: 2.312715\n",
      "Train Epoch: 21/60 [30000/60000 (50%)]\tLoss: 2.302283\n",
      "Train Epoch: 21/60 [40000/60000 (67%)]\tLoss: 2.300709\n",
      "Train Epoch: 21/60 [50000/60000 (83%)]\tLoss: 2.300223\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 22/60 [0/60000 (0%)]\tLoss: 2.309887\n",
      "Train Epoch: 22/60 [10000/60000 (17%)]\tLoss: 2.299864\n",
      "Train Epoch: 22/60 [20000/60000 (33%)]\tLoss: 2.304918\n",
      "Train Epoch: 22/60 [30000/60000 (50%)]\tLoss: 2.299490\n",
      "Train Epoch: 22/60 [40000/60000 (67%)]\tLoss: 2.306799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22/60 [50000/60000 (83%)]\tLoss: 2.302759\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 23/60 [0/60000 (0%)]\tLoss: 2.302987\n",
      "Train Epoch: 23/60 [10000/60000 (17%)]\tLoss: 2.312592\n",
      "Train Epoch: 23/60 [20000/60000 (33%)]\tLoss: 2.304318\n",
      "Train Epoch: 23/60 [30000/60000 (50%)]\tLoss: 2.307711\n",
      "Train Epoch: 23/60 [40000/60000 (67%)]\tLoss: 2.303343\n",
      "Train Epoch: 23/60 [50000/60000 (83%)]\tLoss: 2.296190\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 24/60 [0/60000 (0%)]\tLoss: 2.303475\n",
      "Train Epoch: 24/60 [10000/60000 (17%)]\tLoss: 2.304190\n",
      "Train Epoch: 24/60 [20000/60000 (33%)]\tLoss: 2.299060\n",
      "Train Epoch: 24/60 [30000/60000 (50%)]\tLoss: 2.307139\n",
      "Train Epoch: 24/60 [40000/60000 (67%)]\tLoss: 2.297291\n",
      "Train Epoch: 24/60 [50000/60000 (83%)]\tLoss: 2.299153\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 25/60 [0/60000 (0%)]\tLoss: 2.305438\n",
      "Train Epoch: 25/60 [10000/60000 (17%)]\tLoss: 2.293175\n",
      "Train Epoch: 25/60 [20000/60000 (33%)]\tLoss: 2.293109\n",
      "Train Epoch: 25/60 [30000/60000 (50%)]\tLoss: 2.293635\n",
      "Train Epoch: 25/60 [40000/60000 (67%)]\tLoss: 2.300503\n",
      "Train Epoch: 25/60 [50000/60000 (83%)]\tLoss: 2.305143\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 26/60 [0/60000 (0%)]\tLoss: 2.305515\n",
      "Train Epoch: 26/60 [10000/60000 (17%)]\tLoss: 2.304292\n",
      "Train Epoch: 26/60 [20000/60000 (33%)]\tLoss: 2.286884\n",
      "Train Epoch: 26/60 [30000/60000 (50%)]\tLoss: 2.294157\n",
      "Train Epoch: 26/60 [40000/60000 (67%)]\tLoss: 2.298425\n",
      "Train Epoch: 26/60 [50000/60000 (83%)]\tLoss: 2.306477\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 27/60 [0/60000 (0%)]\tLoss: 2.297483\n",
      "Train Epoch: 27/60 [10000/60000 (17%)]\tLoss: 2.288628\n",
      "Train Epoch: 27/60 [20000/60000 (33%)]\tLoss: 2.295384\n",
      "Train Epoch: 27/60 [30000/60000 (50%)]\tLoss: 2.304539\n",
      "Train Epoch: 27/60 [40000/60000 (67%)]\tLoss: 2.307751\n",
      "Train Epoch: 27/60 [50000/60000 (83%)]\tLoss: 2.294360\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 28/60 [0/60000 (0%)]\tLoss: 2.304235\n",
      "Train Epoch: 28/60 [10000/60000 (17%)]\tLoss: 2.305888\n",
      "Train Epoch: 28/60 [20000/60000 (33%)]\tLoss: 2.304580\n",
      "Train Epoch: 28/60 [30000/60000 (50%)]\tLoss: 2.298859\n",
      "Train Epoch: 28/60 [40000/60000 (67%)]\tLoss: 2.297390\n",
      "Train Epoch: 28/60 [50000/60000 (83%)]\tLoss: 2.301312\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 29/60 [0/60000 (0%)]\tLoss: 2.300928\n",
      "Train Epoch: 29/60 [10000/60000 (17%)]\tLoss: 2.296941\n",
      "Train Epoch: 29/60 [20000/60000 (33%)]\tLoss: 2.309842\n",
      "Train Epoch: 29/60 [30000/60000 (50%)]\tLoss: 2.298752\n",
      "Train Epoch: 29/60 [40000/60000 (67%)]\tLoss: 2.316016\n",
      "Train Epoch: 29/60 [50000/60000 (83%)]\tLoss: 2.307607\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 30/60 [0/60000 (0%)]\tLoss: 2.303263\n",
      "Train Epoch: 30/60 [10000/60000 (17%)]\tLoss: 2.299228\n",
      "Train Epoch: 30/60 [20000/60000 (33%)]\tLoss: 2.291407\n",
      "Train Epoch: 30/60 [30000/60000 (50%)]\tLoss: 2.304714\n",
      "Train Epoch: 30/60 [40000/60000 (67%)]\tLoss: 2.296808\n",
      "Train Epoch: 30/60 [50000/60000 (83%)]\tLoss: 2.306232\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 31/60 [0/60000 (0%)]\tLoss: 2.298907\n",
      "Train Epoch: 31/60 [10000/60000 (17%)]\tLoss: 2.303001\n",
      "Train Epoch: 31/60 [20000/60000 (33%)]\tLoss: 2.298215\n",
      "Train Epoch: 31/60 [30000/60000 (50%)]\tLoss: 2.296535\n",
      "Train Epoch: 31/60 [40000/60000 (67%)]\tLoss: 2.310622\n",
      "Train Epoch: 31/60 [50000/60000 (83%)]\tLoss: 2.306661\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 32/60 [0/60000 (0%)]\tLoss: 2.297530\n",
      "Train Epoch: 32/60 [10000/60000 (17%)]\tLoss: 2.310205\n",
      "Train Epoch: 32/60 [20000/60000 (33%)]\tLoss: 2.306366\n",
      "Train Epoch: 32/60 [30000/60000 (50%)]\tLoss: 2.307263\n",
      "Train Epoch: 32/60 [40000/60000 (67%)]\tLoss: 2.295775\n",
      "Train Epoch: 32/60 [50000/60000 (83%)]\tLoss: 2.314678\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 33/60 [0/60000 (0%)]\tLoss: 2.296033\n",
      "Train Epoch: 33/60 [10000/60000 (17%)]\tLoss: 2.309735\n",
      "Train Epoch: 33/60 [20000/60000 (33%)]\tLoss: 2.296316\n",
      "Train Epoch: 33/60 [30000/60000 (50%)]\tLoss: 2.304875\n",
      "Train Epoch: 33/60 [40000/60000 (67%)]\tLoss: 2.308057\n",
      "Train Epoch: 33/60 [50000/60000 (83%)]\tLoss: 2.291363\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 34/60 [0/60000 (0%)]\tLoss: 2.297669\n",
      "Train Epoch: 34/60 [10000/60000 (17%)]\tLoss: 2.301465\n",
      "Train Epoch: 34/60 [20000/60000 (33%)]\tLoss: 2.304868\n",
      "Train Epoch: 34/60 [30000/60000 (50%)]\tLoss: 2.288537\n",
      "Train Epoch: 34/60 [40000/60000 (67%)]\tLoss: 2.303225\n",
      "Train Epoch: 34/60 [50000/60000 (83%)]\tLoss: 2.312489\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 35/60 [0/60000 (0%)]\tLoss: 2.300847\n",
      "Train Epoch: 35/60 [10000/60000 (17%)]\tLoss: 2.305120\n",
      "Train Epoch: 35/60 [20000/60000 (33%)]\tLoss: 2.289909\n",
      "Train Epoch: 35/60 [30000/60000 (50%)]\tLoss: 2.304022\n",
      "Train Epoch: 35/60 [40000/60000 (67%)]\tLoss: 2.298817\n",
      "Train Epoch: 35/60 [50000/60000 (83%)]\tLoss: 2.310909\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 36/60 [0/60000 (0%)]\tLoss: 2.298161\n",
      "Train Epoch: 36/60 [10000/60000 (17%)]\tLoss: 2.296297\n",
      "Train Epoch: 36/60 [20000/60000 (33%)]\tLoss: 2.290846\n",
      "Train Epoch: 36/60 [30000/60000 (50%)]\tLoss: 2.306669\n",
      "Train Epoch: 36/60 [40000/60000 (67%)]\tLoss: 2.306359\n",
      "Train Epoch: 36/60 [50000/60000 (83%)]\tLoss: 2.303008\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 37/60 [0/60000 (0%)]\tLoss: 2.297893\n",
      "Train Epoch: 37/60 [10000/60000 (17%)]\tLoss: 2.307463\n",
      "Train Epoch: 37/60 [20000/60000 (33%)]\tLoss: 2.301405\n",
      "Train Epoch: 37/60 [30000/60000 (50%)]\tLoss: 2.301208\n",
      "Train Epoch: 37/60 [40000/60000 (67%)]\tLoss: 2.303736\n",
      "Train Epoch: 37/60 [50000/60000 (83%)]\tLoss: 2.302379\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 38/60 [0/60000 (0%)]\tLoss: 2.305446\n",
      "Train Epoch: 38/60 [10000/60000 (17%)]\tLoss: 2.295697\n",
      "Train Epoch: 38/60 [20000/60000 (33%)]\tLoss: 2.299535\n",
      "Train Epoch: 38/60 [30000/60000 (50%)]\tLoss: 2.298881\n",
      "Train Epoch: 38/60 [40000/60000 (67%)]\tLoss: 2.294534\n",
      "Train Epoch: 38/60 [50000/60000 (83%)]\tLoss: 2.305397\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 39/60 [0/60000 (0%)]\tLoss: 2.305337\n",
      "Train Epoch: 39/60 [10000/60000 (17%)]\tLoss: 2.308661\n",
      "Train Epoch: 39/60 [20000/60000 (33%)]\tLoss: 2.299744\n",
      "Train Epoch: 39/60 [30000/60000 (50%)]\tLoss: 2.302859\n",
      "Train Epoch: 39/60 [40000/60000 (67%)]\tLoss: 2.307716\n",
      "Train Epoch: 39/60 [50000/60000 (83%)]\tLoss: 2.291353\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 40/60 [0/60000 (0%)]\tLoss: 2.299744\n",
      "Train Epoch: 40/60 [10000/60000 (17%)]\tLoss: 2.299781\n",
      "Train Epoch: 40/60 [20000/60000 (33%)]\tLoss: 2.299209\n",
      "Train Epoch: 40/60 [30000/60000 (50%)]\tLoss: 2.302909\n",
      "Train Epoch: 40/60 [40000/60000 (67%)]\tLoss: 2.304252\n",
      "Train Epoch: 40/60 [50000/60000 (83%)]\tLoss: 2.301176\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 41/60 [0/60000 (0%)]\tLoss: 2.298155\n",
      "Train Epoch: 41/60 [10000/60000 (17%)]\tLoss: 2.307458\n",
      "Train Epoch: 41/60 [20000/60000 (33%)]\tLoss: 2.307528\n",
      "Train Epoch: 41/60 [30000/60000 (50%)]\tLoss: 2.299710\n",
      "Train Epoch: 41/60 [40000/60000 (67%)]\tLoss: 2.311341\n",
      "Train Epoch: 41/60 [50000/60000 (83%)]\tLoss: 2.301736\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 42/60 [0/60000 (0%)]\tLoss: 2.295823\n",
      "Train Epoch: 42/60 [10000/60000 (17%)]\tLoss: 2.306912\n",
      "Train Epoch: 42/60 [20000/60000 (33%)]\tLoss: 2.306521\n",
      "Train Epoch: 42/60 [30000/60000 (50%)]\tLoss: 2.292384\n",
      "Train Epoch: 42/60 [40000/60000 (67%)]\tLoss: 2.297992\n",
      "Train Epoch: 42/60 [50000/60000 (83%)]\tLoss: 2.306378\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 43/60 [0/60000 (0%)]\tLoss: 2.306842\n",
      "Train Epoch: 43/60 [10000/60000 (17%)]\tLoss: 2.292651\n",
      "Train Epoch: 43/60 [20000/60000 (33%)]\tLoss: 2.300749\n",
      "Train Epoch: 43/60 [30000/60000 (50%)]\tLoss: 2.301513\n",
      "Train Epoch: 43/60 [40000/60000 (67%)]\tLoss: 2.296860\n",
      "Train Epoch: 43/60 [50000/60000 (83%)]\tLoss: 2.307656\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 44/60 [0/60000 (0%)]\tLoss: 2.300693\n",
      "Train Epoch: 44/60 [10000/60000 (17%)]\tLoss: 2.300168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44/60 [20000/60000 (33%)]\tLoss: 2.302622\n",
      "Train Epoch: 44/60 [30000/60000 (50%)]\tLoss: 2.305707\n",
      "Train Epoch: 44/60 [40000/60000 (67%)]\tLoss: 2.307292\n",
      "Train Epoch: 44/60 [50000/60000 (83%)]\tLoss: 2.300454\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 45/60 [0/60000 (0%)]\tLoss: 2.310520\n",
      "Train Epoch: 45/60 [10000/60000 (17%)]\tLoss: 2.305330\n",
      "Train Epoch: 45/60 [20000/60000 (33%)]\tLoss: 2.304358\n",
      "Train Epoch: 45/60 [30000/60000 (50%)]\tLoss: 2.299617\n",
      "Train Epoch: 45/60 [40000/60000 (67%)]\tLoss: 2.300817\n",
      "Train Epoch: 45/60 [50000/60000 (83%)]\tLoss: 2.302171\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 46/60 [0/60000 (0%)]\tLoss: 2.312762\n",
      "Train Epoch: 46/60 [10000/60000 (17%)]\tLoss: 2.303669\n",
      "Train Epoch: 46/60 [20000/60000 (33%)]\tLoss: 2.304850\n",
      "Train Epoch: 46/60 [30000/60000 (50%)]\tLoss: 2.293423\n",
      "Train Epoch: 46/60 [40000/60000 (67%)]\tLoss: 2.298818\n",
      "Train Epoch: 46/60 [50000/60000 (83%)]\tLoss: 2.307284\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 47/60 [0/60000 (0%)]\tLoss: 2.300170\n",
      "Train Epoch: 47/60 [10000/60000 (17%)]\tLoss: 2.286137\n",
      "Train Epoch: 47/60 [20000/60000 (33%)]\tLoss: 2.308507\n",
      "Train Epoch: 47/60 [30000/60000 (50%)]\tLoss: 2.298356\n",
      "Train Epoch: 47/60 [40000/60000 (67%)]\tLoss: 2.301242\n",
      "Train Epoch: 47/60 [50000/60000 (83%)]\tLoss: 2.307392\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 48/60 [0/60000 (0%)]\tLoss: 2.309413\n",
      "Train Epoch: 48/60 [10000/60000 (17%)]\tLoss: 2.304127\n",
      "Train Epoch: 48/60 [20000/60000 (33%)]\tLoss: 2.308516\n",
      "Train Epoch: 48/60 [30000/60000 (50%)]\tLoss: 2.299868\n",
      "Train Epoch: 48/60 [40000/60000 (67%)]\tLoss: 2.295960\n",
      "Train Epoch: 48/60 [50000/60000 (83%)]\tLoss: 2.310598\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 49/60 [0/60000 (0%)]\tLoss: 2.308917\n",
      "Train Epoch: 49/60 [10000/60000 (17%)]\tLoss: 2.309232\n",
      "Train Epoch: 49/60 [20000/60000 (33%)]\tLoss: 2.311487\n",
      "Train Epoch: 49/60 [30000/60000 (50%)]\tLoss: 2.304365\n",
      "Train Epoch: 49/60 [40000/60000 (67%)]\tLoss: 2.303008\n",
      "Train Epoch: 49/60 [50000/60000 (83%)]\tLoss: 2.305600\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 50/60 [0/60000 (0%)]\tLoss: 2.292333\n",
      "Train Epoch: 50/60 [10000/60000 (17%)]\tLoss: 2.298942\n",
      "Train Epoch: 50/60 [20000/60000 (33%)]\tLoss: 2.300390\n",
      "Train Epoch: 50/60 [30000/60000 (50%)]\tLoss: 2.299755\n",
      "Train Epoch: 50/60 [40000/60000 (67%)]\tLoss: 2.288709\n",
      "Train Epoch: 50/60 [50000/60000 (83%)]\tLoss: 2.302265\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 51/60 [0/60000 (0%)]\tLoss: 2.293509\n",
      "Train Epoch: 51/60 [10000/60000 (17%)]\tLoss: 2.305290\n",
      "Train Epoch: 51/60 [20000/60000 (33%)]\tLoss: 2.307023\n",
      "Train Epoch: 51/60 [30000/60000 (50%)]\tLoss: 2.300394\n",
      "Train Epoch: 51/60 [40000/60000 (67%)]\tLoss: 2.300091\n",
      "Train Epoch: 51/60 [50000/60000 (83%)]\tLoss: 2.296829\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 52/60 [0/60000 (0%)]\tLoss: 2.312041\n",
      "Train Epoch: 52/60 [10000/60000 (17%)]\tLoss: 2.302308\n",
      "Train Epoch: 52/60 [20000/60000 (33%)]\tLoss: 2.303191\n",
      "Train Epoch: 52/60 [30000/60000 (50%)]\tLoss: 2.307892\n",
      "Train Epoch: 52/60 [40000/60000 (67%)]\tLoss: 2.295575\n",
      "Train Epoch: 52/60 [50000/60000 (83%)]\tLoss: 2.297219\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 53/60 [0/60000 (0%)]\tLoss: 2.302829\n",
      "Train Epoch: 53/60 [10000/60000 (17%)]\tLoss: 2.311359\n",
      "Train Epoch: 53/60 [20000/60000 (33%)]\tLoss: 2.297249\n",
      "Train Epoch: 53/60 [30000/60000 (50%)]\tLoss: 2.305912\n",
      "Train Epoch: 53/60 [40000/60000 (67%)]\tLoss: 2.299014\n",
      "Train Epoch: 53/60 [50000/60000 (83%)]\tLoss: 2.296302\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 54/60 [0/60000 (0%)]\tLoss: 2.293742\n",
      "Train Epoch: 54/60 [10000/60000 (17%)]\tLoss: 2.303620\n",
      "Train Epoch: 54/60 [20000/60000 (33%)]\tLoss: 2.317492\n",
      "Train Epoch: 54/60 [30000/60000 (50%)]\tLoss: 2.300898\n",
      "Train Epoch: 54/60 [40000/60000 (67%)]\tLoss: 2.302301\n",
      "Train Epoch: 54/60 [50000/60000 (83%)]\tLoss: 2.308833\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 55/60 [0/60000 (0%)]\tLoss: 2.311629\n",
      "Train Epoch: 55/60 [10000/60000 (17%)]\tLoss: 2.299554\n",
      "Train Epoch: 55/60 [20000/60000 (33%)]\tLoss: 2.306051\n",
      "Train Epoch: 55/60 [30000/60000 (50%)]\tLoss: 2.295820\n",
      "Train Epoch: 55/60 [40000/60000 (67%)]\tLoss: 2.301332\n",
      "Train Epoch: 55/60 [50000/60000 (83%)]\tLoss: 2.293302\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 56/60 [0/60000 (0%)]\tLoss: 2.299275\n",
      "Train Epoch: 56/60 [10000/60000 (17%)]\tLoss: 2.299044\n",
      "Train Epoch: 56/60 [20000/60000 (33%)]\tLoss: 2.300999\n",
      "Train Epoch: 56/60 [30000/60000 (50%)]\tLoss: 2.306569\n",
      "Train Epoch: 56/60 [40000/60000 (67%)]\tLoss: 2.300954\n",
      "Train Epoch: 56/60 [50000/60000 (83%)]\tLoss: 2.294130\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 57/60 [0/60000 (0%)]\tLoss: 2.305801\n",
      "Train Epoch: 57/60 [10000/60000 (17%)]\tLoss: 2.301872\n",
      "Train Epoch: 57/60 [20000/60000 (33%)]\tLoss: 2.298162\n",
      "Train Epoch: 57/60 [30000/60000 (50%)]\tLoss: 2.300572\n",
      "Train Epoch: 57/60 [40000/60000 (67%)]\tLoss: 2.304097\n",
      "Train Epoch: 57/60 [50000/60000 (83%)]\tLoss: 2.303070\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 58/60 [0/60000 (0%)]\tLoss: 2.304662\n",
      "Train Epoch: 58/60 [10000/60000 (17%)]\tLoss: 2.303025\n",
      "Train Epoch: 58/60 [20000/60000 (33%)]\tLoss: 2.302574\n",
      "Train Epoch: 58/60 [30000/60000 (50%)]\tLoss: 2.295155\n",
      "Train Epoch: 58/60 [40000/60000 (67%)]\tLoss: 2.296248\n",
      "Train Epoch: 58/60 [50000/60000 (83%)]\tLoss: 2.311992\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 59/60 [0/60000 (0%)]\tLoss: 2.294147\n",
      "Train Epoch: 59/60 [10000/60000 (17%)]\tLoss: 2.307844\n",
      "Train Epoch: 59/60 [20000/60000 (33%)]\tLoss: 2.293456\n",
      "Train Epoch: 59/60 [30000/60000 (50%)]\tLoss: 2.302904\n",
      "Train Epoch: 59/60 [40000/60000 (67%)]\tLoss: 2.295337\n",
      "Train Epoch: 59/60 [50000/60000 (83%)]\tLoss: 2.297039\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 60/60 [0/60000 (0%)]\tLoss: 2.301633\n",
      "Train Epoch: 60/60 [10000/60000 (17%)]\tLoss: 2.303721\n",
      "Train Epoch: 60/60 [20000/60000 (33%)]\tLoss: 2.291802\n",
      "Train Epoch: 60/60 [30000/60000 (50%)]\tLoss: 2.306285\n",
      "Train Epoch: 60/60 [40000/60000 (67%)]\tLoss: 2.293843\n",
      "Train Epoch: 60/60 [50000/60000 (83%)]\tLoss: 2.297698\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_0.75_0.7_15.pt\n",
      "Done in  3559.0567450523376 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "if os.path.isfile(model_path):\n",
    "    print('Loading')\n",
    "    model = torch.load(model_path)\n",
    "    #model.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    print('Learning')\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    from what import main\n",
    "    #%run what.py --epochs 10 --save-model\n",
    "    main(args)\n",
    "    print('Done in ', time.time() - t0, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.no_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda True\n",
      "Retina vectorizing...\n",
      "ok\n",
      "success\n",
      "Done vectorizing...\n",
      "Inversing retina transform...\n",
      "Done Inversing retina transform...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/MNIST_accuracy.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-116fe637d6f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWhatNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mwhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/quantic/science/ActiveVision/WhereIsMyMNIST/notebooks/where.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, save, batch_load, force_training, model, train_loader, test_loader, generate_data, what_model, retina, trainer, save_model, acc_map, save_path)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                        \u001b[0mretina\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                                        \u001b[0macc_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                                        save_path=save_path)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/quantic/science/ActiveVision/WhereIsMyMNIST/notebooks/where.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, model, train_loader, test_loader, device, generate_data, retina, acc_map, save_path)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0macc_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/MNIST_accuracy.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/MNIST_accuracy.npy'"
     ]
    }
   ],
   "source": [
    "from main import init\n",
    "#args = init(filename='debug')\n",
    "#args = init(filename='../data/2019-03-19_bis')\n",
    "#args = init()\n",
    "#args = init(filename='../data/2019-04-15_bis', verbose=1)\n",
    "args = init(filename='../data/2020-07-01')\n",
    "\n",
    "from where import Where\n",
    "from what import WhatNet\n",
    "where = Where(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from main import init\n",
    "#args = init(filename='debug')\n",
    "args = init(filename='../data/2020-07-01')\n",
    "\n",
    "from where import Where\n",
    "from what import WhatNet\n",
    "where = Where(args)\n",
    "\n",
    "filename_train = args.filename + '_train.pt'\n",
    "#%ls -lh {filename_train}\n",
    "#%rm {filename_train}\n",
    "#%rm  ../data/debug_train.pt\n",
    "\n",
    "where.train(filename_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the learned classifier in a standalone class\n",
    "\n",
    "Maintenant qu'on a appris les points qui permet une classification d'√† peu pr√®s 98 % on va utiliser le mod√®le fead-forward pour faire la classification."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from retina import Display\n",
    "d = Display(args)\n",
    "data, label = next(iter(d.loader_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.236066Z",
     "start_time": "2018-02-16T19:37:37.902628Z"
    }
   },
   "source": [
    "from what import WhatNet\n",
    "model = WhatNet()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "from what import test\n",
    "accuracy = test(args, model, torch.device(\"cpu\"), d.loader_test)\n",
    "print('accuracy=', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shifting the input images\n",
    "\n",
    "\n",
    "Je vais maintenant g√©n√©rer des donn√©es en utilisant les donn√©es originales de MNIST translat√©es :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.247845Z",
     "start_time": "2018-02-16T19:37:42.240563Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "i_shift, j_shift = 12, 17\n",
    "N_pix = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.835649Z",
     "start_time": "2018-02-16T19:37:42.250490Z"
    }
   },
   "outputs": [],
   "source": [
    "from display import Display\n",
    "d = Display(args)\n",
    "data, label = next(iter(d.loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.835649Z",
     "start_time": "2018-02-16T19:37:42.250490Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data[0, 0, :, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.225992Z",
     "start_time": "2018-02-16T19:37:42.839053Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.numpy()\n",
    "data_translate = data.min() * np.ones((data.shape[0], 1, N_pix*3 - 2, N_pix*3 - 2))\n",
    "print(data_translate.shape)\n",
    "data_translate[:, :, (N_pix-i_shift):(2*N_pix-i_shift), (N_pix-j_shift):(2*N_pix-j_shift)] = data\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_translate[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.539188Z",
     "start_time": "2018-02-16T19:37:43.228276Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cropped = data_translate[:, :, (N_pix):(2*N_pix), (N_pix):(2*N_pix)]\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_cropped[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.550455Z",
     "start_time": "2018-02-16T19:37:43.543831Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.arange(-N_pix+1, N_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.960102Z",
     "start_time": "2018-02-16T19:37:43.552774Z"
    }
   },
   "outputs": [],
   "source": [
    "def shift_data(data, i_shift, j_shift):\n",
    "    N_pix = data.shape[-1]\n",
    "    assert(N_pix == data.shape[-2])\n",
    "    import numpy as np\n",
    "    data_translate = data.min() * np.ones((data.shape[0], 1, N_pix*3 - 1, N_pix*3 - 1))\n",
    "    data_translate[:, :, (N_pix+i_shift):(2*N_pix+i_shift), (N_pix+j_shift):(2*N_pix+j_shift)] = data\n",
    "    data_cropped = data_translate[:, :, (N_pix):(2*N_pix), (N_pix):(2*N_pix)]\n",
    "    return data_cropped\n",
    "\n",
    "data_cropped = shift_data(data, i_shift = 12, j_shift = -12)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_cropped[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the learned classifier on the shifted data\n",
    "\n",
    "On peut maintenant tester le classifieur sur les images Translat√©es en calculant la valeur de classification en  fonction de l'erreur de localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:44.165284Z",
     "start_time": "2018-02-16T19:37:43.964216Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_shift(test_loader, i_shift, j_shift, verbose=0):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data_cropped = shift_data(data, i_shift=i_shift, j_shift=j_shift)        \n",
    "        data_cropped = torch.FloatTensor(data_cropped) #transforms.ToTensor()(data_cropped)\n",
    "        data_cropped, target = Variable(data_cropped, volatile=True), Variable(target)\n",
    "        output = model(data_cropped)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if verbose: print('\\nTest set: at ({}, {}), the  average loss is {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        i_shift, j_shift, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "path = \"../data/MNIST_accuracy.npy\"\n",
    "\n",
    "import os\n",
    "if os.path.isfile(path):\n",
    "    print('Loading accuracy')\n",
    "    accuracy = np.load(path)\n",
    "else:\n",
    "    print('Computing accuracy')\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    accuracy = np.zeros((2*N_pix-1, 2*N_pix-1))\n",
    "    from tqdm import tqdm\n",
    "    N_step = 1\n",
    "\n",
    "    with tqdm(total=(2*N_pix-1)**2/N_step**2) as pbar:\n",
    "        for i_shift in np.arange(-N_pix+1, N_pix, N_step):\n",
    "            for j_shift in np.arange(-N_pix+1, N_pix, N_step):\n",
    "                accuracy[i_shift+N_pix-1, j_shift+N_pix-1] = test_shift(test_loader, i_shift, j_shift)\n",
    "                pbar.update()\n",
    "    np.save(path, accuracy)\n",
    "    print('Done in ', time.time() - t0, 'seconds')\n",
    "    \n",
    "print('accuracy=', accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'avoue que c'est un peu bourrin de calculer la classification sur les 128 √ó 128 pixels pour 1000 batch multipli√© par 10 type d'entr√©es.... Mais bon on doit faire √ßa seulement une fois :-) (et sur CPU une classif = environ 300¬µs ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:53:37.955718Z",
     "start_time": "2018-02-16T19:53:37.258057Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5, 5.25))\n",
    "cmap = ax.pcolor(np.arange(-N_pix+1, N_pix+1), np.arange(-N_pix+1, N_pix+1), accuracy, cmap=plt.plasma())\n",
    "ax.axis('equal')\n",
    "fig.colorbar(cmap)\n",
    "fig.savefig('/tmp/panel_C.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction de performance du classifieur  est calcul√©e ind√©pendamment de la forme sp√©cifique du chiffre entre 0 et 9. Elle donne donc la carte de performance qu'on attend Au niveau de la classification/ On va pouvoir maintenant l'utiliser ceomm label pour apprendre de fa√ßon supervis√©e la correspondance entre la carte log-polaire obtenue depuis l'image brute et cette carte de performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinotopic mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation invariant power encoding (colliculus??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retina import Retina\n",
    "r = Retina(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r.colliculus.shape=', r.colliculus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r.colliculus_vector.shape=', r.colliculus_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r.colliculus_inverse.shape=', r.colliculus_inverse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = (r.retina_transform**2).sum(axis=(0,3)) \n",
    "energy /= energy.sum(axis=-1)[:, :, None]\n",
    "energy_vector = energy.reshape((args.N_azimuth*args.N_eccentricity, args.N_pic**2))\n",
    "energy_plus = np.linalg.pinv(energy_vector)\n",
    "FIG_WIDTH = 5 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(figwidth/3, figwidth/3))\n",
    "for i_orient in range(args.N_azimuth):\n",
    "    for i_scale in range(args.N_eccentricity):\n",
    "        env = np.sqrt(energy[i_orient, i_scale, :]**2.5).reshape((args.N_pic, args.N_pic))\n",
    "        ax.contour(energy[i_orient, i_scale, :].reshape((args.N_pic, args.N_pic)), levels=[env.max()/2], lw=1,\n",
    "                  colors=[plt.cm.rainbow(i_scale * 1.5/args.N_azimuth)])\n",
    "#fig.suptitle('Tiling of visual space using energy', y=1.02)\n",
    "ax.set_xlabel(r'$Y$')\n",
    "ax.set_ylabel(r'$X$')\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()\n",
    "fig.savefig('/tmp/panel_B.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (figwidth, figwidth/3.618))\n",
    "ax_A = plt.subplot(1, 3, 1, projection='3d')\n",
    "\n",
    "fig, ax_A = panel_A(fig, ax_A)\n",
    "#data_retina = where.retina.retina(full[idx]['data_fullfield'])\n",
    "#ax_A = where.retina.show(ax_A, where.retina.retina_invert(data_retina))\n",
    "    \n",
    "\n",
    "ax_B = plt.subplot(1, 3, 2)\n",
    "for i_orient in range(0, args.N_azimuth, 2):\n",
    "    for i_scale in range(1, args.N_eccentricity, 2):\n",
    "        env = np.sqrt(energy[i_orient, i_scale, :]**2.5).reshape((args.N_pic, args.N_pic))\n",
    "        ax_B.contour(energy[i_orient, i_scale, :].reshape((args.N_pic, args.N_pic)), levels=[env.max()/2], lw=.1,\n",
    "                  colors=[plt.cm.rainbow(i_scale * 1.5/args.N_azimuth)])\n",
    "ax_B.set_xlabel(r'$Y$')\n",
    "ax_B.set_ylabel(r'$X$')\n",
    "ax_B.axis('square')\n",
    "\n",
    "ax_C = plt.subplot(1, 3, 3)\n",
    "cmap = ax_C.pcolor(np.arange(-N_pix+1, N_pix+1), np.arange(-N_pix+1, N_pix+1), accuracy, cmap=plt.plasma())\n",
    "ax_C.axis('square')\n",
    "ax_C.set_xlabel(r'$\\Delta Y$')\n",
    "ax_C.set_ylabel(r'$\\Delta X$')\n",
    "fig.colorbar(cmap)\n",
    "\n",
    "\n",
    "#for ax, text, x_offset, y_offset in [[ax_A, 'A', -.35, .95], [ax_B, 'B', -.35, .95], [ax_C, 'C', -.35, .95]]:\n",
    "#    ax.text(x_offset, y_offset, '(' + text + ')', fontsize=24,\n",
    "#              bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},\n",
    "#              ha='left', va='center', transform=ax.transAxes) \n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(figname + '.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:23.248986Z",
     "start_time": "2018-10-08T14:43:22.900226Z"
    }
   },
   "outputs": [],
   "source": [
    "import tikzmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:23.266580Z",
     "start_time": "2018-10-08T14:43:23.251008Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%tikz \\draw (0,0) rectangle (1,1);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%tikz --save {fname}.pdf\n",
    "\\draw[white, fill=white] (0.\\linewidth,0) rectangle (1.\\linewidth, .382\\linewidth) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls /tmp/panel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:24.719734Z",
     "start_time": "2018-10-08T14:43:23.285861Z"
    }
   },
   "outputs": [],
   "source": [
    "%%tikz -f pdf --save {figname}.pdf\n",
    "\\draw[white, fill=white] (0.\\linewidth,0) rectangle (1.\\linewidth, .382\\linewidth) ;\n",
    "\\draw [anchor=north west] (.0\\linewidth, .382\\linewidth) node {\\includegraphics[width=.33\\linewidth]{/tmp/panel_A.pdf}};\n",
    "\\draw [anchor=north west] (.333\\linewidth, .382\\linewidth) node {\\includegraphics[width=.31\\linewidth]{/tmp/panel_B.pdf}};\n",
    "\\draw [anchor=north west] (.666\\linewidth, .382\\linewidth) node {\\includegraphics[width=.35\\linewidth]{/tmp/panel_C.pdf}};\n",
    "\\begin{scope}[font=\\bf\\sffamily\\large]\n",
    "\\draw [anchor=west,fill=white] (.0\\linewidth, .382\\linewidth) node [above right=-3mm] {$\\mathsf{D}$};\n",
    "\\draw [anchor=west,fill=white] (.36\\linewidth, .382\\linewidth) node [above right=-3mm] {$\\mathsf{E}$};\n",
    "\\draw [anchor=west,fill=white] (.69\\linewidth, .382\\linewidth) node [above right=-3mm] {$\\mathsf{F}$};\n",
    "\\end{scope}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:27.591507Z",
     "start_time": "2018-10-08T14:43:24.722160Z"
    }
   },
   "outputs": [],
   "source": [
    "!convert  -density {dpi_export} {figname}.pdf {figname}.jpg\n",
    "!convert  -density {dpi_export} {figname}.pdf {figname}.png\n",
    "#!convert  -density {dpi_export} -resize 5400  -units pixelsperinch -flatten  -compress lzw  -depth 8 {fname}.pdf {fname}.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.981927Z",
     "start_time": "2018-07-03T10:36:00.949864Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('{figname}.png'.format(figname=figname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.939193Z",
     "start_time": "2018-07-03T10:36:00.766218Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls  -l {figname}*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
