{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On change la loss function --> (multinomial) CrossEntropy loss\n",
    "\n",
    "## output = multinomial sample\n",
    "\n",
    "## Passage à une architecture convolutionnelle\n",
    "\n",
    "Ajouts/modifs :\n",
    "  * simplification de l'architecture (seule l'image blanchie est en entrée)\n",
    "  * dans le roll : supression des régions hors image (white noise) \n",
    "  \n",
    "## modif : poids croissant des entrées selon l'eccentricité\n",
    "\n",
    "## modif : suppression des couches profondes + deconvolution (analyse par niveau de profondeur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_theta, N_azimuth, N_eccentricity, N_phase, N_X, N_Y, rho = 6, 24, 16, 2, 256, 256, 1.21 #1.41 #1.25 #\n",
    "#N_theta, N_azimuth, N_eccentricity, N_phase, N_X, N_Y, rho = 6, 12, 8, 2, 256, 256, 1.41\n",
    "verbose = 1\n",
    "OFFSET_STD = 15\n",
    "OFFSET_MAX = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#size used for downsizing images\n",
    "size=256\n",
    "\n",
    "test_sample_ratio=5/100\n",
    "#folder names\n",
    "imdir_org,fixdir_org='ALLSTIMULI/ALLSTIMULI','ALLFIXATIONMAPS/ALLFIXATIONMAPS'\n",
    "#imdir_new,fixdir_new='GLOBAL_IMAGES','GLOBAL_FIXATIONMAPS'\n",
    "#imdir_test,fixdir_test='GLOBAL_IMAGES_TEST','GLOBAL_FIXATIONMAPS_TEST'\n",
    "#creating empty folders:\n",
    "\n",
    "imdir, fixdir = 'GLOBAL_IMAGES_ALL_PLAIN','GLOBAL_FIXATIONMAPS_ALL_PLAIN'\n",
    "imdir_white, fixdir_white = 'GLOBAL_IMAGES_ALL_WHITE','GLOBAL_FIXATIONMAPS_ALL_WHITE'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GLOBAL_IMAGES_ALL_PLAIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-75e0f1dce7ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdir\u001b[0m \u001b[0;31m#imdir_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimage_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GLOBAL_IMAGES_ALL_PLAIN'"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "'''image_ref_dir = imdir_org\n",
    "image_ref_names=os.listdir(image_ref_dir)\n",
    "image_ref=np.load(os.path.join(image_ref_dir,image_ref_names[i]))\n",
    "\n",
    "fix_ref_dir = fixdir_org\n",
    "fix_ref_names=os.listdir(fix_ref_dir)\n",
    "fix_ref=np.load(os.path.join(fix_ref_dir,fix_ref_names[i]))'''\n",
    "\n",
    "image_dir = imdir #imdir_new\n",
    "image_names=os.listdir(image_dir)\n",
    "image=np.load(os.path.join(image_dir,image_names[i]))\n",
    "\n",
    "image_dir_white = imdir_white #imdir_new\n",
    "image_white_names=os.listdir(image_dir_white)\n",
    "image_white=np.load(os.path.join(image_dir_white,image_names[i]))\n",
    "\n",
    "fix_dir = fixdir #fixdir_new\n",
    "fix_names=os.listdir(fix_dir)\n",
    "fix=np.load(os.path.join(fix_dir,fix_names[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "'''plt.subplot(141)\n",
    "plt.imshow(image_ref)\n",
    "plt.subplot(142)\n",
    "_ = plt.plot(fix_ref)'''\n",
    "plt.subplot(141)\n",
    "plt.imshow(image)\n",
    "plt.subplot(142)\n",
    "_ = plt.plot(image)\n",
    "plt.subplot(143)\n",
    "plt.imshow(fix)\n",
    "plt.subplot(144)\n",
    "_ = plt.plot(fix/sum(fix.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(fix)\n",
    "m = fix/sum(fix.flatten())\n",
    "m = m.flatten()\n",
    "\n",
    "'''for i in range(20):\n",
    "    print(np.where(np.random.multinomial(1, m) == 1)[0][0])'''\n",
    "\n",
    "m_mult = np.random.multinomial(2000, m)\n",
    "plt.figure()\n",
    "plt.imshow(m_mult.reshape(256, 256))\n",
    "\n",
    "m_mult = np.random.multinomial(1, m).reshape(256, 256)\n",
    "print(np.where(m_mult == 1))\n",
    "coord = np.where(m_mult == 1)\n",
    "plt.plot(coord[1], coord[0], 'r+')\n",
    "print(coord[1][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "'''plt.subplot(141)\n",
    "plt.imshow(image_ref)\n",
    "plt.subplot(142)\n",
    "_ = plt.plot(fix_ref)'''\n",
    "plt.subplot(141)\n",
    "plt.imshow(image_white)\n",
    "plt.subplot(142)\n",
    "_ = plt.plot(image_white)\n",
    "plt.subplot(143)\n",
    "plt.imshow(fix)\n",
    "plt.subplot(144)\n",
    "_ = plt.plot(fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from LogGabor import LogGabor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pierre's stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding : N_theta x N_azimuth x N_eccentricity x N_phase  2D filters (to be applied on N_X x N_Y pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparer l'apprentissage et les fonctions nécessaires au fonctionnement du script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorization(N_theta=N_theta, N_azimuth=N_azimuth, N_eccentricity=N_eccentricity, N_phase=N_phase, \\\n",
    "                  N_X=N_X, N_Y=N_Y, rho=rho, ecc_max=1, B_sf=.4, B_theta=np.pi/N_theta/2):\n",
    "    retina = np.zeros((N_theta, N_azimuth, N_eccentricity, N_phase, N_X*N_Y))\n",
    "    parameterfile = 'https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py'\n",
    "    lg = LogGabor(parameterfile)\n",
    "    lg.set_size((N_X, N_Y))\n",
    "    # params = {'sf_0': .1, 'B_sf': lg.pe.B_sf,\n",
    "    #           'theta': np.pi * 5 / 7., 'B_theta': lg.pe.B_theta}\n",
    "    # phase = np.pi/4\n",
    "    # edge = lg.normalize(lg.invert(lg.loggabor(\n",
    "    #     N_X/3, 3*N_Y/4, **params)*np.exp(-1j*phase)))\n",
    "\n",
    "    for i_theta in range(N_theta):\n",
    "        for i_azimuth in range(N_azimuth):\n",
    "            for i_eccentricity in range(N_eccentricity):\n",
    "                ecc = ecc_max * (1/rho)**(N_eccentricity - i_eccentricity)\n",
    "                r = np.sqrt(N_X**2+N_Y**2) / 2 * ecc  # radius\n",
    "                sf_0 = 0.5 * 0.03 / ecc\n",
    "                x = N_X/2 + r * \\\n",
    "                    np.cos((i_azimuth+(i_eccentricity % 2)*.5)*np.pi*2 / N_azimuth)\n",
    "                y = N_Y/2 + r * \\\n",
    "                    np.sin((i_azimuth+(i_eccentricity % 2)*.5)*np.pi*2 / N_azimuth)\n",
    "                for i_phase in range(N_phase):\n",
    "                    params = {'sf_0': sf_0, 'B_sf': B_sf,\n",
    "                              'theta': i_theta*np.pi/N_theta, 'B_theta': B_theta}\n",
    "                    phase = i_phase * np.pi/2\n",
    "                    # print(r, x, y, phase, params)\n",
    "\n",
    "                    retina[i_theta, i_azimuth, i_eccentricity, i_phase, :] = lg.normalize(\n",
    "                        lg.invert(lg.loggabor(x, y, **params)*np.exp(-1j*phase))).ravel() * 2 * np.pi * ecc\n",
    "\n",
    "\n",
    "    return retina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del retina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIC_NAME = 'retina_256_24_ecc_16_expand.npy'\n",
    "if not os.path.exists(FIC_NAME):\n",
    "    retina = vectorization(N_theta, N_azimuth, N_eccentricity, N_phase, N_X, N_Y, rho) #, ecc_max=1)\n",
    "    np.save(FIC_NAME, retina)\n",
    "else:\n",
    "    retina = np.load(FIC_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(retina.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    plt.hist(abs(retina[:,:,15-i,:,::10000].flatten()), 100)\n",
    "    plt.legend()\n",
    "    plt.ylim((0,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retina_vector = retina.reshape((N_theta*N_azimuth*N_eccentricity*N_phase, N_X*N_Y))\n",
    "print(retina_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FIC_NAME = 'retina_inverse_256_24_ecc_16_expand.npy'\n",
    "if not os.path.exists(FIC_NAME):\n",
    "    retina_inverse = np.linalg.pinv(retina_vector)\n",
    "    np.save(FIC_NAME, retina_inverse)\n",
    "else:\n",
    "    retina_inverse = np.load(FIC_NAME)\n",
    "print(retina_inverse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orientation invariant power encoding (colliculus??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colliculus = (retina**2).sum(axis=(0, 3))\n",
    "colliculus = colliculus**.5\n",
    "colliculus /= colliculus.sum(axis=-1)[:, :, None]\n",
    "print(colliculus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colliculus_vector = colliculus.reshape((N_azimuth*N_eccentricity, N_X*N_Y))\n",
    "print(colliculus_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colliculus_inverse = np.linalg.pinv(colliculus_vector)\n",
    "print(colliculus_inverse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "energy = colliculus ** 2\n",
    "energy /= energy.sum(axis=-1)[:, :, None]\n",
    "energy_vector = energy.reshape((N_azimuth*N_eccentricity, N_X*N_Y))\n",
    "energy_plus = np.linalg.pinv(energy_vector)\n",
    "FIG_WIDTH = 5 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_WIDTH))\n",
    "for i_orient in range(N_azimuth):\n",
    "    for i_scale in range(N_eccentricity):\n",
    "        env = np.sqrt(energy[i_orient, i_scale, :]**2.5).reshape((N_X, N_Y))\n",
    "        ax.contour(energy[i_orient, i_scale, :].reshape((N_X, N_Y)), levels=[env.max()/2], lw=1,\n",
    "                  colors=[plt.cm.rainbow(i_scale * 1.5/N_azimuth)])\n",
    "fig.suptitle('Tiling of visual space using energy')\n",
    "ax.set_xlabel(r'$Y$')\n",
    "ax.set_ylabel(r'$X$')\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minmax(value, border):\n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#im = SLIP.Image(pe='https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py')\n",
    "\n",
    "class Transform(object):\n",
    "    \"\"\"Rescale the image through LogGabors\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, test = False, tensor = False):\n",
    "        #assert isinstance(output_size, (int, tuple))\n",
    "        #self.output_size = output_size\n",
    "        self.test = test\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, image_white, fixmap = sample['image'], sample['image_white'], sample['fixation']\n",
    "        (nb_l, nb_col) = image.shape\n",
    "        \n",
    "        #i_offset = minmax(np.random.randn() * OFFSET_STD, OFFSET_MAX)\n",
    "        #j_offset = minmax(np.random.randn() * OFFSET_STD, OFFSET_MAX)\n",
    "        \n",
    "        '''if np.random.rand() > 0.5:\n",
    "            image_white = np.fliplr(image_white)\n",
    "            image = np.fliplr(image)\n",
    "            fixmap = np.fliplr(fixmap)'''\n",
    "        \n",
    "        if True : #not self.test:\n",
    "            m = fixmap/sum(fixmap.flatten())\n",
    "            m = m.flatten()\n",
    "            m_mult = np.random.multinomial(1, m).reshape(256, 256)\n",
    "            coord = np.where(m_mult == 1)\n",
    "            i_offset = 127 - coord[0][0]\n",
    "            j_offset = 127 - coord[1][0]\n",
    "        else:\n",
    "            i_offset = 0\n",
    "            j_offset = 0\n",
    "        \n",
    "        '''i_offset = 0\n",
    "        j_offset = -50'''\n",
    "        \n",
    "        image_white = np.roll(image_white, i_offset, axis=0)\n",
    "        image_white = np.roll(image_white, j_offset, axis=1)  \n",
    "        mean_white = np.mean(image_white.flatten())\n",
    "        std_white = np.std(image_white.flatten())\n",
    "        \n",
    "        image = np.roll(image, i_offset, axis=0)\n",
    "        image = np.roll(image, j_offset, axis=1)\n",
    "        mean_im = np.mean(image.flatten())\n",
    "        std_im = np.std(image.flatten())\n",
    "        \n",
    "        fixmap = np.roll(fixmap, i_offset, axis=0)\n",
    "        fixmap = np.roll(fixmap, j_offset, axis=1)    \n",
    "        \n",
    "        if i_offset > 0 :\n",
    "            image_white[:i_offset, :] = mean_white + std_white * np.random.randn(i_offset, nb_col) #127\n",
    "            image[:i_offset, :] = mean_im + std_im * np.random.randn(i_offset, nb_col) #127\n",
    "            fixmap[:i_offset, :] = 0\n",
    "        elif i_offset < 0:\n",
    "            image_white[i_offset:, :] = mean_white + std_white * np.random.randn(-i_offset, nb_col) #127\n",
    "            image[i_offset:, :] = mean_im + std_im * np.random.randn(-i_offset, nb_col) #127\n",
    "            fixmap[i_offset:, :] = 0     \n",
    "        \n",
    "        if j_offset > 0 :\n",
    "            image_white[:,:j_offset] = mean_white + std_white * np.random.randn(nb_l, j_offset) #127\n",
    "            image[:,:j_offset] = mean_im + std_im * np.random.randn(nb_l, j_offset) #127\n",
    "            fixmap[:,:j_offset] = 0\n",
    "        elif j_offset < 0:\n",
    "            image_white[:,j_offset:] = mean_white + std_white * np.random.randn(nb_l, -j_offset) \n",
    "            image[:,j_offset:] = mean_im + std_im * np.random.randn(nb_l, -j_offset) \n",
    "            fixmap[:,j_offset:] = 0\n",
    "        \n",
    "        image_white = (image_white - mean_white) / std_white\n",
    "        image = (image - mean_im) / std_im\n",
    "        \n",
    "        '''plt.figure()    \n",
    "        plt.imshow(image_white, cmap = 'gray')\n",
    "        plt.figure()    \n",
    "        plt.imshow(fixmap, cmap = 'gray')'''\n",
    "        \n",
    "        image_retina = retina_vector @ np.ravel(image_white)\n",
    "        image_retina /= np.std(image_retina)\n",
    "        \n",
    "        image_colliculus = colliculus_vector @ np.ravel(image)\n",
    "        #image_colliculus -= np.mean(image_colliculus)\n",
    "        image_colliculus /= np.std(image_colliculus)\n",
    "        \n",
    "        fixmap_colliculus = colliculus_vector @ np.ravel(fixmap)\n",
    "        fixmap_colliculus = fixmap_colliculus/np.sum(fixmap_colliculus)\n",
    "        \n",
    "        if not self.test:\n",
    "            m_coll = fixmap_colliculus/sum(fixmap_colliculus)\n",
    "            m_coll_mult = np.random.multinomial(25, m_coll)\n",
    "            #m_coll_mult[np.where(m_coll_mult > 1)] = 1\n",
    "            m_coll_mult = np.array(m_coll_mult)/np.sum(m_coll_mult)\n",
    "        \n",
    "        if self.tensor:\n",
    "            image_retina = image_retina.reshape(N_theta, N_azimuth, N_eccentricity, N_phase)\n",
    "            slice1 = image_retina[N_theta - 1,:,:,:].reshape(1,N_azimuth,N_eccentricity,N_phase)\n",
    "            slice2 = image_retina[0,:,:,:].reshape(1,N_azimuth,N_eccentricity,N_phase)\n",
    "            image_retina = np.concatenate ((slice1, image_retina, slice2), axis = 0)\n",
    "            image_retina = np.transpose(image_retina,(3,0,1,2))\n",
    "            image_colliculus = image_colliculus.reshape(1,N_azimuth, N_eccentricity)\n",
    "            '''if not self.test:\n",
    "                m_coll_mult = m_coll_mult.reshape(1, N_azimuth, N_eccentricity)\n",
    "            else:\n",
    "                fixmap_colliculus = fixmap_colliculus.reshape(N_azimuth, N_eccentricity)'''\n",
    "                \n",
    "        if self.test:\n",
    "            return {'image': image_colliculus, 'image_white': image_retina, 'fixation': fixmap_colliculus}\n",
    "        else:\n",
    "            return {'image': image_colliculus, 'image_white': image_retina, 'fixation': m_coll_mult}   \n",
    "        \n",
    "        #r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageDataset(data.Dataset):\n",
    "    \"\"\"image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, imdir, imdir_white, fixdir, transform=None, index = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imdir (string): Path to the image folder\n",
    "            fixdir (string): Path to the fixation maps folder\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.imdir = imdir\n",
    "        self.fixdir = fixdir\n",
    "        self.imdir_white = imdir_white\n",
    "        if index is None :\n",
    "            print('OK')\n",
    "            self.image_names=os.listdir(imdir)\n",
    "            self.fix_names=os.listdir(fixdir)\n",
    "        else:\n",
    "            self.image_names=np.array(os.listdir(imdir))[index]\n",
    "            self.fix_names=np.array(os.listdir(fixdir))[index]\n",
    "        self.transform = transform # we do not use transforms\n",
    "        #self.data_loader=data.DataLoader(self,batch_size=batch_size) : did not work\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image=np.load(os.path.join(self.imdir,self.image_names[idx]))\n",
    "        image_white=np.load(os.path.join(self.imdir_white,self.image_names[idx]))\n",
    "        fix_map=np.load(os.path.join(self.fixdir,self.fix_names[idx]))/255 # to transform between 0 and 1 (for the BCELoss to work)\n",
    "\n",
    "        sample = {'image': image, 'image_white': image_white, 'fixation': fix_map}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = Transform(tensor = False)\n",
    "dataset = ImageDataset(image_dir,image_dir_white,fix_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "sample = dataset[i] #['image'], dataset[i]['fixation'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(sample['image'], cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "_ = plt.plot(sample['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = sample['image']\n",
    "im2 = np.pad(im, ((10, 10), (10, 10)), 'median')\n",
    "plt.imshow(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_off = sample['image']\n",
    "i_offset = minmax(np.random.randn() * OFFSET_STD, OFFSET_MAX)\n",
    "j_offset = minmax(np.random.randn() * OFFSET_STD, OFFSET_MAX)\n",
    "print(i_offset, j_offset)\n",
    "print(OFFSET_STD)\n",
    "image_off = np.roll(image_off, i_offset, axis=0)\n",
    "image_off = np.roll(image_off, j_offset, axis=1)    \n",
    "if i_offset > 0 :\n",
    "    image_off[:i_offset, :] = 0\n",
    "elif i_offset < 0:\n",
    "    image_off[i_offset:, :] = 0\n",
    "\n",
    "if j_offset > 0 :\n",
    "    image_off[:,:j_offset] = 0\n",
    "elif j_offset < 0:\n",
    "    image_off[:,j_offset:] = 0\n",
    "\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(sample['image'], cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')\n",
    "plt.subplot(122)\n",
    "plt.imshow(image_off, cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(sample['image_white'], cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "_ = plt.plot(sample['image_white'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''train = True\n",
    "batch_size = 10\n",
    "data_loader = torch.utils.data.DataLoader(dataset, train=train, download=True, batch_size=batch_size, shuffle=True)'''\n",
    "dataloader = data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(batch['image'][0,:,:], cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "_ = plt.plot(batch['image'][0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = Transform(tensor = True)\n",
    "sample_retina = trans(sample) #retina_vector @ np.ravel(sample['image'])\n",
    "sample_cut = sample_retina['image_white'][:,1:N_theta+1,:,:]\n",
    "print(sample_cut.shape)\n",
    "sample_cut = np.transpose(sample_cut, (1,2,3,0))\n",
    "print(sample_cut.shape)\n",
    "plt.figure()\n",
    "plt.plot(sample_cut.reshape(N_azimuth * N_eccentricity * N_theta * N_phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(sample_cut.reshape(N_azimuth * N_eccentricity * N_theta * N_phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = Transform()\n",
    "sample_retina = trans(sample) #retina_vector @ np.ravel(sample['image'])\n",
    "plt.plot(sample_retina['image'].reshape(N_azimuth * N_eccentricity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_colliculus = colliculus_vector @ np.ravel(sample['fixation'])\n",
    "plt.plot(sample_retina['fixation'].reshape(N_azimuth * N_eccentricity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Polar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = Transform(test = False)\n",
    "sample_retina = trans(sample)\n",
    "delta = 1/N_azimuth\n",
    "log_r, theta = np.meshgrid(np.linspace(0, 1, N_eccentricity + 1), np.linspace(-np.pi*(.5 + delta), np.pi*(1.5 - delta), N_azimuth + 1))\n",
    "f = plt.figure(figsize = (15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "data_retina = sample_retina['image_white'].reshape(N_azimuth * N_eccentricity * N_theta * N_phase)\n",
    "#data_retina = sample_cut.reshape(N_azimuth * N_eccentricity * N_theta * N_phase)\n",
    "image_white = retina_inverse @ data_retina\n",
    "#im = colliculus_inverse @ data_retina\n",
    "plt.imshow(image_white.reshape(N_X, N_Y), cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')\n",
    "\n",
    "ax = f.add_subplot(132, projection='polar')\n",
    "vec = sample_retina['fixation'].reshape(N_azimuth * N_eccentricity)\n",
    "ax.pcolor(theta, log_r, vec.reshape((N_azimuth, N_eccentricity)))\n",
    "plt.plot(0,0, 'r+')\n",
    "\n",
    "ax = f.add_subplot(133)\n",
    "plt.imshow((colliculus_inverse @ vec).reshape(N_X, N_Y) )#sample['fixation'])\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colliculus_inverse @ vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(sample['image_white'], cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')\n",
    "\n",
    "plt.subplot(122)\n",
    "data_retina = sample_retina['image_white'].reshape(N_azimuth * N_eccentricity * N_theta * N_phase)\n",
    "image_white = retina_inverse @ data_retina\n",
    "#im = colliculus_inverse @ data_retina\n",
    "plt.imshow(image_white.reshape(N_X, N_Y), cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(sample['image'], cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')\n",
    "\n",
    "plt.subplot(122)\n",
    "data_retina = sample_retina['image'].reshape(N_azimuth * N_eccentricity)\n",
    "image = colliculus_inverse @ data_retina\n",
    "#im = colliculus_inverse @ data_retina\n",
    "plt.imshow(image.reshape(N_X, N_Y), cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(sample['image'], cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(10 * image_white.reshape(N_X, N_Y)+image.reshape(N_X, N_Y), cmap = 'gray')\n",
    "plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    transform = Transform()\n",
    "    batch_size = 100\n",
    "    dataset = ImageDataset(image_dir, image_dir_white, fix_dir, transform = transform)\n",
    "    dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    fixmap_avg = sum(batch['fixation'])/batch_size\n",
    "\n",
    "    f = plt.figure(figsize = (15, 5))\n",
    "\n",
    "    i = 3\n",
    "\n",
    "    plt.subplot(131)\n",
    "    #for i in range(10):\n",
    "    plt.plot(batch['fixation'][i,:], 'g')\n",
    "    plt.plot(batch['fixation'][i,:] - fixmap_avg)\n",
    "    plt.plot(fixmap_avg,'r')\n",
    "\n",
    "    ax = f.add_subplot(132, projection='polar')\n",
    "    vec = batch['fixation'][i,:] \n",
    "    ax.pcolor(theta, log_r, vec.reshape((N_azimuth, N_eccentricity)))\n",
    "    plt.plot(0,0, 'r+')\n",
    "\n",
    "    ax = f.add_subplot(133, projection='polar')\n",
    "    vec = batch['fixation'][i,:] - fixmap_avg\n",
    "    ax.pcolor(theta, log_r, vec.reshape((N_azimuth, N_eccentricity)))\n",
    "    plt.plot(0,0, 'r+')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input vectors encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''def image_fullfield(image):\n",
    "    image_retina = retina_vector @ np.ravel(image)\n",
    "    return image_retina'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output vectors (Accuracy/Saliency map) encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''def fixmap_fullfield(fixmap):   \n",
    "    fixmap_colliculus = colliculus_vector @ np.ravel(fixmap)\n",
    "    return fixmap_colliculus'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''def couples(image, fixmap): #, device):\n",
    "    #data = data.to(device)\n",
    "    v = image_fullfield(data)\n",
    "    a = fixmap_fullfield(fixmap)\n",
    "    return (v, a)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minibatch_size = 25  # quantity of examples that'll be processed\n",
    "lr = 1e-4 #0.05\n",
    "\n",
    "verbose = 1\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if do_cuda else {}\n",
    "device = torch.cuda.device(\"cuda\" if do_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = Transform(tensor = True)\n",
    "transform_test = Transform(tensor = True, test = True)\n",
    "\n",
    "image_dir = imdir #'GLOBAL_IMAGES_ALL'\n",
    "fix_dir = fixdir #'GLOBAL_FIXATIONMAPS_ALL'\n",
    "\n",
    "'''image_names=os.listdir(image_dir)\n",
    "print (len(image_names))\n",
    "fix_names=os.listdir(fix_dir)\n",
    "print (len(fix_names))\n",
    "for i in range(len(image_names)):\n",
    "    if image_names[i][:7] != fix_names[i][:7]:\n",
    "        print(image_names[i], fix_names[i])'''\n",
    "\n",
    "n = len(os.listdir(image_dir))\n",
    "index = np.arange(n)\n",
    "np.random.shuffle(index)\n",
    "print(index)\n",
    "index_train = index[:800]\n",
    "index_test = index[800:]\n",
    "\n",
    "train_dataset = ImageDataset(image_dir, image_dir_white, fix_dir, transform = transform, index = index_train)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = ImageDataset(image_dir, image_dir_white, fix_dir, transform = transform_test, index = index_test)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size = len(test_dataset), shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''for batch_idx, batch in enumerate(train_loader):\n",
    "    print (batch_idx)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_azimuth, N_eccentricity, N_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BIAS_CONV = True\n",
    "BIAS_DECONV = True #True\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## White\n",
    "        self.conv1 = nn.Conv3d(2, 16, 3, bias = BIAS_CONV, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 64, 3, bias = BIAS_CONV, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(64, 256, 3, bias = BIAS_CONV, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2, stride=2)\n",
    "        self.conv_hidden1 = nn.Conv2d(256, 20, 1, bias = BIAS_CONV, stride=1, padding=0)\n",
    "        self.conv_hidden2 = nn.Conv2d(20, 2, 1, bias = BIAS_CONV, stride=1, padding=0)\n",
    "        self.deconv_hidden2 = nn.Conv2d(2, 100, 1, bias = BIAS_DECONV, stride=1, padding=0)\n",
    "        self.deconv_hidden1 = nn.Conv2d(100, N_azimuth / 3 * N_eccentricity / 2, 1, bias = BIAS_DECONV, stride=1, padding=0)\n",
    "        # taille 256 *  3 (az) * 2 (ecc) * 1 (thet)\n",
    "        \n",
    "        \n",
    "        #self.dropout = nn.Dropout(p = 0.5) \n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        # in\n",
    "        data = F.relu(self.pool(self.conv1(image)))\n",
    "        data = F.relu(self.pool(self.conv2(data)))\n",
    "        data = F.relu(self.pool(self.conv3(data)))\n",
    "        data = data.view(-1, 256, 3, 2)\n",
    "        \n",
    "        data = F.relu(self.conv_hidden1(data)) \n",
    "        data = F.dropout(data, p = .5) \n",
    "        data = self.conv_hidden2(data)\n",
    "        data = F.relu(self.deconv_hidden2(data))\n",
    "        data = self.deconv_hidden1(data)\n",
    "        \n",
    "        # out\n",
    "        for i in range(3): # Azimuth\n",
    "            for j in range(2): # Eccentricity\n",
    "                data_cell = data[:,:,i,j].view(-1, N_azimuth / 3, N_eccentricity / 2) \n",
    "                if j == 0 :\n",
    "                    data_row = data_cell\n",
    "                else:\n",
    "                    data_row = torch.cat((data_row, data_cell), 2)\n",
    "            if i == 0 :\n",
    "                data_full = data_row\n",
    "            else:\n",
    "                data_full = torch.cat((data_full, data_row), 1)\n",
    "        data = data_full.view(-1, N_azimuth * N_eccentricity) \n",
    "        return data\n",
    "    \n",
    "    '''def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss_func = torch.nn.CrossEntropyLoss() #BCEWithLogitsLoss()\n",
    "\n",
    "def loss_func(pred, soft_targets):\n",
    "    # cross entropy\n",
    "    logsoftmax = nn.LogSoftmax()\n",
    "    return torch.mean(torch.sum(- soft_targets * logsoftmax(pred), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "def KL_loss(pred, soft_targets):\n",
    "    # cross entropy\n",
    "    logsoftmax = nn.LogSoftmax()\n",
    "    log = torch.log\n",
    "    return torch.mean(torch.sum(- soft_targets * (logsoftmax(pred) - log(soft_targets)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "def entropy(soft_targets):\n",
    "    # cross entropy\n",
    "    log = torch.log\n",
    "    return -torch.mean(torch.sum(soft_targets *  log(soft_targets), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net, minibatch_size, \\\n",
    "          optimizer=optimizer, \\\n",
    "          vsize = N_theta * N_azimuth * N_eccentricity * N_phase,\\\n",
    "          asize = N_azimuth * N_eccentricity, \\\n",
    "          verbose=1):\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    if verbose: print('Starting training...')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        log_image_batch_white = batch['image_white'].float()\n",
    "        log_fixmap_batch = batch['fixation'].float()\n",
    "        \n",
    "        prediction = net(log_image_batch_white)\n",
    "        loss = loss_func(prediction, log_fixmap_batch) \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose and batch_idx % 10 == 0:\n",
    "            print('[{}/{}] Loss: {} Time: {:.2f} mn'.format(\n",
    "                batch_idx * minibatch_size, len(train_loader.dataset),\n",
    "                loss.data.numpy(), (time.time()-t_start)/60))\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(net, minibatch_size, optimizer=optimizer,\n",
    "         vsize=N_theta*N_azimuth*N_eccentricity*N_phase,\n",
    "         asize=N_azimuth*N_eccentricity):\n",
    "    #for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    batch = next(iter(test_loader))\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    '''log_image_batch = np.zeros((batch_size, 1, vsize))\n",
    "    log_fixmap_batch = np.zeros((batch_size, 1, asize))\n",
    "    \n",
    "    for idx in range(batch_size):\n",
    "        log_image_batch[idx, 0, :], log_fixmap_batch[idx, 0, :] = couples(batch['image'][idx, :, :], batch['fixation'][idx, :, :])\n",
    "        #input_[idx, 0, :], a_data[idx, 0, :] = couples(data[idx, 0, :], i_offset, j_offset)\n",
    "        #target[idx, :] = a_data[idx, 0, :]'''\n",
    "\n",
    "\n",
    "    prediction = net(batch['image_white'].float())\n",
    "    loss = loss_func(prediction, batch['fixation'].float())\n",
    "\n",
    "    return loss.data.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#FIC_NAME = 'results/2019-01-01-Malek-recap-multi-1-no-offset'\n",
    "FIC_NAME = 'results/2019-01-08-Malek-recap-multi-25-withbias'\n",
    "EPOCHS = 50\n",
    "\n",
    "if not os.path.exists(FIC_NAME + '.npy'):\n",
    "    for epoch in range(EPOCHS) :\n",
    "        print(epoch)\n",
    "        train(net, minibatch_size)\n",
    "        Accuracy = test(net, minibatch_size)\n",
    "        mes = 'Test set: Final Accuracy: {:.3f}'.format(Accuracy * 1.) \n",
    "        print(mes)\n",
    "        with open(FIC_NAME + '.txt', 'a') as f:\n",
    "            f.write(mes + '\\n')\n",
    "        torch.save(net, FIC_NAME + '.npy')    \n",
    "        np.save(FIC_NAME + '-index.npy', index)   \n",
    "else:\n",
    "    net = torch.load(FIC_NAME + '.npy')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    np.save('2018-12-23-fixation-ref.npy', vec_ref)\n",
    "else:\n",
    "    vec_ref = np.load('2018-12-23-fixation-ref.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NB_FIG = 20\n",
    "NB_TURN = 1 #1000\n",
    "FLAG_AFF = True\n",
    "\n",
    "delta = 1/N_azimuth\n",
    "log_r, theta = np.meshgrid(np.linspace(0, 1, N_eccentricity + 1), np.linspace(-np.pi*(.5 + delta), np.pi*(1.5 - delta), N_azimuth + 1))\n",
    "\n",
    "class Results:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "results = Results()\n",
    "\n",
    "if not os.path.exists(FIC_NAME+'-results.npy') or FLAG_AFF: \n",
    "    index = np.load(FIC_NAME+'-index.npy')\n",
    "    index_train = index[:800] \n",
    "    index_test = index[800:] \n",
    "    net = torch.load(FIC_NAME+'.npy', map_location=lambda storage, loc: storage) #torch.load(FIC_NAME+'.npy').to('cpu') \n",
    "\n",
    "    mem_loss_base, mem_loss_out, mem_entropy_fix = [], [], []\n",
    "    mem_KL_loss_base, mem_KL_loss_out = [], []\n",
    "    mem_KL_diff, mem_relative_gain = [], []\n",
    "    for __ in range(NB_TURN):\n",
    "        print(__)\n",
    "        if False :\n",
    "            transform_train = Transform(test = True, tensor = True) \n",
    "            train_dataset = ImageDataset(image_dir, image_dir_white, fix_dir, transform = transform_train, index = index_train)\n",
    "            train_loader = data.DataLoader(train_dataset, batch_size = NB_FIG , shuffle=True, num_workers=4)\n",
    "            batch = next(iter(train_loader))\n",
    "        else:\n",
    "            transform_test = Transform(test = True, tensor = True) \n",
    "            test_dataset = ImageDataset(image_dir, image_dir_white, fix_dir, transform = transform_test, index = index_test)\n",
    "            test_loader = data.DataLoader(test_dataset, batch_size = NB_FIG , shuffle=True, num_workers=4)\n",
    "            batch = next(iter(test_loader))\n",
    "\n",
    "        vec_ref_torch = Variable(torch.FloatTensor(vec_ref))\n",
    "        for _ in range(NB_FIG ):\n",
    "         \n",
    "            vec = batch['fixation'][_,:]\n",
    "            in_white = batch['image_white'][_,:].reshape((1,N_phase,N_theta+2,N_azimuth,N_eccentricity)).float()\n",
    "            out = net(in_white)\n",
    "\n",
    "            loss_base = loss_func(torch.log(vec_ref_torch).reshape((1, -1)), vec.float()).detach().numpy()\n",
    "            mem_loss_base += [loss_base]\n",
    "            loss_out = loss_func(out, vec.float()).detach().numpy()\n",
    "            mem_loss_out += [loss_out]\n",
    "            entropy_fix = entropy(vec.reshape(1,-1)).detach().numpy()\n",
    "            mem_entropy_fix += [entropy_fix]\n",
    "            KL_loss_base = KL_loss(torch.log(vec_ref_torch).reshape((1, -1)), vec.float()).detach().numpy()\n",
    "            mem_KL_loss_base += [KL_loss_base]\n",
    "            KL_loss_out = KL_loss(out, vec.float()).detach().numpy()\n",
    "            mem_KL_loss_out += [KL_loss_out]\n",
    "            KL_diff = KL_loss_base - KL_loss_out\n",
    "            mem_KL_diff +=  [KL_diff]\n",
    "            relative_gain = 1 - KL_loss_out/KL_loss_base\n",
    "            mem_relative_gain += [relative_gain]\n",
    "\n",
    "            if FLAG_AFF:\n",
    "                \n",
    "                image = colliculus_inverse @ batch['image'][_,:].reshape(N_azimuth * N_eccentricity)\n",
    "                \n",
    "                data_white = batch['image_white'][_,:,1:N_theta+1,:,:]\n",
    "                data_white = np.transpose(data_white, (1, 2, 3, 0))\n",
    "                image_white = retina_inverse @ data_white.reshape(N_theta * N_azimuth * N_eccentricity * N_phase)\n",
    "                \n",
    "                plt.figure(figsize = (15, 5))\n",
    "\n",
    "                #plt.subplot(161)\n",
    "                #plt.plot(batch['image_white'][_,:])\n",
    "                plt.subplot(131)\n",
    "                plt.imshow(image_white.reshape(N_X, N_X) * 20 + image.reshape(N_X, N_X) * 0, cmap = 'gray')\n",
    "                plt.plot(N_X/2 - 0.5, N_Y/2 - 0.5, 'r+')\n",
    "                plt.title(_)\n",
    "                plt.subplot(163)\n",
    "                plt.plot(batch['fixation'][_,:].detach().numpy()[::-1])    \n",
    "                plt.title('Loss_base : %.2f' % loss_base)\n",
    "                #col = colliculus_inverse @ batch['fixation'][_,:]\n",
    "                ax = plt.subplot(264, projection='polar')\n",
    "\n",
    "                ax.pcolor(theta, log_r, vec.reshape((N_azimuth, N_eccentricity)))\n",
    "                plt.title('Loss : %.2f' % loss_out)\n",
    "\n",
    "                plt.subplot(2,6,10)\n",
    "                map = vec.reshape((N_azimuth, N_eccentricity)).detach().numpy().transpose()\n",
    "                map = np.flipud(np.fliplr(map))\n",
    "                plt.imshow(map)\n",
    "                plt.title('Entropy : %.2f' % entropy_fix)\n",
    "\n",
    "                #plt.imshow(col.reshape(128, 128))\n",
    "\n",
    "                plt.subplot(165)\n",
    "                out_sig = F.softmax(out).detach().numpy()\n",
    "                plt.plot(out_sig[0,::-1]) #) #_sig)    \n",
    "                loss = loss_func(out, vec.float()).detach().numpy()\n",
    "                plt.title(\"KL_base = %.2f\"% KL_loss_base)\n",
    "                #view = colliculus_inverse @ out_sig\n",
    "                ax = plt.subplot(266, projection='polar')\n",
    "                ax.pcolor(theta, log_r, out_sig.reshape((N_azimuth, N_eccentricity)))\n",
    "                plt.plot(0,0,'r+')\n",
    "                #plt.imshow(view.reshape(128, 128))\n",
    "                plt.title(\"KL_out = %.2f\" % KL_loss_out)\n",
    "                plt.subplot(2,6,12)\n",
    "                map = out_sig.reshape((N_azimuth, N_eccentricity)).transpose()\n",
    "                map = np.flipud(np.fliplr(map))\n",
    "                plt.imshow(map)\n",
    "                #plt.title(\"KL_diff = %.2f\" % KL_diff)\n",
    "                plt.title(\"relative gain = %.2f\" % relative_gain)\n",
    "    \n",
    "        if not FLAG_AFF :\n",
    "            results.mem_loss_base = mem_loss_base\n",
    "            results.mem_loss_out = mem_loss_out\n",
    "            results.mem_entropy_fix = mem_entropy_fix\n",
    "            results.mem_KL_loss_base = mem_KL_loss_base\n",
    "            results.mem_KL_loss_out = mem_KL_loss_out\n",
    "            results.mem_KL_diff = mem_KL_diff\n",
    "            results.mem_relative_gain = mem_relative_gain\n",
    "            np.save(FIC_NAME+'-results.npy', results)\n",
    "else:\n",
    "    results = np.load(FIC_NAME+'-results.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
