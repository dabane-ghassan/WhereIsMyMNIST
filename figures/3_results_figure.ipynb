{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the problem addressed in this paper:\n",
    "\n",
    " - localizating an object in a large image\n",
    " - foveation\n",
    " - action (saccade)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This notebook introduces the problem addressed in this paper:\n",
      "\n",
      " - localizating an object in a large image\n",
      " - foveation\n",
      " - action (saccade)\n",
      "       \n",
      "      \n",
      "{'w': 28, 'minibatch_size': 100, 'train_batch_size': 50000, 'test_batch_size': 5000, 'noise_batch_size': 1000, 'mean': 0.1307, 'std': 0.3081, 'N_pic': 128, 'offset_std': 30, 'offset_max': 34, 'noise': 1.0, 'contrast': 1.0, 'sf_0': 0.2, 'B_sf': 0.3, 'N_theta': 6, 'N_azimuth': 26, 'N_eccentricity': 10, 'N_phase': 2, 'rho': 1.41, 'bias_deconv': True, 'p_dropout': 0.0, 'dim1': 500, 'dim2': 2000, 'lr': 0.001, 'do_adam': True, 'bn1_bn_momentum': 0.5, 'bn2_bn_momentum': 0.2, 'momentum': 0.1, 'epochs': 25, 'num_processes': 1, 'no_cuda': True, 'log_interval': 100, 'verbose': 1, 'filename': '../data/2019-03-27', 'seed': 2019, 'N_cv': 8, 'do_compute': True}\n",
      "Overwriting train.py\n",
      "2019-07-13T14:39:16+02:00\n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.6.1\n",
      "\n",
      "numpy 1.16.4\n",
      "matplotlib 3.1.1\n",
      "torch 1.1.0.post2\n",
      "\n",
      "compiler   : Clang 10.0.1 (clang-1001.0.46.3)\n",
      "system     : Darwin\n",
      "release    : 18.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : ekla\n",
      "Git hash   : fa2c442f1e3fe428ce1efc23dd63a29a368319c3\n",
      "Git repo   : https://github.com/laurentperrinet/WhereIsMyMNIST\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "%run 0_parameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:34:13.258190Z",
     "start_time": "2018-07-03T10:34:13.251661Z"
    }
   },
   "outputs": [],
   "source": [
    "figname = '../paper/fig_result'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Where network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 13 22:14 ../data/2019-03-13_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 14 17:44 ../data/2019-03-14_b_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 14 06:17 ../data/2019-03-14_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 14 14:54 ../data/2019-03-14_train3.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 14 19:28 ../data/2019-03-14_train4.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 15 22:18 ../data/2019-03-15_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 15 15:31 ../data/2019-03-15_train_b.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   8.8M Mar 20 17:46 ../data/2019-03-16_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 19 00:19 ../data/2019-03-18_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 19 15:18 ../data/2019-03-19_bis_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 19 15:54 ../data/2019-03-19_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    12M Mar 27 16:30 ../data/2019-03-27_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    11M Mar 29 16:13 ../data/2019-03-29_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   5.7M Apr  8 23:09 ../data/2019-04-01_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   6.1M Apr  3 12:47 ../data/2019-04-03_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    16M Apr 25 17:17 ../data/2019-04-15_bis_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    16M Apr 15 14:28 ../data/2019-04-15_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff    16M Apr 19 11:00 ../data/2019-04-16_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Mar 14 12:31 ../data/MNIST_cnn.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  1 09:09 ../data/MNIST_cnn_0.05_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  1 12:31 ../data/MNIST_cnn_0.06299605249474366_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 17 22:59 ../data/MNIST_cnn_0.07071067811865475_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 18 13:22 ../data/MNIST_cnn_0.07937005259840997_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 18 15:27 ../data/MNIST_cnn_0.08908987181403394_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 18 21:44 ../data/MNIST_cnn_0.11224620483093731_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 19 02:31 ../data/MNIST_cnn_0.12599210498948732_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 19 03:59 ../data/MNIST_cnn_0.14142135623730953_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  1 14:31 ../data/MNIST_cnn_0.15874010519681994_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  1 21:43 ../data/MNIST_cnn_0.1_0.05_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  1 23:53 ../data/MNIST_cnn_0.1_0.06299605249474366_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 19 08:43 ../data/MNIST_cnn_0.1_0.07071067811865475_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 17 21:39 ../data/MNIST_cnn_0.1_0.07937005259840997_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 19 10:48 ../data/MNIST_cnn_0.1_0.08908987181403394_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 19 10:49 ../data/MNIST_cnn_0.1_0.11224620483093731_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 19 10:49 ../data/MNIST_cnn_0.1_0.12599210498948732_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 19 10:49 ../data/MNIST_cnn_0.1_0.14142135623730953_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  2 02:31 ../data/MNIST_cnn_0.1_0.15874010519681994_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  2 16:09 ../data/MNIST_cnn_0.1_0.1_0.375_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  2 23:24 ../data/MNIST_cnn_0.1_0.1_0.4724703937105774_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 04:19 ../data/MNIST_cnn_0.1_0.1_0.5303300858899106_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 04:19 ../data/MNIST_cnn_0.1_0.1_0.5952753944880748_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 09:33 ../data/MNIST_cnn_0.1_0.1_0.6681740386052545_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  3 06:03 ../data/MNIST_cnn_0.1_0.1_0.75_0.35.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  3 07:04 ../data/MNIST_cnn_0.1_0.1_0.75_0.44097236746320556.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 18:15 ../data/MNIST_cnn_0.1_0.1_0.75_0.4949747468305832.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 18:57 ../data/MNIST_cnn_0.1_0.1_0.75_0.5555903681888698.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 18:58 ../data/MNIST_cnn_0.1_0.1_0.75_0.6236291026982375.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 17 21:39 ../data/MNIST_cnn_0.1_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 21 05:18 ../data/MNIST_cnn_0.1_0.1_0.75_0.7857234338165611.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 21 08:11 ../data/MNIST_cnn_0.1_0.1_0.75_0.8819447349264111.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 21 09:04 ../data/MNIST_cnn_0.1_0.1_0.75_0.9899494936611666.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  3 09:58 ../data/MNIST_cnn_0.1_0.1_0.75_1.1111807363777395.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  3 11:21 ../data/MNIST_cnn_0.1_0.1_0.75_1.4.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 17:23 ../data/MNIST_cnn_0.1_0.1_0.8418465362320298_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 17:57 ../data/MNIST_cnn_0.1_0.1_0.9449407874211548_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Apr 20 18:08 ../data/MNIST_cnn_0.1_0.1_1.0606601717798214_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  3 01:31 ../data/MNIST_cnn_0.1_0.1_1.1905507889761495_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  3 04:02 ../data/MNIST_cnn_0.1_0.1_1.5_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  2 02:30 ../data/MNIST_cnn_0.1_0.2_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M May  1 14:41 ../data/MNIST_cnn_0.2_0.1_0.75_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.1_5epoques_2019-06-20_14h05.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.2_5epoques_2019-06-20_13h58.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.3_5epoques_2019-06-20_13h52.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.4_5epoques_2019-06-20_13h46.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.5_5epoques_2019-06-20_13h40.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.6_5epoques_2019-06-20_13h34.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.7_1epoques_2019-06-14_14h32.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.7_5epoques_2019-06-14_15h00.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.7_5epoques_2019-06-17_16h55.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.7_5epoques_2019-06-19_11h50.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.7_5epoques_2019-06-20_13h27.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.7_60epoques_2019-06-17_10h20.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1.0_0.7_60epoques_2019-06-17_16h54.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1_0.7.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1_0.7_60epoques.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   1.7M Jul  4 14:43 ../data/MNIST_cnn_robust_what_0.1_0.1_1_0.7_60epoques_2019-06-13_10h47.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   6.1M Apr  8 16:34 ../data/debug_train.pt\n",
      "-rw-r--r--  1 laurentperrinet  staff   150M Apr 15 13:22 ../data/noisy-MNIST.pt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh ../data/*pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'what.WhatNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset\n",
      "Loading testing dataset\n",
      "Loading file ../data/2019-04-16_train.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'where.WhereNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "from main import init\n",
    "#args = init(filename='debug')\n",
    "#args = init(filename='../data/2019-03-19_bis')\n",
    "#args = init()\n",
    "args = init(filename='../data/2019-04-16')\n",
    "\n",
    "from where import Where\n",
    "from what import WhatNet\n",
    "where = Where(args)\n",
    "\n",
    "filename_train = args.filename + '_train.pt'\n",
    "#filename_train = \"../data/2019-03-14_train4.pt\"\n",
    "#filename_train = \"../data/2019-03-29.pt\"\n",
    "#%ls -lh {filename_train}\n",
    "#%rm {filename_train}\n",
    "#%rm  ../data/debug_train.pt\n",
    "\n",
    "where.train(filename_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(where.display.loader_test))\n",
    "idx_start, idx_stop = 10, 20\n",
    "\n",
    "positions, data_fullfield, retina_data, accuracy_colliculus = where.minibatch(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knowing the target position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for dimension 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2fad266a515d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fullfield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i_offset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'j_offset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_what\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for dimension 0 with size 100"
     ]
    }
   ],
   "source": [
    "im = np.zeros((args.test_batch_size, args.w, args.w))\n",
    "for idx in range(args.test_batch_size):\n",
    "    im[idx, :, :] = where.extract(data_fullfield[idx, :, :], positions[idx]['i_offset'], positions[idx]['j_offset'])\n",
    "proba = where.classify_what(im).numpy()\n",
    "pred = proba.argmax(axis=1) # get the index of the max log-probability\n",
    "#acc = proba[:, pred]\n",
    "acc_max = (pred==label.numpy()).mean()\n",
    "print('Accuracy max (knowing the position)=', acc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(idx_start, idx_stop):\n",
    "    fig = plt.figure(figsize = (15, 8))\n",
    "    \n",
    "    ax = fig.add_subplot(141)\n",
    "    ax = where.display.show(ax, data_fullfield[idx, :, :])\n",
    "    ax.set_title(f\"i={positions[idx]['i_offset']}, j={positions[idx]['j_offset']}\")\n",
    "    \n",
    "    ax = fig.add_subplot(142)\n",
    "    data_retina = where.retina.retina(data_fullfield[idx, :, :])\n",
    "    ax = where.retina.show(ax, where.retina.retina_invert(data_retina))\n",
    "    ax.set_title(f\"idx={idx}\")\n",
    "              \n",
    "    ax = fig.add_subplot(143, projection='polar')\n",
    "    ax.pcolor(where.retina.theta, where.retina.log_r, accuracy_colliculus[idx, :].numpy().reshape((args.N_azimuth, args.N_eccentricity)), cmap=plt.plasma())\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_title(\"True\")\n",
    "\n",
    "    ax = fig.add_subplot(144)\n",
    "    ax = where.display.show(ax, im[idx, :, :], do_cross=False)\n",
    "    result = '' if pred[idx]==label[idx].numpy() else 'FALSE'\n",
    "    ax.set_title(f\"pred={pred[idx]} acc={proba[idx,pred[idx]]:.2f} {result}\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicting the position of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_accuracy_colliculus = where.pred_accuracy(retina_data)\n",
    "print('pred_accuracy_colliculus.shape=', pred_accuracy_colliculus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(idx_start, idx_stop):\n",
    "    fig = plt.figure(figsize = (15, 8))\n",
    "\n",
    "    ax = fig.add_subplot(131, projection='polar')\n",
    "    ax.pcolor(where.retina.theta, where.retina.log_r, pred_accuracy_colliculus[idx, :].reshape((args.N_azimuth, args.N_eccentricity)), cmap=plt.plasma())\n",
    "    ax.set_title(\"Predicted\")\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "              \n",
    "    x = where.retina.accuracy_invert(pred_accuracy_colliculus[idx, :])\n",
    "    ax = fig.add_subplot(132)\n",
    "    ax.imshow(x, vmin=0, cmap=plt.plasma())\n",
    "    ax.set_title(\"Pred visual space\")\n",
    "    \n",
    "    i_pred, j_pred = where.index_prediction(pred_accuracy_colliculus[idx, :])\n",
    "    \n",
    "    ax = fig.add_subplot(133)\n",
    "    ax = where.display.show(ax, data_fullfield[idx, :, :])\n",
    "    ax.set_title(f\"i={positions[idx]['i_offset']}/{i_pred}, j={positions[idx]['j_offset']}/{j_pred}\")\n",
    "    ax.plot([positions[idx]['j_offset']+args.N_pic//2], [positions[idx]['i_offset']+args.N_pic//2], '+', c='r', ms=26, markeredgewidth=2, alpha=.5)\n",
    "    ax.plot([j_pred+args.N_pic//2], [i_pred+args.N_pic//2], '+', c='b', ms=26, markeredgewidth=2, alpha=.5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing a saccade at the predicted the position of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_fullfield.shape, retina_data.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = where.test_what(data_fullfield, pred_accuracy_colliculus, label)\n",
    "print('mean accuracy =', accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(idx_start, idx_stop):\n",
    "    fig = plt.figure(figsize = (15, 8))\n",
    "    \n",
    "    ax = fig.add_subplot(151)\n",
    "    ax = where.display.show(ax, data_fullfield[idx, :, :])\n",
    "    ax.set_title(f\"i={positions[idx]['i_offset']}, j={positions[idx]['j_offset']}\")\n",
    "    \n",
    "    ax = fig.add_subplot(152)\n",
    "    data_retina = where.retina.retina(data_fullfield[idx, :, :])\n",
    "    ax = where.retina.show(ax, where.retina.retina_invert(data_retina))\n",
    "    ax.set_title(f\"idx={idx}\")\n",
    "              \n",
    "    ax = fig.add_subplot(153, projection='polar')\n",
    "    ax.pcolor(where.retina.theta, where.retina.log_r, accuracy_colliculus[idx, :].numpy().reshape((args.N_azimuth, args.N_eccentricity)), cmap=plt.plasma())\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_title(\"True\")\n",
    "\n",
    "    ax = fig.add_subplot(154, projection='polar')\n",
    "    ax.pcolor(where.retina.theta, where.retina.log_r, pred_accuracy_colliculus[idx, :].reshape((args.N_azimuth, args.N_eccentricity)), cmap=plt.plasma())\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_title(\"Predicted\")\n",
    "\n",
    "    i_pred, j_pred = where.index_prediction(pred_accuracy_colliculus[idx, :])\n",
    "    ax = fig.add_subplot(155)                 \n",
    "    ax = where.display.show(ax, where.extract(data_fullfield[idx, :, :], i_pred, j_pred), do_cross=False)\n",
    "    result = '' if pred[idx]==label[idx].numpy() else 'FALSE'\n",
    "    ax.set_title(f\"pred={pred[idx]} acc={proba[idx,pred[idx]]:.2f} {result}\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = where.test()\n",
    "print('Average accuracy on the test set = ', correct.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy as a function of eccentricity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eccentricities(N_eccentricities=9, ecc_max=.8, do_control=False):\n",
    "    import torch\n",
    "    from torch.autograd import Variable\n",
    "\n",
    "    #eccentricities = args.N_pic / 2 * ecc_max * (1/args.rho)**(args.N_eccentricity - np.arange(N_eccentricities))\n",
    "    eccentricities = np.linspace(where.args.offset_max, 0, N_eccentricities, endpoint=False)\n",
    "    batch_size = where.args.test_batch_size # data.shape[0]\n",
    "    from retina import get_data_loader\n",
    "    loader_test = get_data_loader(batch_size=1, train=False, \n",
    "                                  mean=where.args.mean, std=where.args.std, seed=where.args.seed+10)\n",
    "        \n",
    "    accuracy_mean, accuracy_std = [], []\n",
    "    for eccentricity in eccentricities:\n",
    "\n",
    "        retina_data = np.zeros((batch_size, where.retina.vsize))\n",
    "        labels = np.zeros((batch_size))\n",
    "        data_fullfield = np.zeros((batch_size, where.args.N_pic, where.args.N_pic))        \n",
    "        accuracy_colliculus = np.zeros((batch_size, where.args.N_azimuth * where.args.N_eccentricity))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            data, label = next(iter(loader_test))\n",
    "            data_fullfield[i, :, :], i_offset, j_offset = where.display.draw(data[0, 0, :, :].numpy(), \n",
    "                                                                   radius=eccentricity)\n",
    "            positions.append(dict(i_offset=i_offset, j_offset=j_offset))\n",
    "            retina_data[i, :]  =  where.retina.retina(data_fullfield[i, :, :])\n",
    "            labels[i] = label\n",
    "        labels =  Variable(torch.FloatTensor(labels))\n",
    "        retina_data =  Variable(torch.FloatTensor(retina_data))\n",
    "        pred_accuracy_colliculus = where.pred_accuracy(retina_data)\n",
    "        \n",
    "        accuracy_ = where.test_what(data_fullfield, pred_accuracy_colliculus, labels.squeeze(), do_control=do_control)\n",
    "        accuracy_mean.append(accuracy_.mean())\n",
    "        accuracy_std.append(accuracy_.std()) # TODO fit with beta distribution\n",
    "        \n",
    "    return eccentricities, np.array(accuracy_mean), np.array(accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_eccentricities = 9\n",
    "eccentricities, accuracy_mean, accuracy_std = test_eccentricities(N_eccentricities)\n",
    "print('eccentricities=', eccentricities, ', accuracy_data=', accuracy_mean, ' +/- ', accuracy_std)\n",
    "\n",
    "eccentricities, ctl_accuracy_mean, ctl_accuracy_std = test_eccentricities(N_eccentricities, do_control=True)\n",
    "print('eccentricities=', eccentricities, ', ctl_accuracy_data=', ctl_accuracy_mean, ' +/- ', ctl_accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (figwidth, figwidth/1.618))\n",
    "ax_D = fig.add_subplot(1, 1, 1)\n",
    "width = .8*np.abs(np.gradient(eccentricities)[0])\n",
    "ax_D.bar(eccentricities, accuracy_mean, width=width, alpha = .5, label = 'One saccade')#yerr=accuracy_std, \n",
    "# TODO what instead? ax_D.bar(eccentricities, accuracy_data, alpha = .5, label = 'No saccade') #accuracy_map[27,27:55])\n",
    "ax_D.bar(eccentricities, ctl_accuracy_mean, width=width, color='orange', alpha = 1., label = 'No saccade')\n",
    "ax_D.plot([eccentricities.min()-width/2, eccentricities.max()+width/2], [0.1]*2, ':', c='k', label = 'Baseline')\n",
    "plt.legend(loc='best')\n",
    "#ax_D.set_title('Class accuracy', fontsize = 14)\n",
    "ax_D.set_xlabel('Target eccentricity (pixels)', fontsize = 12)\n",
    "ax_D.set_xticks(eccentricities)\n",
    "ax_D.set_xticklabels(['%.1f' % d for  d in eccentricities])\n",
    "ax_D.set_ylim([0,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (figwidth, figwidth/2.5))#1.618))\n",
    "ax_A = plt.subplot(1, 4, 1) \n",
    "data_retina = where.retina.retina(data_fullfield[idx, :, :])\n",
    "ax_A = where.retina.show(ax_A, where.retina.retina_invert(data_retina))\n",
    "    \n",
    "ax_B = plt.subplot(2, 4, 2, projection='polar', autoscale_on=False)\n",
    "ax_B.pcolor(where.retina.theta, where.retina.log_r, accuracy_colliculus[idx, :].numpy().reshape((args.N_azimuth, args.N_eccentricity)))\n",
    "ax_B.grid('off')\n",
    "plt.title('True', fontsize = 14)\n",
    "ax_B.set_yticklabels([])\n",
    "ax_B.set_xticklabels([])\n",
    "\n",
    "ax_Bb = plt.subplot(2, 4, 6, projection='polar')\n",
    "ax_Bb.pcolor(where.retina.theta, where.retina.log_r, pred_accuracy_colliculus[idx, :].reshape((args.N_azimuth, args.N_eccentricity)))\n",
    "ax_Bb.set_title('Predicted', fontsize = 14)\n",
    "ax_Bb.set_yticklabels([])\n",
    "ax_Bb.set_xticklabels([])\n",
    "\n",
    "ax_C = plt.subplot(1, 4, 3)\n",
    "data_fullfield_ = where.display.place_object(data[idx, 0, :, :].numpy(), 0, 0)\n",
    "input_vector  =  where.retina.retina(data_fullfield_)\n",
    "ax_C = where.retina.show(ax_C, where.retina.retina_invert(input_vector))\n",
    "i_pred, j_pred = where.index_prediction(pred_accuracy_colliculus[idx, :])\n",
    "#ax_A.arrow(64.5, 64.5, j_pred, i_pred, width=.3, color='r', head_width=4., length_includes_head=True, edgecolor='k')\n",
    "ax_C.arrow(args.N_pic//2+j_pred+14, args.N_pic//2+i_pred+14, -j_pred, -i_pred, width=.3, color='r', head_width=4., length_includes_head=True, edgecolor='k')\n",
    "ax_C.arrow(args.N_pic//2+j_pred+14, args.N_pic//2+i_pred-14, -j_pred, -i_pred, width=.3, color='r', head_width=4., length_includes_head=True, edgecolor='k')\n",
    "\n",
    "ax_D = plt.subplot(1, 4, 4)\n",
    "width = .8*np.abs(np.gradient(eccentricities)[0])\n",
    "ax_D.bar(eccentricities, accuracy_mean, width=width, color='blue', alpha = .5, label = 'One saccade')\n",
    "ax_D.bar(eccentricities, ctl_accuracy_mean, width=width, color='orange', alpha = 1., label = 'No saccade')\n",
    "ax_D.plot([eccentricities.min()-width/2, eccentricities.max()+width/2], [0.1]*2, ':', c='k', label = 'Baseline')\n",
    "#ax_D.plot([eccentricities.min()-width/2, eccentricities.max()+width/2], [acc_max]*2, ':', c='k', label = 'Max')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "ax_D.set_xlabel('Target eccentricity (pixels)', fontsize = 12)\n",
    "ax_D.set_xticks(eccentricities)\n",
    "ax_D.set_xticklabels(['%.1f' % d for  d in eccentricities])\n",
    "ax_D.set_ylim([0,1])\n",
    "\n",
    "for ax, text in [[ax_A, 'DIS'], [ax_C, 'SAC']]:\n",
    "    ax.text(4, 15, text, fontsize=24,\n",
    "          bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},\n",
    "          ha='left', va='center') \n",
    "\n",
    "offset = -.015\n",
    "for ax, text, x_offset, y_offset in [[ax_A, 'A', offset, 1.15], [ax_B, 'B', -.25, 1.225], [ax_C, 'C', offset, 1.15], [ax_D, 'D', offset, 1.15]]:\n",
    "    ax.text(x_offset, y_offset, '(' + text + ')', fontsize=24,\n",
    "              bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},\n",
    "              ha='left', va='center', transform=ax.transAxes) \n",
    "\n",
    "# pos : [left, bottom, width, height] =    The new position of the in `.Figure` coordinates.    \n",
    "plt.tight_layout()\n",
    "ax_A.set_position([0.025, 0.1, .3, .45])\n",
    "ax_B.set_position( [0.24, 0.375, .2, 0.2])\n",
    "ax_Bb.set_position([0.24, 0.1, .2, 0.2])\n",
    "ax_C.set_position([0.35, .1, .3, .45])\n",
    "ax_D.set_position([0.65, .1, .3, .45])\n",
    "fig.savefig(figname + '.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:27.591507Z",
     "start_time": "2018-10-08T14:43:24.722160Z"
    }
   },
   "outputs": [],
   "source": [
    "!convert  -density {dpi_export} {figname}.pdf {figname}.jpg\n",
    "!convert  -density {dpi_export} {figname}.pdf {figname}.png\n",
    "#!convert  -density {dpi_export} -resize 5400  -units pixelsperinch -flatten  -compress lzw  -depth 8 {fname}.pdf {fname}.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.981927Z",
     "start_time": "2018-07-03T10:36:00.949864Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('{figname}.png'.format(figname=figname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.939193Z",
     "start_time": "2018-07-03T10:36:00.766218Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls  -l {figname}*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
