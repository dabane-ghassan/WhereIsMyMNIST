{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This notebook introduces the problem addressed in this paper:\n",
      "\n",
      " - localizating an object in a large image\n",
      " - foveation\n",
      " - action (saccade)\n",
      "       \n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "This notebook introduces the problem addressed in this paper:\n",
    "\n",
    " - localizating an object in a large image\n",
    " - foveation\n",
    " - action (saccade)\n",
    "       \n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig_width_pt = 525  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "fig_width_pt = 618  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "fig_width_pt = 1024  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "ppi = 72.27 # (constant) definition of the ppi = points per inch\n",
    "inches_per_pt = 1.0/ppi  # Convert pt to inches\n",
    "#inches_per_cm = 1./2.54\n",
    "figwidth = fig_width_pt*inches_per_pt  # width in inches\n",
    "phi = (np.sqrt(5) + 1. ) /2 # golden ratio is good for your eyes\n",
    "dpi_export = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-14\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().date().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:34:13.258190Z",
     "start_time": "2018-07-03T10:34:13.251661Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../data/' + datetime.datetime.now().date().isoformat()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    kwargs = dict(dataset_folder=dataset_folder, dataset_faces_folder=dataset_faces_folder, batch_size=batch_size, test_batch_size=test_batch_size, size_test_set=size_test_set, epochs=epochs,\n",
    "                do_adam=do_adam, lr=lr, momentum=momentum, no_cuda=no_cuda, num_processes=num_processes, seed=seed,\n",
    "                log_interval=log_interval, fullsize=fullsize, crop=crop, size=size, mean=mean, std=std,\n",
    "                conv1_dim=conv1_dim, conv1_kernel_size=conv1_kernel_size,\n",
    "                conv2_dim=conv2_dim, conv2_kernel_size=conv2_kernel_size,\n",
    "                conv1_bn_momentum=conv1_bn_momentum, conv2_bn_momentum=conv2_bn_momentum, dense_bn_momentum=dense_bn_momentum,\n",
    "                stride1=stride1, stride2=stride2, N_cv=N_cv,\n",
    "                dimension=dimension, verbose=verbose\n",
    "                )\n",
    "    # print(kwargs, locals())\n",
    "    offset_std = OFFSET_STD\n",
    "    offset_max = OFFSET_MAX\n",
    "# \n",
    "dataset_folder = 'dataset'\n",
    "dataset_faces_folder = 'dataset_faces'\n",
    "batch_size = 16\n",
    "no_cuda = False\n",
    "test_batch_size = 1\n",
    "size_test_set = .2\n",
    "\n",
    "seed = 42\n",
    "\n",
    "N_cv = 20\n",
    "# DEBUG\n",
    "# epochs = 2\n",
    "# N_cv = 2\n",
    "\n",
    "#ACTIVATION = F.relu\n",
    "ACTIVATION = torch.tanh\n",
    "#ACTIVATION = F.softmax\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if do_cuda else {'num_workers': 32}\n",
    "device = torch.device(\"cuda\" if do_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict(\n",
    "                        # MNIST\n",
    "                        w=28,\n",
    "                        minibatch_size = 100,  # quantity of examples that'll be processed\n",
    "                        train_batch_size=60000, # train\n",
    "                        test_batch_size=1000, \n",
    "                        noise_batch_size=1000, \n",
    "                        mean=0.1307, \n",
    "                        std=0.3081, \n",
    "                        # display\n",
    "                        N_pic = 128,\n",
    "                        offset_std = 30, #\n",
    "                        offset_max = 35, #\n",
    "                        noise=1., #0 #\n",
    "                        contrast=0.8, #1 #\n",
    "                        sf_0=0.2,\n",
    "                        B_sf=0.3,\n",
    "                        # foveation\n",
    "                        N_theta = 6,\n",
    "                        N_azimuth = 16,\n",
    "                        N_eccentricity = 10,\n",
    "                        N_phase = 2,\n",
    "                        N_X = 128,\n",
    "                        N_Y = 128,\n",
    "                        rho = 1.41,\n",
    "                        # network\n",
    "                        bias_deconv=True,\n",
    "                        p_dropout=.5,\n",
    "                        dim1=1000,\n",
    "                        dim2=1000,\n",
    "                        # training\n",
    "                        loss_func = torch.nn.BCEWithLogitsLoss(), #torch.nn.CrossEntropyLoss()\n",
    "                        lr = 1e-4, #1e-3  #0.05\n",
    "                        do_adam=True,\n",
    "                        epochs=40,\n",
    "                        bn1_bn_momentum=0.5,\n",
    "                        bn2_bn_momentum=0.5,\n",
    "                        momentum=0.1,    \n",
    "                        n_epochs=10,\n",
    "                        # simulation\n",
    "                        num_processes=1,\n",
    "                        no_cuda=True,\n",
    "                        log_interval=100, # period with which we report results for the loss\n",
    "                        verbose = 1,\n",
    "                        filename=filename,\n",
    "                        seed=2019,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    args.train_batch_size = 100\n",
    "    args.lr = 1e-2\n",
    "    #args.noise = .5\n",
    "    #args.contrast = .9\n",
    "    #args.p_dropout = 0.\n",
    "    args.epochs = 80\n",
    "    #args.test_batch_size = 20\n",
    "    #args.offset_std = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': 28, 'minibatch_size': 100, 'train_batch_size': 100, 'test_batch_size': 1000, 'noise_batch_size': 1000, 'mean': 0.1307, 'std': 0.3081, 'N_pic': 128, 'offset_std': 30, 'offset_max': 35, 'noise': 1.0, 'contrast': 0.8, 'sf_0': 0.2, 'B_sf': 0.3, 'N_theta': 6, 'N_azimuth': 16, 'N_eccentricity': 10, 'N_phase': 2, 'N_X': 128, 'N_Y': 128, 'rho': 1.41, 'bias_deconv': True, 'p_dropout': 0.5, 'dim1': 1000, 'dim2': 1000, 'loss_func': BCEWithLogitsLoss(), 'lr': 0.01, 'do_adam': True, 'epochs': 80, 'bn1_bn_momentum': 0.5, 'bn2_bn_momentum': 0.5, 'momentum': 0.1, 'n_epochs': 10, 'num_processes': 1, 'no_cuda': True, 'log_interval': 100, 'verbose': 1, 'filename': '../data/2019-03-14', 'seed': 2019}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retina import Display\n",
    "d = Display(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.loader_train.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from what import WhatNet\n",
    "model_path = \"../data/MNIST_cnn.pt\"\n",
    "What_model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import torch\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({'w': 28, 'minibatch_size': 100, 'train_batch_size': 100, 'test_batch_size': 1000, 'noise_batch_size': 1000, 'mean': 0.1307, 'std': 0.3081, 'N_pic': 128, 'offset_std': 30, 'offset_max': 35, 'noise': 1.0, 'contrast': 0.8, 'sf_0': 0.2, 'B_sf': 0.3, 'N_theta': 6, 'N_azimuth': 16, 'N_eccentricity': 10, 'N_phase': 2, 'N_X': 128, 'N_Y': 128, 'rho': 1.41, 'bias_deconv': True, 'p_dropout': 0.5, 'dim1': 1000, 'dim2': 1000, 'loss_func': torch.nn.BCEWithLogitsLoss(), 'lr': 0.01, 'do_adam': True, 'epochs': 80, 'bn1_bn_momentum': 0.5, 'bn2_bn_momentum': 0.5, 'momentum': 0.1, 'n_epochs': 10, 'num_processes': 1, 'no_cuda': True, 'log_interval': 100, 'verbose': 1, 'filename': '../data/2019-03-14_b', 'seed': 2019})\n",
    "\n",
    "from retina import Display, Retina\n",
    "from where import Where, WhereNet\n",
    "from what import WhatNet\n",
    "where = Where(args, Display(args), Retina(args))\n",
    "filename_train = args.filename + '_train.pt'\n",
    "where.train(filename_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:53:30.186131Z",
     "start_time": "2018-10-08T14:43:18.414Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:53:30.186131Z",
     "start_time": "2018-10-08T14:43:18.414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-14T15:33:32+01:00\n",
      "\n",
      "CPython 3.7.2\n",
      "IPython 7.3.0\n",
      "\n",
      "numpy 1.16.2\n",
      "matplotlib 3.0.2\n",
      "torch 1.0.1.post2\n",
      "\n",
      "compiler   : Clang 10.0.0 (clang-1000.11.45.5)\n",
      "system     : Darwin\n",
      "release    : 18.2.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 36\n",
      "interpreter: 64bit\n",
      "host name  : fortytwo\n",
      "Git hash   : d0db91898d99ee32fca27c07f35c4656d904eb17\n",
      "Git repo   : https://github.com/laurentperrinet/WhereIsMyMNIST\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "%watermark -i -h -m -v -p numpy,matplotlib,torch  -r -g -b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
