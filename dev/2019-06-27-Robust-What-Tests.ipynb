{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../figures\")\n",
    "\n",
    "from what import WhatShift, WhatBackground, WhatNet, WhatTrainer, What, train, test, MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 28,\n",
       " 'minibatch_size': 100,\n",
       " 'train_batch_size': 50000,\n",
       " 'test_batch_size': 10000,\n",
       " 'noise_batch_size': 1000,\n",
       " 'mean': 0.1307,\n",
       " 'std': 0.3081,\n",
       " 'N_pic': 128,\n",
       " 'offset_std': 30,\n",
       " 'offset_max': 34,\n",
       " 'noise': 1.0,\n",
       " 'contrast': None,\n",
       " 'sf_0': 0.1,\n",
       " 'B_sf': 0.1,\n",
       " 'N_theta': 6,\n",
       " 'N_azimuth': 24,\n",
       " 'N_eccentricity': 10,\n",
       " 'N_phase': 2,\n",
       " 'rho': 1.41,\n",
       " 'bias_deconv': True,\n",
       " 'p_dropout': 0.0,\n",
       " 'dim1': 1000,\n",
       " 'dim2': 1000,\n",
       " 'lr': 0.005,\n",
       " 'do_adam': True,\n",
       " 'bn1_bn_momentum': 0.5,\n",
       " 'bn2_bn_momentum': 0.5,\n",
       " 'momentum': 0.3,\n",
       " 'epochs': 60,\n",
       " 'num_processes': 1,\n",
       " 'no_cuda': True,\n",
       " 'log_interval': 100,\n",
       " 'verbose': 1,\n",
       " 'filename': '../data/2019-06-05',\n",
       " 'seed': 2019,\n",
       " 'N_cv': 10,\n",
       " 'do_compute': True,\n",
       " 'what_offset_std': 0,\n",
       " 'what_offset_max': 25}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import init\n",
    "args = init(filename='../data/2019-06-12') # pas de drop out!\n",
    "args.what_offset_std = 0\n",
    "args.what_offset_max = 25\n",
    "args.contrast = None\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_offset = None\n",
    "j_offset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "                               WhatShift(args,i_offset=i_offset, j_offset=j_offset),\n",
    "                               WhatBackground(contrast = args.contrast,\n",
    "                                              noise=args.noise, \n",
    "                                              sf_0=args.sf_0, \n",
    "                                              B_sf=args.B_sf),\n",
    "                               transforms.ToTensor(),\n",
    "                               #transforms.Normalize((args.mean,), (args.std,))\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MNIST('../data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                         batch_size=args.minibatch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = MNIST('../data',\n",
    "                        train=False,\n",
    "                        download=True,\n",
    "                        transform=transform,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                         batch_size=args.minibatch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "plt.imshow(data[i,:,:].detach().numpy().reshape((28, 28)))\n",
    "plt.title('label : '+str(label[i].item()))\n",
    "plt.show()\n",
    "h = plt.hist(data[i,:,:].detach().numpy().flatten(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = WhatNet().to(device)\n",
    "loss_func = F.nll_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, loss_func, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WhatTrainer Class test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatTrainer = WhatTrainer(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for epoch in range(2, args.epochs + 1):\n",
    "        whatTrainer.train(epoch)\n",
    "        whatTrainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What class test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    args.epochs = 1\n",
    "    args.save_model = True\n",
    "    what = What(args=args, force= True)\n",
    "    acc = what.trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script d'entraînement de /MNIST_cnn_0.1_0.1_1.0_None.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En cours : std = 0\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 2.303123\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.381616\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.734503\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.624045\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.463076\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.656665\n",
      "\n",
      "Test set: Average loss: 0.0047, Accuracy: 8504/10000 (85%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.469808\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.436127\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.466370\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.377823\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.390392\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.471371\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 8691/10000 (87%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.461572\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.292807\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.234437\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.603370\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.329893\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.237097\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 8911/10000 (89%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.259177\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.271113\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.241010\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.268436\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.273098\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.208688\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 9094/10000 (91%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.334003\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.333861\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.281651\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.211019\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.339768\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.348709\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 9113/10000 (91%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_0.pt\n",
      "En cours : std = 1\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.312636\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.441187\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.361438\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.411588\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.558582\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.297533\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 8857/10000 (89%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.227193\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.224215\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.221038\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.328223\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.529605\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.201495\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 8802/10000 (88%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.381771\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.388221\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.455344\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.365933\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.332361\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.285615\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8818/10000 (88%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.338266\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.315392\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.375426\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.249364\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.251396\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.523147\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 8946/10000 (89%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.294653\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.329284\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.127036\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.229039\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.303844\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.270889\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 8979/10000 (90%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_1.pt\n",
      "\n",
      "\n",
      "En cours : std = 2\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.929408\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.386383\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.726164\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.377928\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.589562\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.579058\n",
      "\n",
      "Test set: Average loss: 0.0050, Accuracy: 8423/10000 (84%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.394507\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.351426\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.279015\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.556197\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.510716\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.521156\n",
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 8095/10000 (81%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.514634\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.358024\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.512668\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.412637\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.391107\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.544793\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 8585/10000 (86%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.452218\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.382550\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.228986\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.609100\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.446693\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.389756\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 8695/10000 (87%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.277523\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.296707\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.364720\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.397276\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.494686\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.329755\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 8584/10000 (86%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_2.pt\n",
      "\n",
      "\n",
      "En cours : std = 3\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.473649\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.588929\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.933391\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.749726\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.500435\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.611271\n",
      "\n",
      "Test set: Average loss: 0.0064, Accuracy: 7964/10000 (80%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.647690\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.721072\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.644766\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.525849\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.495389\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.728507\n",
      "\n",
      "Test set: Average loss: 0.0059, Accuracy: 8101/10000 (81%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.597083\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.538951\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.615679\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.503538\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.586510\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.566133\n",
      "\n",
      "Test set: Average loss: 0.0063, Accuracy: 8004/10000 (80%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.671763\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.620369\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.670231\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.635016\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.414500\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.330817\n",
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 8138/10000 (81%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.536696\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.501081\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.649269\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.554569\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.546784\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.438129\n",
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 8130/10000 (81%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_3.pt\n",
      "\n",
      "\n",
      "En cours : std = 4\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.115495\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.745389\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.639611\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.695136\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.763922\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.761193\n",
      "\n",
      "Test set: Average loss: 0.0068, Accuracy: 7794/10000 (78%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.710789\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.652959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.698627\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.649966\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.786301\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.698346\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 7811/10000 (78%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.681561\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.581826\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.762066\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.710412\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.592958\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.598626\n",
      "\n",
      "Test set: Average loss: 0.0065, Accuracy: 7864/10000 (79%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.671918\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.527576\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.579742\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.619586\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.717843\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.546705\n",
      "\n",
      "Test set: Average loss: 0.0068, Accuracy: 7833/10000 (78%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.530271\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.545807\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.807469\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.629814\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.563371\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.511819\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 7869/10000 (79%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_4.pt\n",
      "\n",
      "\n",
      "En cours : std = 5\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.679495\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.720466\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.187282\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.984183\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.908075\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.934614\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7217/10000 (72%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.879693\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.749600\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.612235\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.248224\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.647076\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.985363\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7260/10000 (73%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.795953\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.611722\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.848346\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.123507\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.592002\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.667332\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7224/10000 (72%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.650709\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.818516\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.680969\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.870227\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.776238\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.895298\n",
      "\n",
      "Test set: Average loss: 0.0082, Accuracy: 7245/10000 (72%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.703554\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.600555\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.605990\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.774528\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.800805\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.867554\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7385/10000 (74%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_5.pt\n",
      "\n",
      "\n",
      "En cours : std = 6\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.068823\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.995581\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.864339\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.872211\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.020220\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.132935\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 6775/10000 (68%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.974716\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.119499\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.070816\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.803401\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.944862\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.080460\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 6670/10000 (67%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.879935\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.055263\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.940095\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.081567\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.061488\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.882415\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6686/10000 (67%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.121940\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.821557\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.959279\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.013941\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.019964\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.884918\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 6766/10000 (68%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.058221\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.027944\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.705296\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.880865\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.946672\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.866925\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 6817/10000 (68%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_6.pt\n",
      "\n",
      "\n",
      "En cours : std = 7\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.244274\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.191392\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.097293\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.201443\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.938657\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.008360\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6091/10000 (61%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.217463\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.055303\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.016752\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.854331\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.144658\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.964333\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6184/10000 (62%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.018958\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.096599\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.199873\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.254207\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.999294\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.221282\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6082/10000 (61%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.182934\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.130810\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.119800\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.926806\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.097642\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.175958\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6316/10000 (63%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.828861\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.961237\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.898748\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.176032\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.058505\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.126268\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6382/10000 (64%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_7.pt\n",
      "\n",
      "\n",
      "En cours : std = 8\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.176849\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.051162\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.099637\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.300225\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.128222\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.222165\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5461/10000 (55%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.131097\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.283435\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.090860\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.174618\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.309312\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.415445\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5658/10000 (57%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.210820\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.176414\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.250621\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.211372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.345635\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.989938\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 5834/10000 (58%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.217290\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.093817\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.182748\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.200386\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.083603\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.081542\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5837/10000 (58%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.098238\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.124308\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.005592\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.161074\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.177522\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.165342\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5790/10000 (58%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_8.pt\n",
      "\n",
      "\n",
      "En cours : std = 9\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.315470\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.437915\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.396007\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.295781\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.542966\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.435185\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5177/10000 (52%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.487473\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.552813\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.340303\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.384779\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.455083\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.131116\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5227/10000 (52%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.414629\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.315022\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.445641\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.128876\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.347348\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.354184\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5243/10000 (52%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.246637\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.349854\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.235762\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.296728\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.226103\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.241166\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5256/10000 (53%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.160609\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.325584\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.069024\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.081534\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.260938\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.346383\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5378/10000 (54%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_9.pt\n",
      "\n",
      "\n",
      "En cours : std = 10\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.368807\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.268888\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.647915\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.655937\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.357051\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.719678\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4854/10000 (49%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.345180\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.411962\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.179501\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.504849\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.239408\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.458682\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4885/10000 (49%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.481202\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.639019\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.382151\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.354207\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.375448\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.337749\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 4970/10000 (50%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.286563\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.242594\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.468131\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.421991\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.357165\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.342090\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4871/10000 (49%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.189479\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.276910\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.039308\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.136014\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.394403\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.362129\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4983/10000 (50%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_10.pt\n",
      "\n",
      "\n",
      "En cours : std = 11\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.401965\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.602169\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.584799\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.627210\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.640388\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.354967\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4545/10000 (45%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.461590\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.600417\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.395689\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.633005\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.473134\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.417768\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4587/10000 (46%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.653854\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.436107\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.370885\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.566237\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.504853\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.608987\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4586/10000 (46%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.279717\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.430519\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.512873\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.350770\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.382082\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.565535\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4548/10000 (45%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.332947\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.535577\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.326251\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.648102\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.437324\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.673749\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4605/10000 (46%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_11.pt\n",
      "\n",
      "\n",
      "En cours : std = 12\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.389198\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.642214\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.501571\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.759366\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.726386\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.565834\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4275/10000 (43%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.544581\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.538432\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.723546\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.719536\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.760102\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.476129\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4137/10000 (41%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.459393\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.571811\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.675708\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.436951\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.540393\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.722281\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4222/10000 (42%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.463720\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.437992\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.530794\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.641732\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.548444\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.575829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4116/10000 (41%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.555918\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.386639\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.530812\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.444633\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.623733\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.570059\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4141/10000 (41%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_12.pt\n",
      "\n",
      "\n",
      "En cours : std = 13\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.512070\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.529256\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.650845\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.854129\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.667249\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.822106\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3910/10000 (39%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.699424\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.493055\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.599973\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.715114\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.699478\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.704473\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3828/10000 (38%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.642483\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.612723\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.687638\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.555240\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.691438\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.456524\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3871/10000 (39%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.672281\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.567452\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.541596\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.710027\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.354626\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.612627\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3860/10000 (39%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.657383\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.642102\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.707947\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.511125\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.647224\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.550573\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 3887/10000 (39%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_13.pt\n",
      "\n",
      "\n",
      "En cours : std = 14\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.598205\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.802964\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.644032\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.718659\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.594586\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.865395\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3472/10000 (35%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.728550\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.731018\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.818089\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.660729\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.673514\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.753412\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3565/10000 (36%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.725161\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.716435\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.702582\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.620948\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.672522\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.613408\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3556/10000 (36%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.521274\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.573237\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.584350\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.831052\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.585849\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.831701\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3544/10000 (35%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.700315\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.585843\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.628172\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.669149\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.666797\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 2.014427\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3507/10000 (35%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_14.pt\n",
      "\n",
      "\n",
      "En cours : std = 15\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.952878\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.917578\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.891925\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.800862\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.782385\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.893296\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3420/10000 (34%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.760955\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.832736\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.797030\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.625488\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.766586\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.829063\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3317/10000 (33%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.780395\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.733958\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.659308\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.709494\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.749938\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.766607\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3341/10000 (33%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.644590\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.679408\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.764095\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.658901\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.777425\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.740527\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3350/10000 (34%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.595027\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.695722\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.797914\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.961341\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.748159\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.973422\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3367/10000 (34%)\n",
      "\n",
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_15.pt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Duree d'execution : 1:44:27.003422\n"
     ]
    }
   ],
   "source": [
    "if False :\n",
    "    import sys\n",
    "    import datetime\n",
    "\n",
    "    #sys.path.append(\"../figures\")\n",
    "    #from robust_what import WhatShift, WhatBackground, WhatNet, WhatTrainer, What, train, test, MNIST\n",
    "    #from main import init\n",
    "\n",
    "    #args = init(filename='../data/2019-06-12')\n",
    "\n",
    "    args.epochs = 5  # 10 plus tard\n",
    "    args.save_model = True\n",
    "\n",
    "    debut = datetime.datetime.now()\n",
    "    date = str(debut)\n",
    "\n",
    "    liste_std = [i for i in range(0, 16)]  # pas de 1 de std\n",
    "\n",
    "    args.what_offset_max = 25\n",
    "    args.do_adam = True #'adam'\n",
    "    args.what_offset_std = liste_std[0]\n",
    "    print(\"En cours : std = 0\\n\")\n",
    "    what = What(args, force=True, seed=0, robust=True)\n",
    "\n",
    "    seed = 1\n",
    "    for std in liste_std[1:]:\n",
    "        print(\"En cours : std = \" + str(std) + \"\\n\")\n",
    "\n",
    "        args.what_offset_std = std\n",
    "        what_model = what.model\n",
    "        what = What(args, model=what_model, force=True, seed=seed, robust=True)\n",
    "        seed += 1\n",
    "        print(\"\\n\")\n",
    "        if args.contrast is not None:\n",
    "            suffix = \"robust_{}_{}_{}_{}_{}\".format(args.sf_0, args.B_sf, args.noise, args.contrast, std)\n",
    "        else:\n",
    "            suffix = \"robust_{}_{}_{}_all_{}\".format(args.sf_0, args.B_sf, args.noise, std)\n",
    "        what_model_path = \"../data/MNIST_cnn_{}.pt\".format(suffix)\n",
    "        torch.save(what_model, what_model_path)\n",
    "\n",
    "    fin = datetime.datetime.now()\n",
    "    print(\"\\n\\nDuree d'execution : \" + str(fin - debut))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(args.contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    what_model = what.model\n",
    "    if args.contrast is not None:\n",
    "        suffix = \"robust_{}_{}_{}_{}_{}\".format(args.sf_0, args.B_sf, args.noise, args.contrast, std)\n",
    "    else:\n",
    "        suffix = \"robust_{}_{}_{}_all_{}\".format(args.sf_0, args.B_sf, args.noise, std)\n",
    "    what_model_path = \"../data/MNIST_cnn_{}.pt\".format(suffix)\n",
    "    torch.save(what_model, what_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3367/10000 (34%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = what.trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/MNIST_cnn_robust_0.1_0.1_1.0_None_15.pt\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 8036/10000 (80%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std = 15\n",
    "suffix = \"robust_{}_{}_{}_{}_{}\".format(args.sf_0, args.B_sf, args.noise, args.contrast, std)\n",
    "model_path = \"../data/MNIST_cnn_{}.pt\".format(suffix)\n",
    "print(model_path)\n",
    "what_model = torch.load(model_path)\n",
    "if True:\n",
    "    args.what_offset_std = 0\n",
    "    seed = 1\n",
    "    what = What(args, model=what_model, seed=seed)\n",
    "    acc = what.trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-27 -25 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1007/10000 (10%)\n",
      "\n",
      "-27 -20 0.1007\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -18 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 -17 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -16 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-27 -15 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-27 -14 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 -13 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-27 -12 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-27 -11 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 -10 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-27 -9 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1002/10000 (10%)\n",
      "\n",
      "-27 -8 0.1002\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-27 -7 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-27 -6 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1005/10000 (10%)\n",
      "\n",
      "-27 -5 0.1005\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1012/10000 (10%)\n",
      "\n",
      "-27 -4 0.1012\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1002/10000 (10%)\n",
      "\n",
      "-27 -3 0.1002\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-27 -2 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 977/10000 (10%)\n",
      "\n",
      "-27 -1 0.0977\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 0 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 1 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-27 2 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-27 3 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 4 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-27 5 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-27 6 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 7 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-27 8 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1002/10000 (10%)\n",
      "\n",
      "-27 9 0.1002\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 10 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-27 11 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-27 12 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-27 13 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 14 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 15 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-26 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-26 -26 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 -22 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 -21 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-26 -20 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-26 -19 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-26 -18 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-26 -17 0.116\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 879/10000 (9%)\n",
      "\n",
      "-26 -16 0.0879\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-26 -15 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-26 -14 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "-26 -13 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "-26 -12 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1189/10000 (12%)\n",
      "\n",
      "-26 -11 0.1189\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-26 -10 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "-26 -9 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1035/10000 (10%)\n",
      "\n",
      "-26 -8 0.1035\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1033/10000 (10%)\n",
      "\n",
      "-26 -7 0.1033\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "-26 -6 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "-26 -5 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1190/10000 (12%)\n",
      "\n",
      "-26 -4 0.119\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-26 -3 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-26 -2 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 434/10000 (4%)\n",
      "\n",
      "-26 -1 0.0434\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "-26 0 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1016/10000 (10%)\n",
      "\n",
      "-26 1 0.1016\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "-26 2 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "-26 3 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "-26 4 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1193/10000 (12%)\n",
      "\n",
      "-26 5 0.1193\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1057/10000 (11%)\n",
      "\n",
      "-26 6 0.1057\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "-26 7 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-26 8 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1191/10000 (12%)\n",
      "\n",
      "-26 9 0.1191\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1183/10000 (12%)\n",
      "\n",
      "-26 10 0.1183\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "-26 11 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "-26 12 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-26 13 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1176/10000 (12%)\n",
      "\n",
      "-26 14 0.1176\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-26 15 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 902/10000 (9%)\n",
      "\n",
      "-26 16 0.0902\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-26 17 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-26 18 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1012/10000 (10%)\n",
      "\n",
      "-26 19 0.1012\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-26 20 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1013/10000 (10%)\n",
      "\n",
      "-26 21 0.1013\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1007/10000 (10%)\n",
      "\n",
      "-26 22 0.1007\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 958/10000 (10%)\n",
      "\n",
      "-25 -27 0.0958\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-25 -24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-25 -23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-25 -22 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-25 -21 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-25 -20 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "-25 -19 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-25 -18 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "-25 -17 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1193/10000 (12%)\n",
      "\n",
      "-25 -16 0.1193\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1223/10000 (12%)\n",
      "\n",
      "-25 -15 0.1223\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1214/10000 (12%)\n",
      "\n",
      "-25 -14 0.1214\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 356/10000 (4%)\n",
      "\n",
      "-25 -13 0.0356\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 917/10000 (9%)\n",
      "\n",
      "-25 -12 0.0917\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1243/10000 (12%)\n",
      "\n",
      "-25 -11 0.1243\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1269/10000 (13%)\n",
      "\n",
      "-25 -10 0.1269\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1269/10000 (13%)\n",
      "\n",
      "-25 -9 0.1269\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1273/10000 (13%)\n",
      "\n",
      "-25 -8 0.1273\n",
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 1273/10000 (13%)\n",
      "\n",
      "-25 -7 0.1273\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 247/10000 (2%)\n",
      "\n",
      "-25 -6 0.0247\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1255/10000 (13%)\n",
      "\n",
      "-25 -5 0.1255\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 250/10000 (2%)\n",
      "\n",
      "-25 -4 0.025\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1276/10000 (13%)\n",
      "\n",
      "-25 -3 0.1276\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1262/10000 (13%)\n",
      "\n",
      "-25 -2 0.1262\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "-25 -1 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 248/10000 (2%)\n",
      "\n",
      "-25 0 0.0248\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1270/10000 (13%)\n",
      "\n",
      "-25 1 0.127\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 251/10000 (3%)\n",
      "\n",
      "-25 2 0.0251\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "-25 3 0.1268\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "-25 4 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 259/10000 (3%)\n",
      "\n",
      "-25 5 0.0259\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 257/10000 (3%)\n",
      "\n",
      "-25 6 0.0257\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1275/10000 (13%)\n",
      "\n",
      "-25 7 0.1275\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1267/10000 (13%)\n",
      "\n",
      "-25 8 0.1267\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1275/10000 (13%)\n",
      "\n",
      "-25 9 0.1275\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1246/10000 (12%)\n",
      "\n",
      "-25 10 0.1246\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "-25 11 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1256/10000 (13%)\n",
      "\n",
      "-25 12 0.1256\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1232/10000 (12%)\n",
      "\n",
      "-25 13 0.1232\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 307/10000 (3%)\n",
      "\n",
      "-25 14 0.0307\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 672/10000 (7%)\n",
      "\n",
      "-25 15 0.0672\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "-25 16 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1179/10000 (12%)\n",
      "\n",
      "-25 17 0.1179\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 924/10000 (9%)\n",
      "\n",
      "-25 18 0.0924\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-25 19 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 907/10000 (9%)\n",
      "\n",
      "-25 20 0.0907\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 984/10000 (10%)\n",
      "\n",
      "-25 21 0.0984\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-25 22 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-25 27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 982/10000 (10%)\n",
      "\n",
      "-24 -27 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-24 -23 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-24 -22 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-24 -21 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 929/10000 (9%)\n",
      "\n",
      "-24 -20 0.0929\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-24 -19 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "-24 -18 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "-24 -17 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1221/10000 (12%)\n",
      "\n",
      "-24 -16 0.1221\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1193/10000 (12%)\n",
      "\n",
      "-24 -15 0.1193\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1230/10000 (12%)\n",
      "\n",
      "-24 -14 0.123\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "-24 -13 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1233/10000 (12%)\n",
      "\n",
      "-24 -12 0.1233\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1216/10000 (12%)\n",
      "\n",
      "-24 -11 0.1216\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1200/10000 (12%)\n",
      "\n",
      "-24 -10 0.12\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1213/10000 (12%)\n",
      "\n",
      "-24 -9 0.1213\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1217/10000 (12%)\n",
      "\n",
      "-24 -8 0.1217\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1197/10000 (12%)\n",
      "\n",
      "-24 -7 0.1197\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "-24 -6 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 489/10000 (5%)\n",
      "\n",
      "-24 -5 0.0489\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1247/10000 (12%)\n",
      "\n",
      "-24 -4 0.1247\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1239/10000 (12%)\n",
      "\n",
      "-24 -3 0.1239\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 720/10000 (7%)\n",
      "\n",
      "-24 -2 0.072\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1242/10000 (12%)\n",
      "\n",
      "-24 -1 0.1242\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "-24 0 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1312/10000 (13%)\n",
      "\n",
      "-24 1 0.1312\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1281/10000 (13%)\n",
      "\n",
      "-24 2 0.1281\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 825/10000 (8%)\n",
      "\n",
      "-24 3 0.0825\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1286/10000 (13%)\n",
      "\n",
      "-24 4 0.1286\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1272/10000 (13%)\n",
      "\n",
      "-24 5 0.1272\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1292/10000 (13%)\n",
      "\n",
      "-24 6 0.1292\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1068/10000 (11%)\n",
      "\n",
      "-24 7 0.1068\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 541/10000 (5%)\n",
      "\n",
      "-24 8 0.0541\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1248/10000 (12%)\n",
      "\n",
      "-24 9 0.1248\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1448/10000 (14%)\n",
      "\n",
      "-24 10 0.1448\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1234/10000 (12%)\n",
      "\n",
      "-24 11 0.1234\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1230/10000 (12%)\n",
      "\n",
      "-24 12 0.123\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1172/10000 (12%)\n",
      "\n",
      "-24 13 0.1172\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "-24 14 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-24 15 0.116\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "-24 16 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "-24 17 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-24 18 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-24 19 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 893/10000 (9%)\n",
      "\n",
      "-24 20 0.0893\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-24 21 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-24 22 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-24 23 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-24 24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 982/10000 (10%)\n",
      "\n",
      "-24 25 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 958/10000 (10%)\n",
      "\n",
      "-24 27 0.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-23 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-23 -24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-23 -23 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-23 -22 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 956/10000 (10%)\n",
      "\n",
      "-23 -21 0.0956\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-23 -20 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 869/10000 (9%)\n",
      "\n",
      "-23 -19 0.0869\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "-23 -18 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1193/10000 (12%)\n",
      "\n",
      "-23 -17 0.1193\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-23 -16 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1176/10000 (12%)\n",
      "\n",
      "-23 -15 0.1176\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "-23 -14 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-23 -13 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1130/10000 (11%)\n",
      "\n",
      "-23 -12 0.113\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "-23 -11 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1101/10000 (11%)\n",
      "\n",
      "-23 -10 0.1101\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-23 -9 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1126/10000 (11%)\n",
      "\n",
      "-23 -8 0.1126\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1122/10000 (11%)\n",
      "\n",
      "-23 -7 0.1122\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-23 -6 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1104/10000 (11%)\n",
      "\n",
      "-23 -5 0.1104\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-23 -4 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-23 -3 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "-23 -2 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "-23 -1 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1270/10000 (13%)\n",
      "\n",
      "-23 0 0.127\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "-23 1 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "-23 2 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1196/10000 (12%)\n",
      "\n",
      "-23 3 0.1196\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1204/10000 (12%)\n",
      "\n",
      "-23 4 0.1204\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "-23 5 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1190/10000 (12%)\n",
      "\n",
      "-23 6 0.119\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1223/10000 (12%)\n",
      "\n",
      "-23 7 0.1223\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1183/10000 (12%)\n",
      "\n",
      "-23 8 0.1183\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1377/10000 (14%)\n",
      "\n",
      "-23 9 0.1377\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1236/10000 (12%)\n",
      "\n",
      "-23 10 0.1236\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1121/10000 (11%)\n",
      "\n",
      "-23 11 0.1121\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1126/10000 (11%)\n",
      "\n",
      "-23 12 0.1126\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1088/10000 (11%)\n",
      "\n",
      "-23 13 0.1088\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1105/10000 (11%)\n",
      "\n",
      "-23 14 0.1105\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1091/10000 (11%)\n",
      "\n",
      "-23 15 0.1091\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1118/10000 (11%)\n",
      "\n",
      "-23 16 0.1118\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-23 17 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-23 18 0.114\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 672/10000 (7%)\n",
      "\n",
      "-23 19 0.0672\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-23 20 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1129/10000 (11%)\n",
      "\n",
      "-23 21 0.1129\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-23 22 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 989/10000 (10%)\n",
      "\n",
      "-23 23 0.0989\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-23 24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-23 26 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-22 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-22 -26 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-22 -24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-22 -22 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-22 -21 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-22 -20 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "-22 -19 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 825/10000 (8%)\n",
      "\n",
      "-22 -18 0.0825\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1212/10000 (12%)\n",
      "\n",
      "-22 -17 0.1212\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "-22 -16 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "-22 -15 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 825/10000 (8%)\n",
      "\n",
      "-22 -14 0.0825\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1204/10000 (12%)\n",
      "\n",
      "-22 -13 0.1204\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1191/10000 (12%)\n",
      "\n",
      "-22 -12 0.1191\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1172/10000 (12%)\n",
      "\n",
      "-22 -11 0.1172\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "-22 -10 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1226/10000 (12%)\n",
      "\n",
      "-22 -9 0.1226\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1237/10000 (12%)\n",
      "\n",
      "-22 -8 0.1237\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1266/10000 (13%)\n",
      "\n",
      "-22 -7 0.1266\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1293/10000 (13%)\n",
      "\n",
      "-22 -6 0.1293\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1321/10000 (13%)\n",
      "\n",
      "-22 -5 0.1321\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1310/10000 (13%)\n",
      "\n",
      "-22 -4 0.131\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1371/10000 (14%)\n",
      "\n",
      "-22 -3 0.1371\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1341/10000 (13%)\n",
      "\n",
      "-22 -2 0.1341\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1354/10000 (14%)\n",
      "\n",
      "-22 -1 0.1354\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1367/10000 (14%)\n",
      "\n",
      "-22 0 0.1367\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1353/10000 (14%)\n",
      "\n",
      "-22 1 0.1353\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1334/10000 (13%)\n",
      "\n",
      "-22 2 0.1334\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1376/10000 (14%)\n",
      "\n",
      "-22 3 0.1376\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1333/10000 (13%)\n",
      "\n",
      "-22 4 0.1333\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1305/10000 (13%)\n",
      "\n",
      "-22 5 0.1305\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1293/10000 (13%)\n",
      "\n",
      "-22 6 0.1293\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1258/10000 (13%)\n",
      "\n",
      "-22 7 0.1258\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1321/10000 (13%)\n",
      "\n",
      "-22 8 0.1321\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1267/10000 (13%)\n",
      "\n",
      "-22 9 0.1267\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1249/10000 (12%)\n",
      "\n",
      "-22 10 0.1249\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "-22 11 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1200/10000 (12%)\n",
      "\n",
      "-22 12 0.12\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-22 13 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1432/10000 (14%)\n",
      "\n",
      "-22 14 0.1432\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1127/10000 (11%)\n",
      "\n",
      "-22 15 0.1127\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1132/10000 (11%)\n",
      "\n",
      "-22 16 0.1132\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-22 17 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-22 18 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-22 19 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-22 20 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-22 21 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1027/10000 (10%)\n",
      "\n",
      "-22 22 0.1027\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 882/10000 (9%)\n",
      "\n",
      "-22 23 0.0882\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-22 24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-22 27 0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-21 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 981/10000 (10%)\n",
      "\n",
      "-21 -24 0.0981\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 968/10000 (10%)\n",
      "\n",
      "-21 -23 0.0968\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 987/10000 (10%)\n",
      "\n",
      "-21 -22 0.0987\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 878/10000 (9%)\n",
      "\n",
      "-21 -21 0.0878\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "-21 -20 0.117\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "-21 -19 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1198/10000 (12%)\n",
      "\n",
      "-21 -18 0.1198\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1234/10000 (12%)\n",
      "\n",
      "-21 -17 0.1234\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1251/10000 (13%)\n",
      "\n",
      "-21 -16 0.1251\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1202/10000 (12%)\n",
      "\n",
      "-21 -15 0.1202\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "-21 -14 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1107/10000 (11%)\n",
      "\n",
      "-21 -13 0.1107\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1361/10000 (14%)\n",
      "\n",
      "-21 -12 0.1361\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1367/10000 (14%)\n",
      "\n",
      "-21 -11 0.1367\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1370/10000 (14%)\n",
      "\n",
      "-21 -10 0.137\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1420/10000 (14%)\n",
      "\n",
      "-21 -9 0.142\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1435/10000 (14%)\n",
      "\n",
      "-21 -8 0.1435\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1420/10000 (14%)\n",
      "\n",
      "-21 -7 0.142\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1514/10000 (15%)\n",
      "\n",
      "-21 -6 0.1514\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1477/10000 (15%)\n",
      "\n",
      "-21 -5 0.1477\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1498/10000 (15%)\n",
      "\n",
      "-21 -4 0.1498\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1530/10000 (15%)\n",
      "\n",
      "-21 -3 0.153\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1556/10000 (16%)\n",
      "\n",
      "-21 -2 0.1556\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1581/10000 (16%)\n",
      "\n",
      "-21 -1 0.1581\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1669/10000 (17%)\n",
      "\n",
      "-21 0 0.1669\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1651/10000 (17%)\n",
      "\n",
      "-21 1 0.1651\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1647/10000 (16%)\n",
      "\n",
      "-21 2 0.1647\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1630/10000 (16%)\n",
      "\n",
      "-21 3 0.163\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1605/10000 (16%)\n",
      "\n",
      "-21 4 0.1605\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1540/10000 (15%)\n",
      "\n",
      "-21 5 0.154\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1529/10000 (15%)\n",
      "\n",
      "-21 6 0.1529\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1555/10000 (16%)\n",
      "\n",
      "-21 7 0.1555\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1474/10000 (15%)\n",
      "\n",
      "-21 8 0.1474\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1486/10000 (15%)\n",
      "\n",
      "-21 9 0.1486\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1377/10000 (14%)\n",
      "\n",
      "-21 10 0.1377\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1346/10000 (13%)\n",
      "\n",
      "-21 11 0.1346\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "-21 12 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1220/10000 (12%)\n",
      "\n",
      "-21 13 0.122\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-21 14 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-21 15 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-21 16 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "-21 17 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 436/10000 (4%)\n",
      "\n",
      "-21 18 0.0436\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-21 19 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 830/10000 (8%)\n",
      "\n",
      "-21 20 0.083\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1065/10000 (11%)\n",
      "\n",
      "-21 21 0.1065\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-21 22 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-21 23 0.114\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 979/10000 (10%)\n",
      "\n",
      "-21 24 0.0979\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-20 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "-20 -26 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-20 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1001/10000 (10%)\n",
      "\n",
      "-20 -24 0.1001\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 972/10000 (10%)\n",
      "\n",
      "-20 -23 0.0972\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-20 -22 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "-20 -21 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "-20 -20 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1217/10000 (12%)\n",
      "\n",
      "-20 -19 0.1217\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1262/10000 (13%)\n",
      "\n",
      "-20 -18 0.1262\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 579/10000 (6%)\n",
      "\n",
      "-20 -17 0.0579\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1317/10000 (13%)\n",
      "\n",
      "-20 -16 0.1317\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1348/10000 (13%)\n",
      "\n",
      "-20 -15 0.1348\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1400/10000 (14%)\n",
      "\n",
      "-20 -14 0.14\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1453/10000 (15%)\n",
      "\n",
      "-20 -13 0.1453\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1511/10000 (15%)\n",
      "\n",
      "-20 -12 0.1511\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1493/10000 (15%)\n",
      "\n",
      "-20 -11 0.1493\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1606/10000 (16%)\n",
      "\n",
      "-20 -10 0.1606\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1671/10000 (17%)\n",
      "\n",
      "-20 -9 0.1671\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1688/10000 (17%)\n",
      "\n",
      "-20 -8 0.1688\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1677/10000 (17%)\n",
      "\n",
      "-20 -7 0.1677\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1693/10000 (17%)\n",
      "\n",
      "-20 -6 0.1693\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1777/10000 (18%)\n",
      "\n",
      "-20 -5 0.1777\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 1785/10000 (18%)\n",
      "\n",
      "-20 -4 0.1785\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1830/10000 (18%)\n",
      "\n",
      "-20 -3 0.183\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1865/10000 (19%)\n",
      "\n",
      "-20 -2 0.1865\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1883/10000 (19%)\n",
      "\n",
      "-20 -1 0.1883\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 1932/10000 (19%)\n",
      "\n",
      "-20 0 0.1932\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1833/10000 (18%)\n",
      "\n",
      "-20 1 0.1833\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1791/10000 (18%)\n",
      "\n",
      "-20 2 0.1791\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1843/10000 (18%)\n",
      "\n",
      "-20 3 0.1843\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1877/10000 (19%)\n",
      "\n",
      "-20 4 0.1877\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1838/10000 (18%)\n",
      "\n",
      "-20 5 0.1838\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1865/10000 (19%)\n",
      "\n",
      "-20 6 0.1865\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1817/10000 (18%)\n",
      "\n",
      "-20 7 0.1817\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1739/10000 (17%)\n",
      "\n",
      "-20 8 0.1739\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1641/10000 (16%)\n",
      "\n",
      "-20 9 0.1641\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1550/10000 (16%)\n",
      "\n",
      "-20 10 0.155\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1531/10000 (15%)\n",
      "\n",
      "-20 11 0.1531\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1392/10000 (14%)\n",
      "\n",
      "-20 12 0.1392\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1311/10000 (13%)\n",
      "\n",
      "-20 13 0.1311\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "-20 14 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1217/10000 (12%)\n",
      "\n",
      "-20 15 0.1217\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "-20 16 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1226/10000 (12%)\n",
      "\n",
      "-20 17 0.1226\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "-20 18 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "-20 19 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1191/10000 (12%)\n",
      "\n",
      "-20 20 0.1191\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1080/10000 (11%)\n",
      "\n",
      "-20 21 0.108\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-20 22 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-20 23 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-20 24 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-20 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-20 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 958/10000 (10%)\n",
      "\n",
      "-20 27 0.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-19 -24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-19 -23 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "-19 -22 0.1\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1174/10000 (12%)\n",
      "\n",
      "-19 -21 0.1174\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 951/10000 (10%)\n",
      "\n",
      "-19 -20 0.0951\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1246/10000 (12%)\n",
      "\n",
      "-19 -19 0.1246\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1283/10000 (13%)\n",
      "\n",
      "-19 -18 0.1283\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1320/10000 (13%)\n",
      "\n",
      "-19 -17 0.132\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1364/10000 (14%)\n",
      "\n",
      "-19 -16 0.1364\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1441/10000 (14%)\n",
      "\n",
      "-19 -15 0.1441\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1434/10000 (14%)\n",
      "\n",
      "-19 -14 0.1434\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1523/10000 (15%)\n",
      "\n",
      "-19 -13 0.1523\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1597/10000 (16%)\n",
      "\n",
      "-19 -12 0.1597\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1698/10000 (17%)\n",
      "\n",
      "-19 -11 0.1698\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1732/10000 (17%)\n",
      "\n",
      "-19 -10 0.1732\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1845/10000 (18%)\n",
      "\n",
      "-19 -9 0.1845\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1845/10000 (18%)\n",
      "\n",
      "-19 -8 0.1845\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 1886/10000 (19%)\n",
      "\n",
      "-19 -7 0.1886\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 1937/10000 (19%)\n",
      "\n",
      "-19 -6 0.1937\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 1957/10000 (20%)\n",
      "\n",
      "-19 -5 0.1957\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2039/10000 (20%)\n",
      "\n",
      "-19 -4 0.2039\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2126/10000 (21%)\n",
      "\n",
      "-19 -3 0.2126\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2140/10000 (21%)\n",
      "\n",
      "-19 -2 0.214\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2157/10000 (22%)\n",
      "\n",
      "-19 -1 0.2157\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2113/10000 (21%)\n",
      "\n",
      "-19 0 0.2113\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 1976/10000 (20%)\n",
      "\n",
      "-19 1 0.1976\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2004/10000 (20%)\n",
      "\n",
      "-19 2 0.2004\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2012/10000 (20%)\n",
      "\n",
      "-19 3 0.2012\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1943/10000 (19%)\n",
      "\n",
      "-19 4 0.1943\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1978/10000 (20%)\n",
      "\n",
      "-19 5 0.1978\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2003/10000 (20%)\n",
      "\n",
      "-19 6 0.2003\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2024/10000 (20%)\n",
      "\n",
      "-19 7 0.2024\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1917/10000 (19%)\n",
      "\n",
      "-19 8 0.1917\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1877/10000 (19%)\n",
      "\n",
      "-19 9 0.1877\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1757/10000 (18%)\n",
      "\n",
      "-19 10 0.1757\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1592/10000 (16%)\n",
      "\n",
      "-19 11 0.1592\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1448/10000 (14%)\n",
      "\n",
      "-19 12 0.1448\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1385/10000 (14%)\n",
      "\n",
      "-19 13 0.1385\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1236/10000 (12%)\n",
      "\n",
      "-19 14 0.1236\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1269/10000 (13%)\n",
      "\n",
      "-19 15 0.1269\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1255/10000 (13%)\n",
      "\n",
      "-19 16 0.1255\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1125/10000 (11%)\n",
      "\n",
      "-19 17 0.1125\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "-19 18 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1193/10000 (12%)\n",
      "\n",
      "-19 19 0.1193\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1192/10000 (12%)\n",
      "\n",
      "-19 20 0.1192\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 568/10000 (6%)\n",
      "\n",
      "-19 21 0.0568\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-19 22 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-19 23 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-19 24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-19 26 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 917/10000 (9%)\n",
      "\n",
      "-18 -25 0.0917\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-18 -24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1003/10000 (10%)\n",
      "\n",
      "-18 -23 0.1003\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-18 -22 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "-18 -21 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1206/10000 (12%)\n",
      "\n",
      "-18 -20 0.1206\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1246/10000 (12%)\n",
      "\n",
      "-18 -19 0.1246\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1307/10000 (13%)\n",
      "\n",
      "-18 -18 0.1307\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 629/10000 (6%)\n",
      "\n",
      "-18 -17 0.0629\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1425/10000 (14%)\n",
      "\n",
      "-18 -16 0.1425\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-18 -15 0.101\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1511/10000 (15%)\n",
      "\n",
      "-18 -14 0.1511\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1633/10000 (16%)\n",
      "\n",
      "-18 -13 0.1633\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1732/10000 (17%)\n",
      "\n",
      "-18 -12 0.1732\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1829/10000 (18%)\n",
      "\n",
      "-18 -11 0.1829\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1886/10000 (19%)\n",
      "\n",
      "-18 -10 0.1886\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2005/10000 (20%)\n",
      "\n",
      "-18 -9 0.2005\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2093/10000 (21%)\n",
      "\n",
      "-18 -8 0.2093\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2106/10000 (21%)\n",
      "\n",
      "-18 -7 0.2106\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2200/10000 (22%)\n",
      "\n",
      "-18 -6 0.22\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2359/10000 (24%)\n",
      "\n",
      "-18 -5 0.2359\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2424/10000 (24%)\n",
      "\n",
      "-18 -4 0.2424\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2426/10000 (24%)\n",
      "\n",
      "-18 -3 0.2426\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2375/10000 (24%)\n",
      "\n",
      "-18 -2 0.2375\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2357/10000 (24%)\n",
      "\n",
      "-18 -1 0.2357\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2310/10000 (23%)\n",
      "\n",
      "-18 0 0.231\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2237/10000 (22%)\n",
      "\n",
      "-18 1 0.2237\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2190/10000 (22%)\n",
      "\n",
      "-18 2 0.219\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2100/10000 (21%)\n",
      "\n",
      "-18 3 0.21\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2179/10000 (22%)\n",
      "\n",
      "-18 4 0.2179\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2109/10000 (21%)\n",
      "\n",
      "-18 5 0.2109\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2050/10000 (20%)\n",
      "\n",
      "-18 6 0.205\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2066/10000 (21%)\n",
      "\n",
      "-18 7 0.2066\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1971/10000 (20%)\n",
      "\n",
      "-18 8 0.1971\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1919/10000 (19%)\n",
      "\n",
      "-18 9 0.1919\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1748/10000 (17%)\n",
      "\n",
      "-18 10 0.1748\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1646/10000 (16%)\n",
      "\n",
      "-18 11 0.1646\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1552/10000 (16%)\n",
      "\n",
      "-18 12 0.1552\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1377/10000 (14%)\n",
      "\n",
      "-18 13 0.1377\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1315/10000 (13%)\n",
      "\n",
      "-18 14 0.1315\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1304/10000 (13%)\n",
      "\n",
      "-18 15 0.1304\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1250/10000 (12%)\n",
      "\n",
      "-18 16 0.125\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1235/10000 (12%)\n",
      "\n",
      "-18 17 0.1235\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1247/10000 (12%)\n",
      "\n",
      "-18 18 0.1247\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "-18 19 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1192/10000 (12%)\n",
      "\n",
      "-18 20 0.1192\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 866/10000 (9%)\n",
      "\n",
      "-18 21 0.0866\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1050/10000 (10%)\n",
      "\n",
      "-18 22 0.105\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-18 23 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-18 24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-18 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 892/10000 (9%)\n",
      "\n",
      "-17 -27 0.0892\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-17 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-17 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-17 -24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-17 -23 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "-17 -22 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "-17 -21 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1202/10000 (12%)\n",
      "\n",
      "-17 -20 0.1202\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1277/10000 (13%)\n",
      "\n",
      "-17 -19 0.1277\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1321/10000 (13%)\n",
      "\n",
      "-17 -18 0.1321\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1366/10000 (14%)\n",
      "\n",
      "-17 -17 0.1366\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1418/10000 (14%)\n",
      "\n",
      "-17 -16 0.1418\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1190/10000 (12%)\n",
      "\n",
      "-17 -15 0.119\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1472/10000 (15%)\n",
      "\n",
      "-17 -14 0.1472\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1668/10000 (17%)\n",
      "\n",
      "-17 -13 0.1668\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1785/10000 (18%)\n",
      "\n",
      "-17 -12 0.1785\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1959/10000 (20%)\n",
      "\n",
      "-17 -11 0.1959\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2121/10000 (21%)\n",
      "\n",
      "-17 -10 0.2121\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2220/10000 (22%)\n",
      "\n",
      "-17 -9 0.222\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2306/10000 (23%)\n",
      "\n",
      "-17 -8 0.2306\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2506/10000 (25%)\n",
      "\n",
      "-17 -7 0.2506\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2563/10000 (26%)\n",
      "\n",
      "-17 -6 0.2563\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 2669/10000 (27%)\n",
      "\n",
      "-17 -5 0.2669\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 2756/10000 (28%)\n",
      "\n",
      "-17 -4 0.2756\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 2764/10000 (28%)\n",
      "\n",
      "-17 -3 0.2764\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 2764/10000 (28%)\n",
      "\n",
      "-17 -2 0.2764\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 2736/10000 (27%)\n",
      "\n",
      "-17 -1 0.2736\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 2695/10000 (27%)\n",
      "\n",
      "-17 0 0.2695\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2556/10000 (26%)\n",
      "\n",
      "-17 1 0.2556\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2494/10000 (25%)\n",
      "\n",
      "-17 2 0.2494\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2353/10000 (24%)\n",
      "\n",
      "-17 3 0.2353\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2225/10000 (22%)\n",
      "\n",
      "-17 4 0.2225\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2201/10000 (22%)\n",
      "\n",
      "-17 5 0.2201\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2115/10000 (21%)\n",
      "\n",
      "-17 6 0.2115\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2142/10000 (21%)\n",
      "\n",
      "-17 7 0.2142\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2111/10000 (21%)\n",
      "\n",
      "-17 8 0.2111\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2019/10000 (20%)\n",
      "\n",
      "-17 9 0.2019\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1869/10000 (19%)\n",
      "\n",
      "-17 10 0.1869\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1725/10000 (17%)\n",
      "\n",
      "-17 11 0.1725\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1659/10000 (17%)\n",
      "\n",
      "-17 12 0.1659\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1502/10000 (15%)\n",
      "\n",
      "-17 13 0.1502\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1414/10000 (14%)\n",
      "\n",
      "-17 14 0.1414\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1324/10000 (13%)\n",
      "\n",
      "-17 15 0.1324\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1327/10000 (13%)\n",
      "\n",
      "-17 16 0.1327\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1350/10000 (14%)\n",
      "\n",
      "-17 17 0.135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1298/10000 (13%)\n",
      "\n",
      "-17 18 0.1298\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1297/10000 (13%)\n",
      "\n",
      "-17 19 0.1297\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1255/10000 (13%)\n",
      "\n",
      "-17 20 0.1255\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "-17 21 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "-17 22 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1165/10000 (12%)\n",
      "\n",
      "-17 23 0.1165\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-17 24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-17 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 982/10000 (10%)\n",
      "\n",
      "-17 26 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-17 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-16 -26 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-16 -24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-16 -23 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "-16 -22 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "-16 -21 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1229/10000 (12%)\n",
      "\n",
      "-16 -20 0.1229\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1257/10000 (13%)\n",
      "\n",
      "-16 -19 0.1257\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1340/10000 (13%)\n",
      "\n",
      "-16 -18 0.134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1408/10000 (14%)\n",
      "\n",
      "-16 -17 0.1408\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1442/10000 (14%)\n",
      "\n",
      "-16 -16 0.1442\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1315/10000 (13%)\n",
      "\n",
      "-16 -15 0.1315\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1546/10000 (15%)\n",
      "\n",
      "-16 -14 0.1546\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1709/10000 (17%)\n",
      "\n",
      "-16 -13 0.1709\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1872/10000 (19%)\n",
      "\n",
      "-16 -12 0.1872\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2138/10000 (21%)\n",
      "\n",
      "-16 -11 0.2138\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2339/10000 (23%)\n",
      "\n",
      "-16 -10 0.2339\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2401/10000 (24%)\n",
      "\n",
      "-16 -9 0.2401\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2596/10000 (26%)\n",
      "\n",
      "-16 -8 0.2596\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 2700/10000 (27%)\n",
      "\n",
      "-16 -7 0.27\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 2859/10000 (29%)\n",
      "\n",
      "-16 -6 0.2859\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 2942/10000 (29%)\n",
      "\n",
      "-16 -5 0.2942\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3017/10000 (30%)\n",
      "\n",
      "-16 -4 0.3017\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3063/10000 (31%)\n",
      "\n",
      "-16 -3 0.3063\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3069/10000 (31%)\n",
      "\n",
      "-16 -2 0.3069\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 2983/10000 (30%)\n",
      "\n",
      "-16 -1 0.2983\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3072/10000 (31%)\n",
      "\n",
      "-16 0 0.3072\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 2979/10000 (30%)\n",
      "\n",
      "-16 1 0.2979\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 2875/10000 (29%)\n",
      "\n",
      "-16 2 0.2875\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 2762/10000 (28%)\n",
      "\n",
      "-16 3 0.2762\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2690/10000 (27%)\n",
      "\n",
      "-16 4 0.269\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2578/10000 (26%)\n",
      "\n",
      "-16 5 0.2578\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2444/10000 (24%)\n",
      "\n",
      "-16 6 0.2444\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2414/10000 (24%)\n",
      "\n",
      "-16 7 0.2414\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2323/10000 (23%)\n",
      "\n",
      "-16 8 0.2323\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2296/10000 (23%)\n",
      "\n",
      "-16 9 0.2296\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2116/10000 (21%)\n",
      "\n",
      "-16 10 0.2116\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1933/10000 (19%)\n",
      "\n",
      "-16 11 0.1933\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1798/10000 (18%)\n",
      "\n",
      "-16 12 0.1798\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1662/10000 (17%)\n",
      "\n",
      "-16 13 0.1662\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1476/10000 (15%)\n",
      "\n",
      "-16 14 0.1476\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1441/10000 (14%)\n",
      "\n",
      "-16 15 0.1441\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1484/10000 (15%)\n",
      "\n",
      "-16 16 0.1484\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1428/10000 (14%)\n",
      "\n",
      "-16 17 0.1428\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1392/10000 (14%)\n",
      "\n",
      "-16 18 0.1392\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1340/10000 (13%)\n",
      "\n",
      "-16 19 0.134\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 756/10000 (8%)\n",
      "\n",
      "-16 20 0.0756\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1240/10000 (12%)\n",
      "\n",
      "-16 21 0.124\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1208/10000 (12%)\n",
      "\n",
      "-16 22 0.1208\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1165/10000 (12%)\n",
      "\n",
      "-16 23 0.1165\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-16 24 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1032/10000 (10%)\n",
      "\n",
      "-16 25 0.1032\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-16 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-15 -27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-15 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 976/10000 (10%)\n",
      "\n",
      "-15 -25 0.0976\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "-15 -24 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-15 -23 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1172/10000 (12%)\n",
      "\n",
      "-15 -22 0.1172\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1202/10000 (12%)\n",
      "\n",
      "-15 -21 0.1202\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1246/10000 (12%)\n",
      "\n",
      "-15 -20 0.1246\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1294/10000 (13%)\n",
      "\n",
      "-15 -19 0.1294\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1365/10000 (14%)\n",
      "\n",
      "-15 -18 0.1365\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1398/10000 (14%)\n",
      "\n",
      "-15 -17 0.1398\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 974/10000 (10%)\n",
      "\n",
      "-15 -16 0.0974\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1445/10000 (14%)\n",
      "\n",
      "-15 -15 0.1445\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1607/10000 (16%)\n",
      "\n",
      "-15 -14 0.1607\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1771/10000 (18%)\n",
      "\n",
      "-15 -13 0.1771\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2017/10000 (20%)\n",
      "\n",
      "-15 -12 0.2017\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2332/10000 (23%)\n",
      "\n",
      "-15 -11 0.2332\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2487/10000 (25%)\n",
      "\n",
      "-15 -10 0.2487\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2649/10000 (26%)\n",
      "\n",
      "-15 -9 0.2649\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2847/10000 (28%)\n",
      "\n",
      "-15 -8 0.2847\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3004/10000 (30%)\n",
      "\n",
      "-15 -7 0.3004\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3099/10000 (31%)\n",
      "\n",
      "-15 -6 0.3099\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3120/10000 (31%)\n",
      "\n",
      "-15 -5 0.312\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3220/10000 (32%)\n",
      "\n",
      "-15 -4 0.322\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3206/10000 (32%)\n",
      "\n",
      "-15 -3 0.3206\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3323/10000 (33%)\n",
      "\n",
      "-15 -2 0.3323\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3344/10000 (33%)\n",
      "\n",
      "-15 -1 0.3344\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3363/10000 (34%)\n",
      "\n",
      "-15 0 0.3363\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3406/10000 (34%)\n",
      "\n",
      "-15 1 0.3406\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3359/10000 (34%)\n",
      "\n",
      "-15 2 0.3359\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3354/10000 (34%)\n",
      "\n",
      "-15 3 0.3354\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3290/10000 (33%)\n",
      "\n",
      "-15 4 0.329\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3159/10000 (32%)\n",
      "\n",
      "-15 5 0.3159\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3110/10000 (31%)\n",
      "\n",
      "-15 6 0.311\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3024/10000 (30%)\n",
      "\n",
      "-15 7 0.3024\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2889/10000 (29%)\n",
      "\n",
      "-15 8 0.2889\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2665/10000 (27%)\n",
      "\n",
      "-15 9 0.2665\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2373/10000 (24%)\n",
      "\n",
      "-15 10 0.2373\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2154/10000 (22%)\n",
      "\n",
      "-15 11 0.2154\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1965/10000 (20%)\n",
      "\n",
      "-15 12 0.1965\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1768/10000 (18%)\n",
      "\n",
      "-15 13 0.1768\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1586/10000 (16%)\n",
      "\n",
      "-15 14 0.1586\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1439/10000 (14%)\n",
      "\n",
      "-15 15 0.1439\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1570/10000 (16%)\n",
      "\n",
      "-15 16 0.157\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1470/10000 (15%)\n",
      "\n",
      "-15 17 0.147\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1480/10000 (15%)\n",
      "\n",
      "-15 18 0.148\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1412/10000 (14%)\n",
      "\n",
      "-15 19 0.1412\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1354/10000 (14%)\n",
      "\n",
      "-15 20 0.1354\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1285/10000 (13%)\n",
      "\n",
      "-15 21 0.1285\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1213/10000 (12%)\n",
      "\n",
      "-15 22 0.1213\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "-15 23 0.118\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-15 24 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "-15 25 0.1014\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-15 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-15 27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-14 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-14 -26 0.101\n",
      "\n",
      "Test set: Average loss: 0.0308, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-14 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-14 -24 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1158/10000 (12%)\n",
      "\n",
      "-14 -23 0.1158\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1174/10000 (12%)\n",
      "\n",
      "-14 -22 0.1174\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 938/10000 (9%)\n",
      "\n",
      "-14 -21 0.0938\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1251/10000 (13%)\n",
      "\n",
      "-14 -20 0.1251\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1327/10000 (13%)\n",
      "\n",
      "-14 -19 0.1327\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1394/10000 (14%)\n",
      "\n",
      "-14 -18 0.1394\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1431/10000 (14%)\n",
      "\n",
      "-14 -17 0.1431\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1405/10000 (14%)\n",
      "\n",
      "-14 -16 0.1405\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1492/10000 (15%)\n",
      "\n",
      "-14 -15 0.1492\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1725/10000 (17%)\n",
      "\n",
      "-14 -14 0.1725\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2011/10000 (20%)\n",
      "\n",
      "-14 -13 0.2011\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2314/10000 (23%)\n",
      "\n",
      "-14 -12 0.2314\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2620/10000 (26%)\n",
      "\n",
      "-14 -11 0.262\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2811/10000 (28%)\n",
      "\n",
      "-14 -10 0.2811\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3067/10000 (31%)\n",
      "\n",
      "-14 -9 0.3067\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3144/10000 (31%)\n",
      "\n",
      "-14 -8 0.3144\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3299/10000 (33%)\n",
      "\n",
      "-14 -7 0.3299\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3440/10000 (34%)\n",
      "\n",
      "-14 -6 0.344\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3459/10000 (35%)\n",
      "\n",
      "-14 -5 0.3459\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3518/10000 (35%)\n",
      "\n",
      "-14 -4 0.3518\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3568/10000 (36%)\n",
      "\n",
      "-14 -3 0.3568\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3605/10000 (36%)\n",
      "\n",
      "-14 -2 0.3605\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 3713/10000 (37%)\n",
      "\n",
      "-14 -1 0.3713\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 3810/10000 (38%)\n",
      "\n",
      "-14 0 0.381\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 3733/10000 (37%)\n",
      "\n",
      "-14 1 0.3733\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 3911/10000 (39%)\n",
      "\n",
      "-14 2 0.3911\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 3851/10000 (39%)\n",
      "\n",
      "-14 3 0.3851\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 3878/10000 (39%)\n",
      "\n",
      "-14 4 0.3878\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3797/10000 (38%)\n",
      "\n",
      "-14 5 0.3797\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3646/10000 (36%)\n",
      "\n",
      "-14 6 0.3646\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3556/10000 (36%)\n",
      "\n",
      "-14 7 0.3556\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3314/10000 (33%)\n",
      "\n",
      "-14 8 0.3314\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3004/10000 (30%)\n",
      "\n",
      "-14 9 0.3004\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2672/10000 (27%)\n",
      "\n",
      "-14 10 0.2672\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2370/10000 (24%)\n",
      "\n",
      "-14 11 0.237\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2173/10000 (22%)\n",
      "\n",
      "-14 12 0.2173\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2022/10000 (20%)\n",
      "\n",
      "-14 13 0.2022\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1769/10000 (18%)\n",
      "\n",
      "-14 14 0.1769\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1738/10000 (17%)\n",
      "\n",
      "-14 15 0.1738\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1657/10000 (17%)\n",
      "\n",
      "-14 16 0.1657\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1636/10000 (16%)\n",
      "\n",
      "-14 17 0.1636\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1544/10000 (15%)\n",
      "\n",
      "-14 18 0.1544\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1484/10000 (15%)\n",
      "\n",
      "-14 19 0.1484\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1372/10000 (14%)\n",
      "\n",
      "-14 20 0.1372\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1289/10000 (13%)\n",
      "\n",
      "-14 21 0.1289\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1215/10000 (12%)\n",
      "\n",
      "-14 22 0.1215\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "-14 23 0.118\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-14 24 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-14 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-14 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-14 27 0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-13 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-13 -26 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-13 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-13 -24 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 951/10000 (10%)\n",
      "\n",
      "-13 -23 0.0951\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 869/10000 (9%)\n",
      "\n",
      "-13 -22 0.0869\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1217/10000 (12%)\n",
      "\n",
      "-13 -21 0.1217\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1284/10000 (13%)\n",
      "\n",
      "-13 -20 0.1284\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1357/10000 (14%)\n",
      "\n",
      "-13 -19 0.1357\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1439/10000 (14%)\n",
      "\n",
      "-13 -18 0.1439\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 774/10000 (8%)\n",
      "\n",
      "-13 -17 0.0774\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1496/10000 (15%)\n",
      "\n",
      "-13 -16 0.1496\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1585/10000 (16%)\n",
      "\n",
      "-13 -15 0.1585\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1828/10000 (18%)\n",
      "\n",
      "-13 -14 0.1828\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2249/10000 (22%)\n",
      "\n",
      "-13 -13 0.2249\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2560/10000 (26%)\n",
      "\n",
      "-13 -12 0.256\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2903/10000 (29%)\n",
      "\n",
      "-13 -11 0.2903\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3198/10000 (32%)\n",
      "\n",
      "-13 -10 0.3198\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3336/10000 (33%)\n",
      "\n",
      "-13 -9 0.3336\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3551/10000 (36%)\n",
      "\n",
      "-13 -8 0.3551\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3648/10000 (36%)\n",
      "\n",
      "-13 -7 0.3648\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 3867/10000 (39%)\n",
      "\n",
      "-13 -6 0.3867\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 3826/10000 (38%)\n",
      "\n",
      "-13 -5 0.3826\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 3900/10000 (39%)\n",
      "\n",
      "-13 -4 0.39\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4019/10000 (40%)\n",
      "\n",
      "-13 -3 0.4019\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4135/10000 (41%)\n",
      "\n",
      "-13 -2 0.4135\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4221/10000 (42%)\n",
      "\n",
      "-13 -1 0.4221\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4340/10000 (43%)\n",
      "\n",
      "-13 0 0.434\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4332/10000 (43%)\n",
      "\n",
      "-13 1 0.4332\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4397/10000 (44%)\n",
      "\n",
      "-13 2 0.4397\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4326/10000 (43%)\n",
      "\n",
      "-13 3 0.4326\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4274/10000 (43%)\n",
      "\n",
      "-13 4 0.4274\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4113/10000 (41%)\n",
      "\n",
      "-13 5 0.4113\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4062/10000 (41%)\n",
      "\n",
      "-13 6 0.4062\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 3851/10000 (39%)\n",
      "\n",
      "-13 7 0.3851\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3583/10000 (36%)\n",
      "\n",
      "-13 8 0.3583\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3382/10000 (34%)\n",
      "\n",
      "-13 9 0.3382\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2989/10000 (30%)\n",
      "\n",
      "-13 10 0.2989\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2678/10000 (27%)\n",
      "\n",
      "-13 11 0.2678\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2399/10000 (24%)\n",
      "\n",
      "-13 12 0.2399\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2238/10000 (22%)\n",
      "\n",
      "-13 13 0.2238\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1992/10000 (20%)\n",
      "\n",
      "-13 14 0.1992\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1842/10000 (18%)\n",
      "\n",
      "-13 15 0.1842\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1788/10000 (18%)\n",
      "\n",
      "-13 16 0.1788\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1748/10000 (17%)\n",
      "\n",
      "-13 17 0.1748\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 878/10000 (9%)\n",
      "\n",
      "-13 18 0.0878\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1528/10000 (15%)\n",
      "\n",
      "-13 19 0.1528\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1387/10000 (14%)\n",
      "\n",
      "-13 20 0.1387\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1319/10000 (13%)\n",
      "\n",
      "-13 21 0.1319\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "-13 22 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-13 23 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-13 24 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-13 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-13 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-13 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 974/10000 (10%)\n",
      "\n",
      "-12 -27 0.0974\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-12 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-12 -25 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-12 -24 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "-12 -23 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 514/10000 (5%)\n",
      "\n",
      "-12 -22 0.0514\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1230/10000 (12%)\n",
      "\n",
      "-12 -21 0.123\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 588/10000 (6%)\n",
      "\n",
      "-12 -20 0.0588\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1374/10000 (14%)\n",
      "\n",
      "-12 -19 0.1374\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1450/10000 (14%)\n",
      "\n",
      "-12 -18 0.145\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1516/10000 (15%)\n",
      "\n",
      "-12 -17 0.1516\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1459/10000 (15%)\n",
      "\n",
      "-12 -16 0.1459\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1829/10000 (18%)\n",
      "\n",
      "-12 -15 0.1829\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2191/10000 (22%)\n",
      "\n",
      "-12 -14 0.2191\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2529/10000 (25%)\n",
      "\n",
      "-12 -13 0.2529\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2912/10000 (29%)\n",
      "\n",
      "-12 -12 0.2912\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3171/10000 (32%)\n",
      "\n",
      "-12 -11 0.3171\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3524/10000 (35%)\n",
      "\n",
      "-12 -10 0.3524\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3764/10000 (38%)\n",
      "\n",
      "-12 -9 0.3764\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 3862/10000 (39%)\n",
      "\n",
      "-12 -8 0.3862\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4022/10000 (40%)\n",
      "\n",
      "-12 -7 0.4022\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4078/10000 (41%)\n",
      "\n",
      "-12 -6 0.4078\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4289/10000 (43%)\n",
      "\n",
      "-12 -5 0.4289\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4321/10000 (43%)\n",
      "\n",
      "-12 -4 0.4321\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4371/10000 (44%)\n",
      "\n",
      "-12 -3 0.4371\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 4622/10000 (46%)\n",
      "\n",
      "-12 -2 0.4622\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 4668/10000 (47%)\n",
      "\n",
      "-12 -1 0.4668\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 4807/10000 (48%)\n",
      "\n",
      "-12 0 0.4807\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 4787/10000 (48%)\n",
      "\n",
      "-12 1 0.4787\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 4687/10000 (47%)\n",
      "\n",
      "-12 2 0.4687\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4594/10000 (46%)\n",
      "\n",
      "-12 3 0.4594\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4456/10000 (45%)\n",
      "\n",
      "-12 4 0.4456\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 4465/10000 (45%)\n",
      "\n",
      "-12 5 0.4465\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4394/10000 (44%)\n",
      "\n",
      "-12 6 0.4394\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4136/10000 (41%)\n",
      "\n",
      "-12 7 0.4136\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3844/10000 (38%)\n",
      "\n",
      "-12 8 0.3844\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3568/10000 (36%)\n",
      "\n",
      "-12 9 0.3568\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3413/10000 (34%)\n",
      "\n",
      "-12 10 0.3413\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3048/10000 (30%)\n",
      "\n",
      "-12 11 0.3048\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2718/10000 (27%)\n",
      "\n",
      "-12 12 0.2718\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2436/10000 (24%)\n",
      "\n",
      "-12 13 0.2436\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2206/10000 (22%)\n",
      "\n",
      "-12 14 0.2206\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1831/10000 (18%)\n",
      "\n",
      "-12 15 0.1831\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1919/10000 (19%)\n",
      "\n",
      "-12 16 0.1919\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-12 17 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1678/10000 (17%)\n",
      "\n",
      "-12 18 0.1678\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1529/10000 (15%)\n",
      "\n",
      "-12 19 0.1529\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 649/10000 (6%)\n",
      "\n",
      "-12 20 0.0649\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1323/10000 (13%)\n",
      "\n",
      "-12 21 0.1323\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 774/10000 (8%)\n",
      "\n",
      "-12 22 0.0774\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "-12 23 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-12 24 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-12 25 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-12 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-12 27 0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-11 -25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-11 -24 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1158/10000 (12%)\n",
      "\n",
      "-11 -23 0.1158\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 757/10000 (8%)\n",
      "\n",
      "-11 -22 0.0757\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 274/10000 (3%)\n",
      "\n",
      "-11 -21 0.0274\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1324/10000 (13%)\n",
      "\n",
      "-11 -20 0.1324\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1400/10000 (14%)\n",
      "\n",
      "-11 -19 0.14\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1481/10000 (15%)\n",
      "\n",
      "-11 -18 0.1481\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1573/10000 (16%)\n",
      "\n",
      "-11 -17 0.1573\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1634/10000 (16%)\n",
      "\n",
      "-11 -16 0.1634\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2005/10000 (20%)\n",
      "\n",
      "-11 -15 0.2005\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2359/10000 (24%)\n",
      "\n",
      "-11 -14 0.2359\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2874/10000 (29%)\n",
      "\n",
      "-11 -13 0.2874\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3197/10000 (32%)\n",
      "\n",
      "-11 -12 0.3197\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3534/10000 (35%)\n",
      "\n",
      "-11 -11 0.3534\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3725/10000 (37%)\n",
      "\n",
      "-11 -10 0.3725\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 3843/10000 (38%)\n",
      "\n",
      "-11 -9 0.3843\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 3950/10000 (40%)\n",
      "\n",
      "-11 -8 0.395\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4096/10000 (41%)\n",
      "\n",
      "-11 -7 0.4096\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4299/10000 (43%)\n",
      "\n",
      "-11 -6 0.4299\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4410/10000 (44%)\n",
      "\n",
      "-11 -5 0.441\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4640/10000 (46%)\n",
      "\n",
      "-11 -4 0.464\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 4899/10000 (49%)\n",
      "\n",
      "-11 -3 0.4899\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 4937/10000 (49%)\n",
      "\n",
      "-11 -2 0.4937\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 4984/10000 (50%)\n",
      "\n",
      "-11 -1 0.4984\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5109/10000 (51%)\n",
      "\n",
      "-11 0 0.5109\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5129/10000 (51%)\n",
      "\n",
      "-11 1 0.5129\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5042/10000 (50%)\n",
      "\n",
      "-11 2 0.5042\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 4734/10000 (47%)\n",
      "\n",
      "-11 3 0.4734\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 4754/10000 (48%)\n",
      "\n",
      "-11 4 0.4754\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4592/10000 (46%)\n",
      "\n",
      "-11 5 0.4592\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4635/10000 (46%)\n",
      "\n",
      "-11 6 0.4635\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4386/10000 (44%)\n",
      "\n",
      "-11 7 0.4386\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4254/10000 (43%)\n",
      "\n",
      "-11 8 0.4254\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3976/10000 (40%)\n",
      "\n",
      "-11 9 0.3976\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3762/10000 (38%)\n",
      "\n",
      "-11 10 0.3762\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3369/10000 (34%)\n",
      "\n",
      "-11 11 0.3369\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2933/10000 (29%)\n",
      "\n",
      "-11 12 0.2933\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2687/10000 (27%)\n",
      "\n",
      "-11 13 0.2687\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2372/10000 (24%)\n",
      "\n",
      "-11 14 0.2372\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2138/10000 (21%)\n",
      "\n",
      "-11 15 0.2138\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1649/10000 (16%)\n",
      "\n",
      "-11 16 0.1649\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1738/10000 (17%)\n",
      "\n",
      "-11 17 0.1738\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1643/10000 (16%)\n",
      "\n",
      "-11 18 0.1643\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1507/10000 (15%)\n",
      "\n",
      "-11 19 0.1507\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1371/10000 (14%)\n",
      "\n",
      "-11 20 0.1371\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1302/10000 (13%)\n",
      "\n",
      "-11 21 0.1302\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1235/10000 (12%)\n",
      "\n",
      "-11 22 0.1235\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "-11 23 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 899/10000 (9%)\n",
      "\n",
      "-11 24 0.0899\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1017/10000 (10%)\n",
      "\n",
      "-11 25 0.1017\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-10 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-10 -26 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-10 -25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-10 -24 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 504/10000 (5%)\n",
      "\n",
      "-10 -23 0.0504\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "-10 -22 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1239/10000 (12%)\n",
      "\n",
      "-10 -21 0.1239\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1317/10000 (13%)\n",
      "\n",
      "-10 -20 0.1317\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1420/10000 (14%)\n",
      "\n",
      "-10 -19 0.142\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1523/10000 (15%)\n",
      "\n",
      "-10 -18 0.1523\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1668/10000 (17%)\n",
      "\n",
      "-10 -17 0.1668\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1855/10000 (19%)\n",
      "\n",
      "-10 -16 0.1855\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2165/10000 (22%)\n",
      "\n",
      "-10 -15 0.2165\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2580/10000 (26%)\n",
      "\n",
      "-10 -14 0.258\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 3053/10000 (31%)\n",
      "\n",
      "-10 -13 0.3053\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3403/10000 (34%)\n",
      "\n",
      "-10 -12 0.3403\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3639/10000 (36%)\n",
      "\n",
      "-10 -11 0.3639\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3751/10000 (38%)\n",
      "\n",
      "-10 -10 0.3751\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 3888/10000 (39%)\n",
      "\n",
      "-10 -9 0.3888\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4158/10000 (42%)\n",
      "\n",
      "-10 -8 0.4158\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4314/10000 (43%)\n",
      "\n",
      "-10 -7 0.4314\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4495/10000 (45%)\n",
      "\n",
      "-10 -6 0.4495\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 4774/10000 (48%)\n",
      "\n",
      "-10 -5 0.4774\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5083/10000 (51%)\n",
      "\n",
      "-10 -4 0.5083\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5106/10000 (51%)\n",
      "\n",
      "-10 -3 0.5106\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5233/10000 (52%)\n",
      "\n",
      "-10 -2 0.5233\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5283/10000 (53%)\n",
      "\n",
      "-10 -1 0.5283\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5355/10000 (54%)\n",
      "\n",
      "-10 0 0.5355\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5366/10000 (54%)\n",
      "\n",
      "-10 1 0.5366\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5201/10000 (52%)\n",
      "\n",
      "-10 2 0.5201\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5042/10000 (50%)\n",
      "\n",
      "-10 3 0.5042\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5060/10000 (51%)\n",
      "\n",
      "-10 4 0.506\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 4879/10000 (49%)\n",
      "\n",
      "-10 5 0.4879\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4719/10000 (47%)\n",
      "\n",
      "-10 6 0.4719\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4624/10000 (46%)\n",
      "\n",
      "-10 7 0.4624\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4533/10000 (45%)\n",
      "\n",
      "-10 8 0.4533\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4268/10000 (43%)\n",
      "\n",
      "-10 9 0.4268\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3916/10000 (39%)\n",
      "\n",
      "-10 10 0.3916\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3568/10000 (36%)\n",
      "\n",
      "-10 11 0.3568\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3121/10000 (31%)\n",
      "\n",
      "-10 12 0.3121\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2798/10000 (28%)\n",
      "\n",
      "-10 13 0.2798\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2415/10000 (24%)\n",
      "\n",
      "-10 14 0.2415\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2095/10000 (21%)\n",
      "\n",
      "-10 15 0.2095\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1911/10000 (19%)\n",
      "\n",
      "-10 16 0.1911\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-10 17 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 858/10000 (9%)\n",
      "\n",
      "-10 18 0.0858\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1488/10000 (15%)\n",
      "\n",
      "-10 19 0.1488\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1381/10000 (14%)\n",
      "\n",
      "-10 20 0.1381\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "-10 21 0.1268\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1227/10000 (12%)\n",
      "\n",
      "-10 22 0.1227\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "-10 23 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-10 24 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-10 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-10 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-10 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "-9 -26 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 919/10000 (9%)\n",
      "\n",
      "-9 -25 0.0919\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-9 -24 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "-9 -23 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "-9 -22 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1258/10000 (13%)\n",
      "\n",
      "-9 -21 0.1258\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1321/10000 (13%)\n",
      "\n",
      "-9 -20 0.1321\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1425/10000 (14%)\n",
      "\n",
      "-9 -19 0.1425\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 859/10000 (9%)\n",
      "\n",
      "-9 -18 0.0859\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1687/10000 (17%)\n",
      "\n",
      "-9 -17 0.1687\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1907/10000 (19%)\n",
      "\n",
      "-9 -16 0.1907\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2292/10000 (23%)\n",
      "\n",
      "-9 -15 0.2292\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2762/10000 (28%)\n",
      "\n",
      "-9 -14 0.2762\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3237/10000 (32%)\n",
      "\n",
      "-9 -13 0.3237\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3513/10000 (35%)\n",
      "\n",
      "-9 -12 0.3513\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3761/10000 (38%)\n",
      "\n",
      "-9 -11 0.3761\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3858/10000 (39%)\n",
      "\n",
      "-9 -10 0.3858\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4129/10000 (41%)\n",
      "\n",
      "-9 -9 0.4129\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4376/10000 (44%)\n",
      "\n",
      "-9 -8 0.4376\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4620/10000 (46%)\n",
      "\n",
      "-9 -7 0.462\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 4844/10000 (48%)\n",
      "\n",
      "-9 -6 0.4844\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5142/10000 (51%)\n",
      "\n",
      "-9 -5 0.5142\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5312/10000 (53%)\n",
      "\n",
      "-9 -4 0.5312\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5548/10000 (55%)\n",
      "\n",
      "-9 -3 0.5548\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5583/10000 (56%)\n",
      "\n",
      "-9 -2 0.5583\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5642/10000 (56%)\n",
      "\n",
      "-9 -1 0.5642\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 5745/10000 (57%)\n",
      "\n",
      "-9 0 0.5745\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5618/10000 (56%)\n",
      "\n",
      "-9 1 0.5618\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5433/10000 (54%)\n",
      "\n",
      "-9 2 0.5433\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5332/10000 (53%)\n",
      "\n",
      "-9 3 0.5332\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5205/10000 (52%)\n",
      "\n",
      "-9 4 0.5205\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5212/10000 (52%)\n",
      "\n",
      "-9 5 0.5212\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5061/10000 (51%)\n",
      "\n",
      "-9 6 0.5061\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4956/10000 (50%)\n",
      "\n",
      "-9 7 0.4956\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4708/10000 (47%)\n",
      "\n",
      "-9 8 0.4708\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4452/10000 (45%)\n",
      "\n",
      "-9 9 0.4452\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4207/10000 (42%)\n",
      "\n",
      "-9 10 0.4207\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3693/10000 (37%)\n",
      "\n",
      "-9 11 0.3693\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3379/10000 (34%)\n",
      "\n",
      "-9 12 0.3379\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2901/10000 (29%)\n",
      "\n",
      "-9 13 0.2901\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2540/10000 (25%)\n",
      "\n",
      "-9 14 0.254\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2160/10000 (22%)\n",
      "\n",
      "-9 15 0.216\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1834/10000 (18%)\n",
      "\n",
      "-9 16 0.1834\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1690/10000 (17%)\n",
      "\n",
      "-9 17 0.169\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1500/10000 (15%)\n",
      "\n",
      "-9 18 0.15\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 619/10000 (6%)\n",
      "\n",
      "-9 19 0.0619\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1346/10000 (13%)\n",
      "\n",
      "-9 20 0.1346\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1249/10000 (12%)\n",
      "\n",
      "-9 21 0.1249\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 567/10000 (6%)\n",
      "\n",
      "-9 22 0.0567\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1005/10000 (10%)\n",
      "\n",
      "-9 23 0.1005\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-9 24 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-9 25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "-8 -27 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 952/10000 (10%)\n",
      "\n",
      "-8 -26 0.0952\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-8 -25 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-8 -24 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "-8 -23 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 904/10000 (9%)\n",
      "\n",
      "-8 -22 0.0904\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "-8 -21 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1326/10000 (13%)\n",
      "\n",
      "-8 -20 0.1326\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1398/10000 (14%)\n",
      "\n",
      "-8 -19 0.1398\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1525/10000 (15%)\n",
      "\n",
      "-8 -18 0.1525\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1630/10000 (16%)\n",
      "\n",
      "-8 -17 0.163\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1908/10000 (19%)\n",
      "\n",
      "-8 -16 0.1908\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2287/10000 (23%)\n",
      "\n",
      "-8 -15 0.2287\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2851/10000 (29%)\n",
      "\n",
      "-8 -14 0.2851\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3248/10000 (32%)\n",
      "\n",
      "-8 -13 0.3248\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3690/10000 (37%)\n",
      "\n",
      "-8 -12 0.369\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3900/10000 (39%)\n",
      "\n",
      "-8 -11 0.39\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4130/10000 (41%)\n",
      "\n",
      "-8 -10 0.413\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4322/10000 (43%)\n",
      "\n",
      "-8 -9 0.4322\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4643/10000 (46%)\n",
      "\n",
      "-8 -8 0.4643\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 4972/10000 (50%)\n",
      "\n",
      "-8 -7 0.4972\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5230/10000 (52%)\n",
      "\n",
      "-8 -6 0.523\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5514/10000 (55%)\n",
      "\n",
      "-8 -5 0.5514\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5705/10000 (57%)\n",
      "\n",
      "-8 -4 0.5705\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 5938/10000 (59%)\n",
      "\n",
      "-8 -3 0.5938\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 5975/10000 (60%)\n",
      "\n",
      "-8 -2 0.5975\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6036/10000 (60%)\n",
      "\n",
      "-8 -1 0.6036\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6088/10000 (61%)\n",
      "\n",
      "-8 0 0.6088\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6021/10000 (60%)\n",
      "\n",
      "-8 1 0.6021\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 5962/10000 (60%)\n",
      "\n",
      "-8 2 0.5962\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5695/10000 (57%)\n",
      "\n",
      "-8 3 0.5695\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5536/10000 (55%)\n",
      "\n",
      "-8 4 0.5536\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5452/10000 (55%)\n",
      "\n",
      "-8 5 0.5452\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5305/10000 (53%)\n",
      "\n",
      "-8 6 0.5305\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5154/10000 (52%)\n",
      "\n",
      "-8 7 0.5154\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 5000/10000 (50%)\n",
      "\n",
      "-8 8 0.5\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4682/10000 (47%)\n",
      "\n",
      "-8 9 0.4682\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4390/10000 (44%)\n",
      "\n",
      "-8 10 0.439\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3911/10000 (39%)\n",
      "\n",
      "-8 11 0.3911\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3451/10000 (35%)\n",
      "\n",
      "-8 12 0.3451\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2981/10000 (30%)\n",
      "\n",
      "-8 13 0.2981\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2540/10000 (25%)\n",
      "\n",
      "-8 14 0.254\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2117/10000 (21%)\n",
      "\n",
      "-8 15 0.2117\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1891/10000 (19%)\n",
      "\n",
      "-8 16 0.1891\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1701/10000 (17%)\n",
      "\n",
      "-8 17 0.1701\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 797/10000 (8%)\n",
      "\n",
      "-8 18 0.0797\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1419/10000 (14%)\n",
      "\n",
      "-8 19 0.1419\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1340/10000 (13%)\n",
      "\n",
      "-8 20 0.134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1295/10000 (13%)\n",
      "\n",
      "-8 21 0.1295\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "-8 22 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "-8 23 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-8 24 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-8 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 982/10000 (10%)\n",
      "\n",
      "-8 26 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-8 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-7 -27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1032/10000 (10%)\n",
      "\n",
      "-7 -26 0.1032\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1013/10000 (10%)\n",
      "\n",
      "-7 -25 0.1013\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1158/10000 (12%)\n",
      "\n",
      "-7 -24 0.1158\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "-7 -23 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1214/10000 (12%)\n",
      "\n",
      "-7 -22 0.1214\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 472/10000 (5%)\n",
      "\n",
      "-7 -21 0.0472\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 598/10000 (6%)\n",
      "\n",
      "-7 -20 0.0598\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1408/10000 (14%)\n",
      "\n",
      "-7 -19 0.1408\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1545/10000 (15%)\n",
      "\n",
      "-7 -18 0.1545\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1430/10000 (14%)\n",
      "\n",
      "-7 -17 0.143\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1957/10000 (20%)\n",
      "\n",
      "-7 -16 0.1957\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2484/10000 (25%)\n",
      "\n",
      "-7 -15 0.2484\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2978/10000 (30%)\n",
      "\n",
      "-7 -14 0.2978\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3515/10000 (35%)\n",
      "\n",
      "-7 -13 0.3515\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3866/10000 (39%)\n",
      "\n",
      "-7 -12 0.3866\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4181/10000 (42%)\n",
      "\n",
      "-7 -11 0.4181\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4405/10000 (44%)\n",
      "\n",
      "-7 -10 0.4405\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4686/10000 (47%)\n",
      "\n",
      "-7 -9 0.4686\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5071/10000 (51%)\n",
      "\n",
      "-7 -8 0.5071\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5325/10000 (53%)\n",
      "\n",
      "-7 -7 0.5325\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5622/10000 (56%)\n",
      "\n",
      "-7 -6 0.5622\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5878/10000 (59%)\n",
      "\n",
      "-7 -5 0.5878\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6130/10000 (61%)\n",
      "\n",
      "-7 -4 0.613\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6262/10000 (63%)\n",
      "\n",
      "-7 -3 0.6262\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6400/10000 (64%)\n",
      "\n",
      "-7 -2 0.64\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6518/10000 (65%)\n",
      "\n",
      "-7 -1 0.6518\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6551/10000 (66%)\n",
      "\n",
      "-7 0 0.6551\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6650/10000 (66%)\n",
      "\n",
      "-7 1 0.665\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6315/10000 (63%)\n",
      "\n",
      "-7 2 0.6315\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6212/10000 (62%)\n",
      "\n",
      "-7 3 0.6212\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5927/10000 (59%)\n",
      "\n",
      "-7 4 0.5927\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5777/10000 (58%)\n",
      "\n",
      "-7 5 0.5777\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5514/10000 (55%)\n",
      "\n",
      "-7 6 0.5514\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5354/10000 (54%)\n",
      "\n",
      "-7 7 0.5354\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5195/10000 (52%)\n",
      "\n",
      "-7 8 0.5195\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4917/10000 (49%)\n",
      "\n",
      "-7 9 0.4917\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4584/10000 (46%)\n",
      "\n",
      "-7 10 0.4584\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4057/10000 (41%)\n",
      "\n",
      "-7 11 0.4057\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3609/10000 (36%)\n",
      "\n",
      "-7 12 0.3609\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 3125/10000 (31%)\n",
      "\n",
      "-7 13 0.3125\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2627/10000 (26%)\n",
      "\n",
      "-7 14 0.2627\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2147/10000 (21%)\n",
      "\n",
      "-7 15 0.2147\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1546/10000 (15%)\n",
      "\n",
      "-7 16 0.1546\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1129/10000 (11%)\n",
      "\n",
      "-7 17 0.1129\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1597/10000 (16%)\n",
      "\n",
      "-7 18 0.1597\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1449/10000 (14%)\n",
      "\n",
      "-7 19 0.1449\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1382/10000 (14%)\n",
      "\n",
      "-7 20 0.1382\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 550/10000 (6%)\n",
      "\n",
      "-7 21 0.055\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1206/10000 (12%)\n",
      "\n",
      "-7 22 0.1206\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1002/10000 (10%)\n",
      "\n",
      "-7 23 0.1002\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-7 24 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-7 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-7 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-7 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-6 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1013/10000 (10%)\n",
      "\n",
      "-6 -26 0.1013\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-6 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-6 -24 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "-6 -23 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 650/10000 (6%)\n",
      "\n",
      "-6 -22 0.065\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1259/10000 (13%)\n",
      "\n",
      "-6 -21 0.1259\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1316/10000 (13%)\n",
      "\n",
      "-6 -20 0.1316\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 778/10000 (8%)\n",
      "\n",
      "-6 -19 0.0778\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1595/10000 (16%)\n",
      "\n",
      "-6 -18 0.1595\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1814/10000 (18%)\n",
      "\n",
      "-6 -17 0.1814\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2205/10000 (22%)\n",
      "\n",
      "-6 -16 0.2205\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2753/10000 (28%)\n",
      "\n",
      "-6 -15 0.2753\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3302/10000 (33%)\n",
      "\n",
      "-6 -14 0.3302\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3841/10000 (38%)\n",
      "\n",
      "-6 -13 0.3841\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4194/10000 (42%)\n",
      "\n",
      "-6 -12 0.4194\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4558/10000 (46%)\n",
      "\n",
      "-6 -11 0.4558\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4761/10000 (48%)\n",
      "\n",
      "-6 -10 0.4761\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 5079/10000 (51%)\n",
      "\n",
      "-6 -9 0.5079\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5439/10000 (54%)\n",
      "\n",
      "-6 -8 0.5439\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5728/10000 (57%)\n",
      "\n",
      "-6 -7 0.5728\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 6068/10000 (61%)\n",
      "\n",
      "-6 -6 0.6068\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6274/10000 (63%)\n",
      "\n",
      "-6 -5 0.6274\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6533/10000 (65%)\n",
      "\n",
      "-6 -4 0.6533\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6662/10000 (67%)\n",
      "\n",
      "-6 -3 0.6662\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6832/10000 (68%)\n",
      "\n",
      "-6 -2 0.6832\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 6946/10000 (69%)\n",
      "\n",
      "-6 -1 0.6946\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 7021/10000 (70%)\n",
      "\n",
      "-6 0 0.7021\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6904/10000 (69%)\n",
      "\n",
      "-6 1 0.6904\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6815/10000 (68%)\n",
      "\n",
      "-6 2 0.6815\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6534/10000 (65%)\n",
      "\n",
      "-6 3 0.6534\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6376/10000 (64%)\n",
      "\n",
      "-6 4 0.6376\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5991/10000 (60%)\n",
      "\n",
      "-6 5 0.5991\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5823/10000 (58%)\n",
      "\n",
      "-6 6 0.5823\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5619/10000 (56%)\n",
      "\n",
      "-6 7 0.5619\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5448/10000 (54%)\n",
      "\n",
      "-6 8 0.5448\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5172/10000 (52%)\n",
      "\n",
      "-6 9 0.5172\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4609/10000 (46%)\n",
      "\n",
      "-6 10 0.4609\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4254/10000 (43%)\n",
      "\n",
      "-6 11 0.4254\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3730/10000 (37%)\n",
      "\n",
      "-6 12 0.373\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3312/10000 (33%)\n",
      "\n",
      "-6 13 0.3312\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2719/10000 (27%)\n",
      "\n",
      "-6 14 0.2719\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2337/10000 (23%)\n",
      "\n",
      "-6 15 0.2337\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1721/10000 (17%)\n",
      "\n",
      "-6 16 0.1721\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1765/10000 (18%)\n",
      "\n",
      "-6 17 0.1765\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1618/10000 (16%)\n",
      "\n",
      "-6 18 0.1618\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1465/10000 (15%)\n",
      "\n",
      "-6 19 0.1465\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1404/10000 (14%)\n",
      "\n",
      "-6 20 0.1404\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1312/10000 (13%)\n",
      "\n",
      "-6 21 0.1312\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1230/10000 (12%)\n",
      "\n",
      "-6 22 0.123\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1018/10000 (10%)\n",
      "\n",
      "-6 23 0.1018\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-6 24 0.116\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-6 25 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-6 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 958/10000 (10%)\n",
      "\n",
      "-6 27 0.0958\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-5 -27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-5 -26 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-5 -25 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-5 -24 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "-5 -23 0.118\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1212/10000 (12%)\n",
      "\n",
      "-5 -22 0.1212\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "-5 -21 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1315/10000 (13%)\n",
      "\n",
      "-5 -20 0.1315\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1440/10000 (14%)\n",
      "\n",
      "-5 -19 0.144\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1696/10000 (17%)\n",
      "\n",
      "-5 -18 0.1696\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1718/10000 (17%)\n",
      "\n",
      "-5 -17 0.1718\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2474/10000 (25%)\n",
      "\n",
      "-5 -16 0.2474\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2943/10000 (29%)\n",
      "\n",
      "-5 -15 0.2943\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3589/10000 (36%)\n",
      "\n",
      "-5 -14 0.3589\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 4140/10000 (41%)\n",
      "\n",
      "-5 -13 0.414\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4430/10000 (44%)\n",
      "\n",
      "-5 -12 0.443\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4734/10000 (47%)\n",
      "\n",
      "-5 -11 0.4734\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5101/10000 (51%)\n",
      "\n",
      "-5 -10 0.5101\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5379/10000 (54%)\n",
      "\n",
      "-5 -9 0.5379\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5856/10000 (59%)\n",
      "\n",
      "-5 -8 0.5856\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6152/10000 (62%)\n",
      "\n",
      "-5 -7 0.6152\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6467/10000 (65%)\n",
      "\n",
      "-5 -6 0.6467\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6607/10000 (66%)\n",
      "\n",
      "-5 -5 0.6607\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6893/10000 (69%)\n",
      "\n",
      "-5 -4 0.6893\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 6978/10000 (70%)\n",
      "\n",
      "-5 -3 0.6978\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7101/10000 (71%)\n",
      "\n",
      "-5 -2 0.7101\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7257/10000 (73%)\n",
      "\n",
      "-5 -1 0.7257\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7330/10000 (73%)\n",
      "\n",
      "-5 0 0.733\n",
      "\n",
      "Test set: Average loss: 0.0089, Accuracy: 7306/10000 (73%)\n",
      "\n",
      "-5 1 0.7306\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7118/10000 (71%)\n",
      "\n",
      "-5 2 0.7118\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6865/10000 (69%)\n",
      "\n",
      "-5 3 0.6865\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6577/10000 (66%)\n",
      "\n",
      "-5 4 0.6577\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6379/10000 (64%)\n",
      "\n",
      "-5 5 0.6379\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 6091/10000 (61%)\n",
      "\n",
      "-5 6 0.6091\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5962/10000 (60%)\n",
      "\n",
      "-5 7 0.5962\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5710/10000 (57%)\n",
      "\n",
      "-5 8 0.571\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5217/10000 (52%)\n",
      "\n",
      "-5 9 0.5217\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4889/10000 (49%)\n",
      "\n",
      "-5 10 0.4889\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4400/10000 (44%)\n",
      "\n",
      "-5 11 0.44\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3860/10000 (39%)\n",
      "\n",
      "-5 12 0.386\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3381/10000 (34%)\n",
      "\n",
      "-5 13 0.3381\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2843/10000 (28%)\n",
      "\n",
      "-5 14 0.2843\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2299/10000 (23%)\n",
      "\n",
      "-5 15 0.2299\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2166/10000 (22%)\n",
      "\n",
      "-5 16 0.2166\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1925/10000 (19%)\n",
      "\n",
      "-5 17 0.1925\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1657/10000 (17%)\n",
      "\n",
      "-5 18 0.1657\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1535/10000 (15%)\n",
      "\n",
      "-5 19 0.1535\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1433/10000 (14%)\n",
      "\n",
      "-5 20 0.1433\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1311/10000 (13%)\n",
      "\n",
      "-5 21 0.1311\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1255/10000 (13%)\n",
      "\n",
      "-5 22 0.1255\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "-5 23 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "-5 24 0.1024\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-5 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-5 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-5 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-4 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-4 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-4 -25 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1027/10000 (10%)\n",
      "\n",
      "-4 -24 0.1027\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "-4 -23 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "-4 -22 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1315/10000 (13%)\n",
      "\n",
      "-4 -21 0.1315\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1383/10000 (14%)\n",
      "\n",
      "-4 -20 0.1383\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 815/10000 (8%)\n",
      "\n",
      "-4 -19 0.0815\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1769/10000 (18%)\n",
      "\n",
      "-4 -18 0.1769\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 2174/10000 (22%)\n",
      "\n",
      "-4 -17 0.2174\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2640/10000 (26%)\n",
      "\n",
      "-4 -16 0.264\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 3275/10000 (33%)\n",
      "\n",
      "-4 -15 0.3275\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3943/10000 (39%)\n",
      "\n",
      "-4 -14 0.3943\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4340/10000 (43%)\n",
      "\n",
      "-4 -13 0.434\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4706/10000 (47%)\n",
      "\n",
      "-4 -12 0.4706\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4927/10000 (49%)\n",
      "\n",
      "-4 -11 0.4927\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5296/10000 (53%)\n",
      "\n",
      "-4 -10 0.5296\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5632/10000 (56%)\n",
      "\n",
      "-4 -9 0.5632\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 6177/10000 (62%)\n",
      "\n",
      "-4 -8 0.6177\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6495/10000 (65%)\n",
      "\n",
      "-4 -7 0.6495\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6817/10000 (68%)\n",
      "\n",
      "-4 -6 0.6817\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 7043/10000 (70%)\n",
      "\n",
      "-4 -5 0.7043\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7194/10000 (72%)\n",
      "\n",
      "-4 -4 0.7194\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7337/10000 (73%)\n",
      "\n",
      "-4 -3 0.7337\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7366/10000 (74%)\n",
      "\n",
      "-4 -2 0.7366\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7475/10000 (75%)\n",
      "\n",
      "-4 -1 0.7475\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7554/10000 (76%)\n",
      "\n",
      "-4 0 0.7554\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7527/10000 (75%)\n",
      "\n",
      "-4 1 0.7527\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7371/10000 (74%)\n",
      "\n",
      "-4 2 0.7371\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7017/10000 (70%)\n",
      "\n",
      "-4 3 0.7017\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6844/10000 (68%)\n",
      "\n",
      "-4 4 0.6844\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6729/10000 (67%)\n",
      "\n",
      "-4 5 0.6729\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6506/10000 (65%)\n",
      "\n",
      "-4 6 0.6506\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6311/10000 (63%)\n",
      "\n",
      "-4 7 0.6311\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5945/10000 (59%)\n",
      "\n",
      "-4 8 0.5945\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5513/10000 (55%)\n",
      "\n",
      "-4 9 0.5513\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 5057/10000 (51%)\n",
      "\n",
      "-4 10 0.5057\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4611/10000 (46%)\n",
      "\n",
      "-4 11 0.4611\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 4067/10000 (41%)\n",
      "\n",
      "-4 12 0.4067\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3607/10000 (36%)\n",
      "\n",
      "-4 13 0.3607\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 3017/10000 (30%)\n",
      "\n",
      "-4 14 0.3017\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2665/10000 (27%)\n",
      "\n",
      "-4 15 0.2665\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1968/10000 (20%)\n",
      "\n",
      "-4 16 0.1968\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1450/10000 (14%)\n",
      "\n",
      "-4 17 0.145\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1765/10000 (18%)\n",
      "\n",
      "-4 18 0.1765\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 917/10000 (9%)\n",
      "\n",
      "-4 19 0.0917\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1476/10000 (15%)\n",
      "\n",
      "-4 20 0.1476\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1370/10000 (14%)\n",
      "\n",
      "-4 21 0.137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1038/10000 (10%)\n",
      "\n",
      "-4 22 0.1038\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 924/10000 (9%)\n",
      "\n",
      "-4 23 0.0924\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 994/10000 (10%)\n",
      "\n",
      "-4 24 0.0994\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-4 25 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-4 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-4 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-3 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-3 -26 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-3 -25 0.1144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-3 -24 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 747/10000 (7%)\n",
      "\n",
      "-3 -23 0.0747\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1250/10000 (12%)\n",
      "\n",
      "-3 -22 0.125\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1315/10000 (13%)\n",
      "\n",
      "-3 -21 0.1315\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1422/10000 (14%)\n",
      "\n",
      "-3 -20 0.1422\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1657/10000 (17%)\n",
      "\n",
      "-3 -19 0.1657\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1943/10000 (19%)\n",
      "\n",
      "-3 -18 0.1943\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2141/10000 (21%)\n",
      "\n",
      "-3 -17 0.2141\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2865/10000 (29%)\n",
      "\n",
      "-3 -16 0.2865\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 3545/10000 (35%)\n",
      "\n",
      "-3 -15 0.3545\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 4126/10000 (41%)\n",
      "\n",
      "-3 -14 0.4126\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4480/10000 (45%)\n",
      "\n",
      "-3 -13 0.448\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4798/10000 (48%)\n",
      "\n",
      "-3 -12 0.4798\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5152/10000 (52%)\n",
      "\n",
      "-3 -11 0.5152\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5490/10000 (55%)\n",
      "\n",
      "-3 -10 0.549\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5870/10000 (59%)\n",
      "\n",
      "-3 -9 0.587\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6322/10000 (63%)\n",
      "\n",
      "-3 -8 0.6322\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6753/10000 (68%)\n",
      "\n",
      "-3 -7 0.6753\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 6988/10000 (70%)\n",
      "\n",
      "-3 -6 0.6988\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 7240/10000 (72%)\n",
      "\n",
      "-3 -5 0.724\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7321/10000 (73%)\n",
      "\n",
      "-3 -4 0.7321\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7505/10000 (75%)\n",
      "\n",
      "-3 -3 0.7505\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7621/10000 (76%)\n",
      "\n",
      "-3 -2 0.7621\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7612/10000 (76%)\n",
      "\n",
      "-3 -1 0.7612\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7694/10000 (77%)\n",
      "\n",
      "-3 0 0.7694\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7663/10000 (77%)\n",
      "\n",
      "-3 1 0.7663\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 7435/10000 (74%)\n",
      "\n",
      "-3 2 0.7435\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 7236/10000 (72%)\n",
      "\n",
      "-3 3 0.7236\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 7110/10000 (71%)\n",
      "\n",
      "-3 4 0.711\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6898/10000 (69%)\n",
      "\n",
      "-3 5 0.6898\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6784/10000 (68%)\n",
      "\n",
      "-3 6 0.6784\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6514/10000 (65%)\n",
      "\n",
      "-3 7 0.6514\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6182/10000 (62%)\n",
      "\n",
      "-3 8 0.6182\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5741/10000 (57%)\n",
      "\n",
      "-3 9 0.5741\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 5302/10000 (53%)\n",
      "\n",
      "-3 10 0.5302\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4807/10000 (48%)\n",
      "\n",
      "-3 11 0.4807\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4362/10000 (44%)\n",
      "\n",
      "-3 12 0.4362\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3783/10000 (38%)\n",
      "\n",
      "-3 13 0.3783\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 3276/10000 (33%)\n",
      "\n",
      "-3 14 0.3276\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2774/10000 (28%)\n",
      "\n",
      "-3 15 0.2774\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2441/10000 (24%)\n",
      "\n",
      "-3 16 0.2441\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2088/10000 (21%)\n",
      "\n",
      "-3 17 0.2088\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1847/10000 (18%)\n",
      "\n",
      "-3 18 0.1847\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 944/10000 (9%)\n",
      "\n",
      "-3 19 0.0944\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1513/10000 (15%)\n",
      "\n",
      "-3 20 0.1513\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1378/10000 (14%)\n",
      "\n",
      "-3 21 0.1378\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 764/10000 (8%)\n",
      "\n",
      "-3 22 0.0764\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1220/10000 (12%)\n",
      "\n",
      "-3 23 0.122\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-3 24 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-3 25 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-3 26 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-3 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-2 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1029/10000 (10%)\n",
      "\n",
      "-2 -26 0.1029\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-2 -25 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-2 -24 0.116\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "-2 -23 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 935/10000 (9%)\n",
      "\n",
      "-2 -22 0.0935\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1369/10000 (14%)\n",
      "\n",
      "-2 -21 0.1369\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1502/10000 (15%)\n",
      "\n",
      "-2 -20 0.1502\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1105/10000 (11%)\n",
      "\n",
      "-2 -19 0.1105\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2158/10000 (22%)\n",
      "\n",
      "-2 -18 0.2158\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2628/10000 (26%)\n",
      "\n",
      "-2 -17 0.2628\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 3151/10000 (32%)\n",
      "\n",
      "-2 -16 0.3151\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3759/10000 (38%)\n",
      "\n",
      "-2 -15 0.3759\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4245/10000 (42%)\n",
      "\n",
      "-2 -14 0.4245\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4565/10000 (46%)\n",
      "\n",
      "-2 -13 0.4565\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4872/10000 (49%)\n",
      "\n",
      "-2 -12 0.4872\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5190/10000 (52%)\n",
      "\n",
      "-2 -11 0.519\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5613/10000 (56%)\n",
      "\n",
      "-2 -10 0.5613\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5975/10000 (60%)\n",
      "\n",
      "-2 -9 0.5975\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6583/10000 (66%)\n",
      "\n",
      "-2 -8 0.6583\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6914/10000 (69%)\n",
      "\n",
      "-2 -7 0.6914\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 7249/10000 (72%)\n",
      "\n",
      "-2 -6 0.7249\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7345/10000 (73%)\n",
      "\n",
      "-2 -5 0.7345\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7484/10000 (75%)\n",
      "\n",
      "-2 -4 0.7484\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7567/10000 (76%)\n",
      "\n",
      "-2 -3 0.7567\n",
      "\n",
      "Test set: Average loss: 0.0077, Accuracy: 7712/10000 (77%)\n",
      "\n",
      "-2 -2 0.7712\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 7778/10000 (78%)\n",
      "\n",
      "-2 -1 0.7778\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 7811/10000 (78%)\n",
      "\n",
      "-2 0 0.7811\n",
      "\n",
      "Test set: Average loss: 0.0077, Accuracy: 7788/10000 (78%)\n",
      "\n",
      "-2 1 0.7788\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 7621/10000 (76%)\n",
      "\n",
      "-2 2 0.7621\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7420/10000 (74%)\n",
      "\n",
      "-2 3 0.742\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7351/10000 (74%)\n",
      "\n",
      "-2 4 0.7351\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7217/10000 (72%)\n",
      "\n",
      "-2 5 0.7217\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 6992/10000 (70%)\n",
      "\n",
      "-2 6 0.6992\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6743/10000 (67%)\n",
      "\n",
      "-2 7 0.6743\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6421/10000 (64%)\n",
      "\n",
      "-2 8 0.6421\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5960/10000 (60%)\n",
      "\n",
      "-2 9 0.596\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5499/10000 (55%)\n",
      "\n",
      "-2 10 0.5499\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 5119/10000 (51%)\n",
      "\n",
      "-2 11 0.5119\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4563/10000 (46%)\n",
      "\n",
      "-2 12 0.4563\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 4010/10000 (40%)\n",
      "\n",
      "-2 13 0.401\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3508/10000 (35%)\n",
      "\n",
      "-2 14 0.3508\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2863/10000 (29%)\n",
      "\n",
      "-2 15 0.2863\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2557/10000 (26%)\n",
      "\n",
      "-2 16 0.2557\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2264/10000 (23%)\n",
      "\n",
      "-2 17 0.2264\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1968/10000 (20%)\n",
      "\n",
      "-2 18 0.1968\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1770/10000 (18%)\n",
      "\n",
      "-2 19 0.177\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 965/10000 (10%)\n",
      "\n",
      "-2 20 0.0965\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1401/10000 (14%)\n",
      "\n",
      "-2 21 0.1401\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1278/10000 (13%)\n",
      "\n",
      "-2 22 0.1278\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1216/10000 (12%)\n",
      "\n",
      "-2 23 0.1216\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 926/10000 (9%)\n",
      "\n",
      "-2 24 0.0926\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-2 25 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-2 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-2 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "-1 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-1 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 913/10000 (9%)\n",
      "\n",
      "-1 -25 0.0913\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "-1 -24 0.1162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1015/10000 (10%)\n",
      "\n",
      "-1 -23 0.1015\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "-1 -22 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1407/10000 (14%)\n",
      "\n",
      "-1 -21 0.1407\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1579/10000 (16%)\n",
      "\n",
      "-1 -20 0.1579\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1879/10000 (19%)\n",
      "\n",
      "-1 -19 0.1879\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2283/10000 (23%)\n",
      "\n",
      "-1 -18 0.2283\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2869/10000 (29%)\n",
      "\n",
      "-1 -17 0.2869\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 3369/10000 (34%)\n",
      "\n",
      "-1 -16 0.3369\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3967/10000 (40%)\n",
      "\n",
      "-1 -15 0.3967\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4401/10000 (44%)\n",
      "\n",
      "-1 -14 0.4401\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4688/10000 (47%)\n",
      "\n",
      "-1 -13 0.4688\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4894/10000 (49%)\n",
      "\n",
      "-1 -12 0.4894\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 5216/10000 (52%)\n",
      "\n",
      "-1 -11 0.5216\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5630/10000 (56%)\n",
      "\n",
      "-1 -10 0.563\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 6161/10000 (62%)\n",
      "\n",
      "-1 -9 0.6161\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6585/10000 (66%)\n",
      "\n",
      "-1 -8 0.6585\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7019/10000 (70%)\n",
      "\n",
      "-1 -7 0.7019\n",
      "\n",
      "Test set: Average loss: 0.0089, Accuracy: 7333/10000 (73%)\n",
      "\n",
      "-1 -6 0.7333\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7478/10000 (75%)\n",
      "\n",
      "-1 -5 0.7478\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7683/10000 (77%)\n",
      "\n",
      "-1 -4 0.7683\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7658/10000 (77%)\n",
      "\n",
      "-1 -3 0.7658\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7763/10000 (78%)\n",
      "\n",
      "-1 -2 0.7763\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 7903/10000 (79%)\n",
      "\n",
      "-1 -1 0.7903\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 7948/10000 (79%)\n",
      "\n",
      "-1 0 0.7948\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 7893/10000 (79%)\n",
      "\n",
      "-1 1 0.7893\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7789/10000 (78%)\n",
      "\n",
      "-1 2 0.7789\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7551/10000 (76%)\n",
      "\n",
      "-1 3 0.7551\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7419/10000 (74%)\n",
      "\n",
      "-1 4 0.7419\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7350/10000 (74%)\n",
      "\n",
      "-1 5 0.735\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7197/10000 (72%)\n",
      "\n",
      "-1 6 0.7197\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6893/10000 (69%)\n",
      "\n",
      "-1 7 0.6893\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6584/10000 (66%)\n",
      "\n",
      "-1 8 0.6584\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6069/10000 (61%)\n",
      "\n",
      "-1 9 0.6069\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5723/10000 (57%)\n",
      "\n",
      "-1 10 0.5723\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 5359/10000 (54%)\n",
      "\n",
      "-1 11 0.5359\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4900/10000 (49%)\n",
      "\n",
      "-1 12 0.49\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4305/10000 (43%)\n",
      "\n",
      "-1 13 0.4305\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3720/10000 (37%)\n",
      "\n",
      "-1 14 0.372\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3043/10000 (30%)\n",
      "\n",
      "-1 15 0.3043\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2738/10000 (27%)\n",
      "\n",
      "-1 16 0.2738\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2379/10000 (24%)\n",
      "\n",
      "-1 17 0.2379\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2079/10000 (21%)\n",
      "\n",
      "-1 18 0.2079\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1804/10000 (18%)\n",
      "\n",
      "-1 19 0.1804\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "-1 20 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1047/10000 (10%)\n",
      "\n",
      "-1 21 0.1047\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1290/10000 (13%)\n",
      "\n",
      "-1 22 0.129\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1219/10000 (12%)\n",
      "\n",
      "-1 23 0.1219\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "-1 24 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-1 25 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-1 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-1 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "0 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "0 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "0 -25 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "0 -24 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1240/10000 (12%)\n",
      "\n",
      "0 -23 0.124\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1323/10000 (13%)\n",
      "\n",
      "0 -22 0.1323\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1064/10000 (11%)\n",
      "\n",
      "0 -21 0.1064\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1704/10000 (17%)\n",
      "\n",
      "0 -20 0.1704\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 2023/10000 (20%)\n",
      "\n",
      "0 -19 0.2023\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2439/10000 (24%)\n",
      "\n",
      "0 -18 0.2439\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2689/10000 (27%)\n",
      "\n",
      "0 -17 0.2689\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 3453/10000 (35%)\n",
      "\n",
      "0 -16 0.3453\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3907/10000 (39%)\n",
      "\n",
      "0 -15 0.3907\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4285/10000 (43%)\n",
      "\n",
      "0 -14 0.4285\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4664/10000 (47%)\n",
      "\n",
      "0 -13 0.4664\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4894/10000 (49%)\n",
      "\n",
      "0 -12 0.4894\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 5202/10000 (52%)\n",
      "\n",
      "0 -11 0.5202\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5569/10000 (56%)\n",
      "\n",
      "0 -10 0.5569\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 6017/10000 (60%)\n",
      "\n",
      "0 -9 0.6017\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6604/10000 (66%)\n",
      "\n",
      "0 -8 0.6604\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6961/10000 (70%)\n",
      "\n",
      "0 -7 0.6961\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7382/10000 (74%)\n",
      "\n",
      "0 -6 0.7382\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7581/10000 (76%)\n",
      "\n",
      "0 -5 0.7581\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 7675/10000 (77%)\n",
      "\n",
      "0 -4 0.7675\n",
      "\n",
      "Test set: Average loss: 0.0078, Accuracy: 7773/10000 (78%)\n",
      "\n",
      "0 -3 0.7773\n",
      "\n",
      "Test set: Average loss: 0.0073, Accuracy: 7863/10000 (79%)\n",
      "\n",
      "0 -2 0.7863\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8028/10000 (80%)\n",
      "\n",
      "0 -1 0.8028\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 8039/10000 (80%)\n",
      "\n",
      "0 0 0.8039\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 7961/10000 (80%)\n",
      "\n",
      "0 1 0.7961\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 7883/10000 (79%)\n",
      "\n",
      "0 2 0.7883\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7765/10000 (78%)\n",
      "\n",
      "0 3 0.7765\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 7555/10000 (76%)\n",
      "\n",
      "0 4 0.7555\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7374/10000 (74%)\n",
      "\n",
      "0 5 0.7374\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7273/10000 (73%)\n",
      "\n",
      "0 6 0.7273\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 6973/10000 (70%)\n",
      "\n",
      "0 7 0.6973\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6735/10000 (67%)\n",
      "\n",
      "0 8 0.6735\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6385/10000 (64%)\n",
      "\n",
      "0 9 0.6385\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5919/10000 (59%)\n",
      "\n",
      "0 10 0.5919\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5515/10000 (55%)\n",
      "\n",
      "0 11 0.5515\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4953/10000 (50%)\n",
      "\n",
      "0 12 0.4953\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4350/10000 (44%)\n",
      "\n",
      "0 13 0.435\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3808/10000 (38%)\n",
      "\n",
      "0 14 0.3808\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3169/10000 (32%)\n",
      "\n",
      "0 15 0.3169\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2715/10000 (27%)\n",
      "\n",
      "0 16 0.2715\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2397/10000 (24%)\n",
      "\n",
      "0 17 0.2397\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 2110/10000 (21%)\n",
      "\n",
      "0 18 0.211\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1818/10000 (18%)\n",
      "\n",
      "0 19 0.1818\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1624/10000 (16%)\n",
      "\n",
      "0 20 0.1624\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1448/10000 (14%)\n",
      "\n",
      "0 21 0.1448\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1062/10000 (11%)\n",
      "\n",
      "0 22 0.1062\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 879/10000 (9%)\n",
      "\n",
      "0 23 0.0879\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 887/10000 (9%)\n",
      "\n",
      "0 24 0.0887\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 988/10000 (10%)\n",
      "\n",
      "0 25 0.0988\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "0 26 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "0 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "1 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "1 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "1 -25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 813/10000 (8%)\n",
      "\n",
      "1 -24 0.0813\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1224/10000 (12%)\n",
      "\n",
      "1 -23 0.1224\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1331/10000 (13%)\n",
      "\n",
      "1 -22 0.1331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1497/10000 (15%)\n",
      "\n",
      "1 -21 0.1497\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1748/10000 (17%)\n",
      "\n",
      "1 -20 0.1748\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2051/10000 (21%)\n",
      "\n",
      "1 -19 0.2051\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2492/10000 (25%)\n",
      "\n",
      "1 -18 0.2492\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2893/10000 (29%)\n",
      "\n",
      "1 -17 0.2893\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 3360/10000 (34%)\n",
      "\n",
      "1 -16 0.336\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3803/10000 (38%)\n",
      "\n",
      "1 -15 0.3803\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 4107/10000 (41%)\n",
      "\n",
      "1 -14 0.4107\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4386/10000 (44%)\n",
      "\n",
      "1 -13 0.4386\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4752/10000 (48%)\n",
      "\n",
      "1 -12 0.4752\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4996/10000 (50%)\n",
      "\n",
      "1 -11 0.4996\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5389/10000 (54%)\n",
      "\n",
      "1 -10 0.5389\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 6000/10000 (60%)\n",
      "\n",
      "1 -9 0.6\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6468/10000 (65%)\n",
      "\n",
      "1 -8 0.6468\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6859/10000 (69%)\n",
      "\n",
      "1 -7 0.6859\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7236/10000 (72%)\n",
      "\n",
      "1 -6 0.7236\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7436/10000 (74%)\n",
      "\n",
      "1 -5 0.7436\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7561/10000 (76%)\n",
      "\n",
      "1 -4 0.7561\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7671/10000 (77%)\n",
      "\n",
      "1 -3 0.7671\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7857/10000 (79%)\n",
      "\n",
      "1 -2 0.7857\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 7997/10000 (80%)\n",
      "\n",
      "1 -1 0.7997\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8007/10000 (80%)\n",
      "\n",
      "1 0 0.8007\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 7989/10000 (80%)\n",
      "\n",
      "1 1 0.7989\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 7880/10000 (79%)\n",
      "\n",
      "1 2 0.788\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7725/10000 (77%)\n",
      "\n",
      "1 3 0.7725\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7530/10000 (75%)\n",
      "\n",
      "1 4 0.753\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7401/10000 (74%)\n",
      "\n",
      "1 5 0.7401\n",
      "\n",
      "Test set: Average loss: 0.0089, Accuracy: 7275/10000 (73%)\n",
      "\n",
      "1 6 0.7275\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 6969/10000 (70%)\n",
      "\n",
      "1 7 0.6969\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6700/10000 (67%)\n",
      "\n",
      "1 8 0.67\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6446/10000 (64%)\n",
      "\n",
      "1 9 0.6446\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5966/10000 (60%)\n",
      "\n",
      "1 10 0.5966\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5469/10000 (55%)\n",
      "\n",
      "1 11 0.5469\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4916/10000 (49%)\n",
      "\n",
      "1 12 0.4916\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4364/10000 (44%)\n",
      "\n",
      "1 13 0.4364\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3695/10000 (37%)\n",
      "\n",
      "1 14 0.3695\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3233/10000 (32%)\n",
      "\n",
      "1 15 0.3233\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2438/10000 (24%)\n",
      "\n",
      "1 16 0.2438\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1804/10000 (18%)\n",
      "\n",
      "1 17 0.1804\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2157/10000 (22%)\n",
      "\n",
      "1 18 0.2157\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1827/10000 (18%)\n",
      "\n",
      "1 19 0.1827\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1629/10000 (16%)\n",
      "\n",
      "1 20 0.1629\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 772/10000 (8%)\n",
      "\n",
      "1 21 0.0772\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1075/10000 (11%)\n",
      "\n",
      "1 22 0.1075\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1230/10000 (12%)\n",
      "\n",
      "1 23 0.123\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1165/10000 (12%)\n",
      "\n",
      "1 24 0.1165\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 979/10000 (10%)\n",
      "\n",
      "1 25 0.0979\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "1 26 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "1 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "2 -27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "2 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 954/10000 (10%)\n",
      "\n",
      "2 -25 0.0954\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "2 -24 0.117\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 581/10000 (6%)\n",
      "\n",
      "2 -23 0.0581\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1119/10000 (11%)\n",
      "\n",
      "2 -22 0.1119\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1551/10000 (16%)\n",
      "\n",
      "2 -21 0.1551\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1751/10000 (18%)\n",
      "\n",
      "2 -20 0.1751\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2065/10000 (21%)\n",
      "\n",
      "2 -19 0.2065\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2478/10000 (25%)\n",
      "\n",
      "2 -18 0.2478\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2883/10000 (29%)\n",
      "\n",
      "2 -17 0.2883\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 3221/10000 (32%)\n",
      "\n",
      "2 -16 0.3221\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3598/10000 (36%)\n",
      "\n",
      "2 -15 0.3598\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3928/10000 (39%)\n",
      "\n",
      "2 -14 0.3928\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4164/10000 (42%)\n",
      "\n",
      "2 -13 0.4164\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4421/10000 (44%)\n",
      "\n",
      "2 -12 0.4421\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4693/10000 (47%)\n",
      "\n",
      "2 -11 0.4693\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 5230/10000 (52%)\n",
      "\n",
      "2 -10 0.523\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5677/10000 (57%)\n",
      "\n",
      "2 -9 0.5677\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 6224/10000 (62%)\n",
      "\n",
      "2 -8 0.6224\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6757/10000 (68%)\n",
      "\n",
      "2 -7 0.6757\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 7019/10000 (70%)\n",
      "\n",
      "2 -6 0.7019\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 7339/10000 (73%)\n",
      "\n",
      "2 -5 0.7339\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7541/10000 (75%)\n",
      "\n",
      "2 -4 0.7541\n",
      "\n",
      "Test set: Average loss: 0.0082, Accuracy: 7605/10000 (76%)\n",
      "\n",
      "2 -3 0.7605\n",
      "\n",
      "Test set: Average loss: 0.0077, Accuracy: 7758/10000 (78%)\n",
      "\n",
      "2 -2 0.7758\n",
      "\n",
      "Test set: Average loss: 0.0077, Accuracy: 7902/10000 (79%)\n",
      "\n",
      "2 -1 0.7902\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 7978/10000 (80%)\n",
      "\n",
      "2 0 0.7978\n",
      "\n",
      "Test set: Average loss: 0.0073, Accuracy: 7898/10000 (79%)\n",
      "\n",
      "2 1 0.7898\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7854/10000 (79%)\n",
      "\n",
      "2 2 0.7854\n",
      "\n",
      "Test set: Average loss: 0.0082, Accuracy: 7684/10000 (77%)\n",
      "\n",
      "2 3 0.7684\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7504/10000 (75%)\n",
      "\n",
      "2 4 0.7504\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7306/10000 (73%)\n",
      "\n",
      "2 5 0.7306\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7093/10000 (71%)\n",
      "\n",
      "2 6 0.7093\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6853/10000 (69%)\n",
      "\n",
      "2 7 0.6853\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6531/10000 (65%)\n",
      "\n",
      "2 8 0.6531\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6215/10000 (62%)\n",
      "\n",
      "2 9 0.6215\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5743/10000 (57%)\n",
      "\n",
      "2 10 0.5743\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 5283/10000 (53%)\n",
      "\n",
      "2 11 0.5283\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4773/10000 (48%)\n",
      "\n",
      "2 12 0.4773\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4102/10000 (41%)\n",
      "\n",
      "2 13 0.4102\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3565/10000 (36%)\n",
      "\n",
      "2 14 0.3565\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3063/10000 (31%)\n",
      "\n",
      "2 15 0.3063\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2717/10000 (27%)\n",
      "\n",
      "2 16 0.2717\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1805/10000 (18%)\n",
      "\n",
      "2 17 0.1805\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1346/10000 (13%)\n",
      "\n",
      "2 18 0.1346\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1854/10000 (19%)\n",
      "\n",
      "2 19 0.1854\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1587/10000 (16%)\n",
      "\n",
      "2 20 0.1587\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1426/10000 (14%)\n",
      "\n",
      "2 21 0.1426\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1283/10000 (13%)\n",
      "\n",
      "2 22 0.1283\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 878/10000 (9%)\n",
      "\n",
      "2 23 0.0878\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "2 24 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "2 25 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "2 26 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "2 27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "3 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "3 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "3 -25 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1049/10000 (10%)\n",
      "\n",
      "3 -24 0.1049\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "3 -23 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 829/10000 (8%)\n",
      "\n",
      "3 -22 0.0829\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 644/10000 (6%)\n",
      "\n",
      "3 -21 0.0644\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1795/10000 (18%)\n",
      "\n",
      "3 -20 0.1795\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 2136/10000 (21%)\n",
      "\n",
      "3 -19 0.2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2417/10000 (24%)\n",
      "\n",
      "3 -18 0.2417\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2736/10000 (27%)\n",
      "\n",
      "3 -17 0.2736\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2985/10000 (30%)\n",
      "\n",
      "3 -16 0.2985\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 3250/10000 (32%)\n",
      "\n",
      "3 -15 0.325\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3544/10000 (35%)\n",
      "\n",
      "3 -14 0.3544\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3862/10000 (39%)\n",
      "\n",
      "3 -13 0.3862\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 4119/10000 (41%)\n",
      "\n",
      "3 -12 0.4119\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4516/10000 (45%)\n",
      "\n",
      "3 -11 0.4516\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4951/10000 (50%)\n",
      "\n",
      "3 -10 0.4951\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 5605/10000 (56%)\n",
      "\n",
      "3 -9 0.5605\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 6169/10000 (62%)\n",
      "\n",
      "3 -8 0.6169\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6504/10000 (65%)\n",
      "\n",
      "3 -7 0.6504\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6893/10000 (69%)\n",
      "\n",
      "3 -6 0.6893\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 7160/10000 (72%)\n",
      "\n",
      "3 -5 0.716\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7374/10000 (74%)\n",
      "\n",
      "3 -4 0.7374\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7560/10000 (76%)\n",
      "\n",
      "3 -3 0.756\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7660/10000 (77%)\n",
      "\n",
      "3 -2 0.766\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7744/10000 (77%)\n",
      "\n",
      "3 -1 0.7744\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 7928/10000 (79%)\n",
      "\n",
      "3 0 0.7928\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 7888/10000 (79%)\n",
      "\n",
      "3 1 0.7888\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7826/10000 (78%)\n",
      "\n",
      "3 2 0.7826\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7659/10000 (77%)\n",
      "\n",
      "3 3 0.7659\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7406/10000 (74%)\n",
      "\n",
      "3 4 0.7406\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7142/10000 (71%)\n",
      "\n",
      "3 5 0.7142\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6896/10000 (69%)\n",
      "\n",
      "3 6 0.6896\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6676/10000 (67%)\n",
      "\n",
      "3 7 0.6676\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6363/10000 (64%)\n",
      "\n",
      "3 8 0.6363\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5948/10000 (59%)\n",
      "\n",
      "3 9 0.5948\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5583/10000 (56%)\n",
      "\n",
      "3 10 0.5583\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5024/10000 (50%)\n",
      "\n",
      "3 11 0.5024\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4522/10000 (45%)\n",
      "\n",
      "3 12 0.4522\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4025/10000 (40%)\n",
      "\n",
      "3 13 0.4025\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3486/10000 (35%)\n",
      "\n",
      "3 14 0.3486\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2941/10000 (29%)\n",
      "\n",
      "3 15 0.2941\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2644/10000 (26%)\n",
      "\n",
      "3 16 0.2644\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1793/10000 (18%)\n",
      "\n",
      "3 17 0.1793\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2039/10000 (20%)\n",
      "\n",
      "3 18 0.2039\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1003/10000 (10%)\n",
      "\n",
      "3 19 0.1003\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1568/10000 (16%)\n",
      "\n",
      "3 20 0.1568\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 982/10000 (10%)\n",
      "\n",
      "3 21 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1305/10000 (13%)\n",
      "\n",
      "3 22 0.1305\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1209/10000 (12%)\n",
      "\n",
      "3 23 0.1209\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "3 24 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "3 25 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "3 26 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "3 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "4 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "4 -26 0.114\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "4 -25 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1045/10000 (10%)\n",
      "\n",
      "4 -24 0.1045\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1264/10000 (13%)\n",
      "\n",
      "4 -23 0.1264\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1414/10000 (14%)\n",
      "\n",
      "4 -22 0.1414\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1627/10000 (16%)\n",
      "\n",
      "4 -21 0.1627\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1848/10000 (18%)\n",
      "\n",
      "4 -20 0.1848\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 2084/10000 (21%)\n",
      "\n",
      "4 -19 0.2084\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1782/10000 (18%)\n",
      "\n",
      "4 -18 0.1782\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2551/10000 (26%)\n",
      "\n",
      "4 -17 0.2551\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2710/10000 (27%)\n",
      "\n",
      "4 -16 0.271\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2932/10000 (29%)\n",
      "\n",
      "4 -15 0.2932\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 3220/10000 (32%)\n",
      "\n",
      "4 -14 0.322\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3431/10000 (34%)\n",
      "\n",
      "4 -13 0.3431\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3883/10000 (39%)\n",
      "\n",
      "4 -12 0.3883\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 4250/10000 (42%)\n",
      "\n",
      "4 -11 0.425\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4812/10000 (48%)\n",
      "\n",
      "4 -10 0.4812\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5361/10000 (54%)\n",
      "\n",
      "4 -9 0.5361\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5981/10000 (60%)\n",
      "\n",
      "4 -8 0.5981\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6494/10000 (65%)\n",
      "\n",
      "4 -7 0.6494\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6794/10000 (68%)\n",
      "\n",
      "4 -6 0.6794\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 7060/10000 (71%)\n",
      "\n",
      "4 -5 0.706\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7238/10000 (72%)\n",
      "\n",
      "4 -4 0.7238\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7349/10000 (73%)\n",
      "\n",
      "4 -3 0.7349\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7548/10000 (75%)\n",
      "\n",
      "4 -2 0.7548\n",
      "\n",
      "Test set: Average loss: 0.0082, Accuracy: 7673/10000 (77%)\n",
      "\n",
      "4 -1 0.7673\n",
      "\n",
      "Test set: Average loss: 0.0077, Accuracy: 7765/10000 (78%)\n",
      "\n",
      "4 0 0.7765\n",
      "\n",
      "Test set: Average loss: 0.0078, Accuracy: 7767/10000 (78%)\n",
      "\n",
      "4 1 0.7767\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7695/10000 (77%)\n",
      "\n",
      "4 2 0.7695\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7476/10000 (75%)\n",
      "\n",
      "4 3 0.7476\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7192/10000 (72%)\n",
      "\n",
      "4 4 0.7192\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6900/10000 (69%)\n",
      "\n",
      "4 5 0.69\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 6598/10000 (66%)\n",
      "\n",
      "4 6 0.6598\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6312/10000 (63%)\n",
      "\n",
      "4 7 0.6312\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6004/10000 (60%)\n",
      "\n",
      "4 8 0.6004\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5634/10000 (56%)\n",
      "\n",
      "4 9 0.5634\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 5262/10000 (53%)\n",
      "\n",
      "4 10 0.5262\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4778/10000 (48%)\n",
      "\n",
      "4 11 0.4778\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4324/10000 (43%)\n",
      "\n",
      "4 12 0.4324\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3753/10000 (38%)\n",
      "\n",
      "4 13 0.3753\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3263/10000 (33%)\n",
      "\n",
      "4 14 0.3263\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2845/10000 (28%)\n",
      "\n",
      "4 15 0.2845\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2590/10000 (26%)\n",
      "\n",
      "4 16 0.259\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2214/10000 (22%)\n",
      "\n",
      "4 17 0.2214\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1989/10000 (20%)\n",
      "\n",
      "4 18 0.1989\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1716/10000 (17%)\n",
      "\n",
      "4 19 0.1716\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1542/10000 (15%)\n",
      "\n",
      "4 20 0.1542\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1364/10000 (14%)\n",
      "\n",
      "4 21 0.1364\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1266/10000 (13%)\n",
      "\n",
      "4 22 0.1266\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1210/10000 (12%)\n",
      "\n",
      "4 23 0.121\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "4 24 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "4 25 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1012/10000 (10%)\n",
      "\n",
      "4 26 0.1012\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 959/10000 (10%)\n",
      "\n",
      "4 27 0.0959\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "5 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "5 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "5 -25 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "5 -24 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "5 -23 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1396/10000 (14%)\n",
      "\n",
      "5 -22 0.1396\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1674/10000 (17%)\n",
      "\n",
      "5 -21 0.1674\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1300/10000 (13%)\n",
      "\n",
      "5 -20 0.13\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 2054/10000 (21%)\n",
      "\n",
      "5 -19 0.2054\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2256/10000 (23%)\n",
      "\n",
      "5 -18 0.2256\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2452/10000 (25%)\n",
      "\n",
      "5 -17 0.2452\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2548/10000 (25%)\n",
      "\n",
      "5 -16 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2760/10000 (28%)\n",
      "\n",
      "5 -15 0.276\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2950/10000 (30%)\n",
      "\n",
      "5 -14 0.295\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 3312/10000 (33%)\n",
      "\n",
      "5 -13 0.3312\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3629/10000 (36%)\n",
      "\n",
      "5 -12 0.3629\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 4084/10000 (41%)\n",
      "\n",
      "5 -11 0.4084\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4685/10000 (47%)\n",
      "\n",
      "5 -10 0.4685\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 5259/10000 (53%)\n",
      "\n",
      "5 -9 0.5259\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5872/10000 (59%)\n",
      "\n",
      "5 -8 0.5872\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6269/10000 (63%)\n",
      "\n",
      "5 -7 0.6269\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6680/10000 (67%)\n",
      "\n",
      "5 -6 0.668\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6859/10000 (69%)\n",
      "\n",
      "5 -5 0.6859\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6983/10000 (70%)\n",
      "\n",
      "5 -4 0.6983\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7151/10000 (72%)\n",
      "\n",
      "5 -3 0.7151\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 7341/10000 (73%)\n",
      "\n",
      "5 -2 0.7341\n",
      "\n",
      "Test set: Average loss: 0.0089, Accuracy: 7414/10000 (74%)\n",
      "\n",
      "5 -1 0.7414\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7524/10000 (75%)\n",
      "\n",
      "5 0 0.7524\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 7500/10000 (75%)\n",
      "\n",
      "5 1 0.75\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7460/10000 (75%)\n",
      "\n",
      "5 2 0.746\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 7289/10000 (73%)\n",
      "\n",
      "5 3 0.7289\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6895/10000 (69%)\n",
      "\n",
      "5 4 0.6895\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6594/10000 (66%)\n",
      "\n",
      "5 5 0.6594\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6228/10000 (62%)\n",
      "\n",
      "5 6 0.6228\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6058/10000 (61%)\n",
      "\n",
      "5 7 0.6058\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5732/10000 (57%)\n",
      "\n",
      "5 8 0.5732\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5338/10000 (53%)\n",
      "\n",
      "5 9 0.5338\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4915/10000 (49%)\n",
      "\n",
      "5 10 0.4915\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4489/10000 (45%)\n",
      "\n",
      "5 11 0.4489\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4003/10000 (40%)\n",
      "\n",
      "5 12 0.4003\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3513/10000 (35%)\n",
      "\n",
      "5 13 0.3513\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3078/10000 (31%)\n",
      "\n",
      "5 14 0.3078\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2801/10000 (28%)\n",
      "\n",
      "5 15 0.2801\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2481/10000 (25%)\n",
      "\n",
      "5 16 0.2481\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2154/10000 (22%)\n",
      "\n",
      "5 17 0.2154\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1914/10000 (19%)\n",
      "\n",
      "5 18 0.1914\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1639/10000 (16%)\n",
      "\n",
      "5 19 0.1639\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 711/10000 (7%)\n",
      "\n",
      "5 20 0.0711\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 906/10000 (9%)\n",
      "\n",
      "5 21 0.0906\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1027/10000 (10%)\n",
      "\n",
      "5 22 0.1027\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1202/10000 (12%)\n",
      "\n",
      "5 23 0.1202\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "5 24 0.1162\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 986/10000 (10%)\n",
      "\n",
      "5 25 0.0986\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "5 26 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "5 27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "6 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "6 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "6 -25 0.115\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1196/10000 (12%)\n",
      "\n",
      "6 -24 0.1196\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1269/10000 (13%)\n",
      "\n",
      "6 -23 0.1269\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1423/10000 (14%)\n",
      "\n",
      "6 -22 0.1423\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1636/10000 (16%)\n",
      "\n",
      "6 -21 0.1636\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1300/10000 (13%)\n",
      "\n",
      "6 -20 0.13\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1296/10000 (13%)\n",
      "\n",
      "6 -19 0.1296\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2187/10000 (22%)\n",
      "\n",
      "6 -18 0.2187\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2312/10000 (23%)\n",
      "\n",
      "6 -17 0.2312\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2383/10000 (24%)\n",
      "\n",
      "6 -16 0.2383\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2653/10000 (27%)\n",
      "\n",
      "6 -15 0.2653\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2791/10000 (28%)\n",
      "\n",
      "6 -14 0.2791\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 3132/10000 (31%)\n",
      "\n",
      "6 -13 0.3132\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3526/10000 (35%)\n",
      "\n",
      "6 -12 0.3526\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 4060/10000 (41%)\n",
      "\n",
      "6 -11 0.406\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4539/10000 (45%)\n",
      "\n",
      "6 -10 0.4539\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 5101/10000 (51%)\n",
      "\n",
      "6 -9 0.5101\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5702/10000 (57%)\n",
      "\n",
      "6 -8 0.5702\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 6154/10000 (62%)\n",
      "\n",
      "6 -7 0.6154\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6492/10000 (65%)\n",
      "\n",
      "6 -6 0.6492\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6614/10000 (66%)\n",
      "\n",
      "6 -5 0.6614\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6809/10000 (68%)\n",
      "\n",
      "6 -4 0.6809\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6983/10000 (70%)\n",
      "\n",
      "6 -3 0.6983\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 7084/10000 (71%)\n",
      "\n",
      "6 -2 0.7084\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7112/10000 (71%)\n",
      "\n",
      "6 -1 0.7112\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 7117/10000 (71%)\n",
      "\n",
      "6 0 0.7117\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7140/10000 (71%)\n",
      "\n",
      "6 1 0.714\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7031/10000 (70%)\n",
      "\n",
      "6 2 0.7031\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6805/10000 (68%)\n",
      "\n",
      "6 3 0.6805\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6554/10000 (66%)\n",
      "\n",
      "6 4 0.6554\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6183/10000 (62%)\n",
      "\n",
      "6 5 0.6183\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5856/10000 (59%)\n",
      "\n",
      "6 6 0.5856\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5568/10000 (56%)\n",
      "\n",
      "6 7 0.5568\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 5180/10000 (52%)\n",
      "\n",
      "6 8 0.518\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4884/10000 (49%)\n",
      "\n",
      "6 9 0.4884\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4534/10000 (45%)\n",
      "\n",
      "6 10 0.4534\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4108/10000 (41%)\n",
      "\n",
      "6 11 0.4108\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3693/10000 (37%)\n",
      "\n",
      "6 12 0.3693\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3373/10000 (34%)\n",
      "\n",
      "6 13 0.3373\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2962/10000 (30%)\n",
      "\n",
      "6 14 0.2962\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2626/10000 (26%)\n",
      "\n",
      "6 15 0.2626\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2365/10000 (24%)\n",
      "\n",
      "6 16 0.2365\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2091/10000 (21%)\n",
      "\n",
      "6 17 0.2091\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1094/10000 (11%)\n",
      "\n",
      "6 18 0.1094\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 852/10000 (9%)\n",
      "\n",
      "6 19 0.0852\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1451/10000 (15%)\n",
      "\n",
      "6 20 0.1451\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 905/10000 (9%)\n",
      "\n",
      "6 21 0.0905\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 687/10000 (7%)\n",
      "\n",
      "6 22 0.0687\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "6 23 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1029/10000 (10%)\n",
      "\n",
      "6 24 0.1029\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "6 25 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "6 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "6 27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "7 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "7 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "7 -25 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1179/10000 (12%)\n",
      "\n",
      "7 -24 0.1179\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1273/10000 (13%)\n",
      "\n",
      "7 -23 0.1273\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1394/10000 (14%)\n",
      "\n",
      "7 -22 0.1394\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1569/10000 (16%)\n",
      "\n",
      "7 -21 0.1569\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1736/10000 (17%)\n",
      "\n",
      "7 -20 0.1736\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1227/10000 (12%)\n",
      "\n",
      "7 -19 0.1227\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 2131/10000 (21%)\n",
      "\n",
      "7 -18 0.2131\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 2287/10000 (23%)\n",
      "\n",
      "7 -17 0.2287\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2393/10000 (24%)\n",
      "\n",
      "7 -16 0.2393\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2530/10000 (25%)\n",
      "\n",
      "7 -15 0.253\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2701/10000 (27%)\n",
      "\n",
      "7 -14 0.2701\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 3009/10000 (30%)\n",
      "\n",
      "7 -13 0.3009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3309/10000 (33%)\n",
      "\n",
      "7 -12 0.3309\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3870/10000 (39%)\n",
      "\n",
      "7 -11 0.387\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4388/10000 (44%)\n",
      "\n",
      "7 -10 0.4388\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4924/10000 (49%)\n",
      "\n",
      "7 -9 0.4924\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5549/10000 (55%)\n",
      "\n",
      "7 -8 0.5549\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5868/10000 (59%)\n",
      "\n",
      "7 -7 0.5868\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6144/10000 (61%)\n",
      "\n",
      "7 -6 0.6144\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6390/10000 (64%)\n",
      "\n",
      "7 -5 0.639\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6581/10000 (66%)\n",
      "\n",
      "7 -4 0.6581\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 6673/10000 (67%)\n",
      "\n",
      "7 -3 0.6673\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6797/10000 (68%)\n",
      "\n",
      "7 -2 0.6797\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6856/10000 (69%)\n",
      "\n",
      "7 -1 0.6856\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6846/10000 (68%)\n",
      "\n",
      "7 0 0.6846\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6840/10000 (68%)\n",
      "\n",
      "7 1 0.684\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6758/10000 (68%)\n",
      "\n",
      "7 2 0.6758\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6477/10000 (65%)\n",
      "\n",
      "7 3 0.6477\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6165/10000 (62%)\n",
      "\n",
      "7 4 0.6165\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5867/10000 (59%)\n",
      "\n",
      "7 5 0.5867\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5492/10000 (55%)\n",
      "\n",
      "7 6 0.5492\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5225/10000 (52%)\n",
      "\n",
      "7 7 0.5225\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4876/10000 (49%)\n",
      "\n",
      "7 8 0.4876\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4532/10000 (45%)\n",
      "\n",
      "7 9 0.4532\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4270/10000 (43%)\n",
      "\n",
      "7 10 0.427\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 3940/10000 (39%)\n",
      "\n",
      "7 11 0.394\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3548/10000 (35%)\n",
      "\n",
      "7 12 0.3548\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3286/10000 (33%)\n",
      "\n",
      "7 13 0.3286\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2915/10000 (29%)\n",
      "\n",
      "7 14 0.2915\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2626/10000 (26%)\n",
      "\n",
      "7 15 0.2626\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2392/10000 (24%)\n",
      "\n",
      "7 16 0.2392\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2013/10000 (20%)\n",
      "\n",
      "7 17 0.2013\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1008/10000 (10%)\n",
      "\n",
      "7 18 0.1008\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1580/10000 (16%)\n",
      "\n",
      "7 19 0.158\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1446/10000 (14%)\n",
      "\n",
      "7 20 0.1446\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1330/10000 (13%)\n",
      "\n",
      "7 21 0.133\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "7 22 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "7 23 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "7 24 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1015/10000 (10%)\n",
      "\n",
      "7 25 0.1015\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "7 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 974/10000 (10%)\n",
      "\n",
      "7 27 0.0974\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "8 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "8 -26 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1025/10000 (10%)\n",
      "\n",
      "8 -25 0.1025\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "8 -24 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1260/10000 (13%)\n",
      "\n",
      "8 -23 0.126\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1390/10000 (14%)\n",
      "\n",
      "8 -22 0.139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1540/10000 (15%)\n",
      "\n",
      "8 -21 0.154\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 970/10000 (10%)\n",
      "\n",
      "8 -20 0.097\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1225/10000 (12%)\n",
      "\n",
      "8 -19 0.1225\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1954/10000 (20%)\n",
      "\n",
      "8 -18 0.1954\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1794/10000 (18%)\n",
      "\n",
      "8 -17 0.1794\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2241/10000 (22%)\n",
      "\n",
      "8 -16 0.2241\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2388/10000 (24%)\n",
      "\n",
      "8 -15 0.2388\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2596/10000 (26%)\n",
      "\n",
      "8 -14 0.2596\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2806/10000 (28%)\n",
      "\n",
      "8 -13 0.2806\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 3198/10000 (32%)\n",
      "\n",
      "8 -12 0.3198\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3567/10000 (36%)\n",
      "\n",
      "8 -11 0.3567\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4194/10000 (42%)\n",
      "\n",
      "8 -10 0.4194\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4893/10000 (49%)\n",
      "\n",
      "8 -9 0.4893\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5263/10000 (53%)\n",
      "\n",
      "8 -8 0.5263\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5646/10000 (56%)\n",
      "\n",
      "8 -7 0.5646\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5909/10000 (59%)\n",
      "\n",
      "8 -6 0.5909\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 6120/10000 (61%)\n",
      "\n",
      "8 -5 0.612\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6333/10000 (63%)\n",
      "\n",
      "8 -4 0.6333\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6523/10000 (65%)\n",
      "\n",
      "8 -3 0.6523\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6550/10000 (66%)\n",
      "\n",
      "8 -2 0.655\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6650/10000 (66%)\n",
      "\n",
      "8 -1 0.665\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6568/10000 (66%)\n",
      "\n",
      "8 0 0.6568\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 6569/10000 (66%)\n",
      "\n",
      "8 1 0.6569\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6375/10000 (64%)\n",
      "\n",
      "8 2 0.6375\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6235/10000 (62%)\n",
      "\n",
      "8 3 0.6235\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5932/10000 (59%)\n",
      "\n",
      "8 4 0.5932\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5593/10000 (56%)\n",
      "\n",
      "8 5 0.5593\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5292/10000 (53%)\n",
      "\n",
      "8 6 0.5292\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5023/10000 (50%)\n",
      "\n",
      "8 7 0.5023\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4681/10000 (47%)\n",
      "\n",
      "8 8 0.4681\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4396/10000 (44%)\n",
      "\n",
      "8 9 0.4396\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4061/10000 (41%)\n",
      "\n",
      "8 10 0.4061\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3863/10000 (39%)\n",
      "\n",
      "8 11 0.3863\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3476/10000 (35%)\n",
      "\n",
      "8 12 0.3476\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3103/10000 (31%)\n",
      "\n",
      "8 13 0.3103\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2894/10000 (29%)\n",
      "\n",
      "8 14 0.2894\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2527/10000 (25%)\n",
      "\n",
      "8 15 0.2527\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2372/10000 (24%)\n",
      "\n",
      "8 16 0.2372\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1379/10000 (14%)\n",
      "\n",
      "8 17 0.1379\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1839/10000 (18%)\n",
      "\n",
      "8 18 0.1839\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1665/10000 (17%)\n",
      "\n",
      "8 19 0.1665\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1450/10000 (14%)\n",
      "\n",
      "8 20 0.145\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1327/10000 (13%)\n",
      "\n",
      "8 21 0.1327\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1249/10000 (12%)\n",
      "\n",
      "8 22 0.1249\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "8 23 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "8 24 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "8 25 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1012/10000 (10%)\n",
      "\n",
      "8 26 0.1012\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "8 27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "9 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1029/10000 (10%)\n",
      "\n",
      "9 -26 0.1029\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "9 -25 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "9 -24 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1259/10000 (13%)\n",
      "\n",
      "9 -23 0.1259\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1112/10000 (11%)\n",
      "\n",
      "9 -22 0.1112\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1463/10000 (15%)\n",
      "\n",
      "9 -21 0.1463\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1634/10000 (16%)\n",
      "\n",
      "9 -20 0.1634\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1774/10000 (18%)\n",
      "\n",
      "9 -19 0.1774\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1921/10000 (19%)\n",
      "\n",
      "9 -18 0.1921\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 2005/10000 (20%)\n",
      "\n",
      "9 -17 0.2005\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 2114/10000 (21%)\n",
      "\n",
      "9 -16 0.2114\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2276/10000 (23%)\n",
      "\n",
      "9 -15 0.2276\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2542/10000 (25%)\n",
      "\n",
      "9 -14 0.2542\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2644/10000 (26%)\n",
      "\n",
      "9 -13 0.2644\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 3039/10000 (30%)\n",
      "\n",
      "9 -12 0.3039\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3548/10000 (35%)\n",
      "\n",
      "9 -11 0.3548\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 4116/10000 (41%)\n",
      "\n",
      "9 -10 0.4116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4556/10000 (46%)\n",
      "\n",
      "9 -9 0.4556\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 4996/10000 (50%)\n",
      "\n",
      "9 -8 0.4996\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 5341/10000 (53%)\n",
      "\n",
      "9 -7 0.5341\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5600/10000 (56%)\n",
      "\n",
      "9 -6 0.56\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5820/10000 (58%)\n",
      "\n",
      "9 -5 0.582\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6047/10000 (60%)\n",
      "\n",
      "9 -4 0.6047\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6298/10000 (63%)\n",
      "\n",
      "9 -3 0.6298\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6310/10000 (63%)\n",
      "\n",
      "9 -2 0.631\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6231/10000 (62%)\n",
      "\n",
      "9 -1 0.6231\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6219/10000 (62%)\n",
      "\n",
      "9 0 0.6219\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6205/10000 (62%)\n",
      "\n",
      "9 1 0.6205\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 5983/10000 (60%)\n",
      "\n",
      "9 2 0.5983\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 5879/10000 (59%)\n",
      "\n",
      "9 3 0.5879\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5639/10000 (56%)\n",
      "\n",
      "9 4 0.5639\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5414/10000 (54%)\n",
      "\n",
      "9 5 0.5414\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5035/10000 (50%)\n",
      "\n",
      "9 6 0.5035\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4728/10000 (47%)\n",
      "\n",
      "9 7 0.4728\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4415/10000 (44%)\n",
      "\n",
      "9 8 0.4415\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4130/10000 (41%)\n",
      "\n",
      "9 9 0.413\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3943/10000 (39%)\n",
      "\n",
      "9 10 0.3943\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3638/10000 (36%)\n",
      "\n",
      "9 11 0.3638\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3454/10000 (35%)\n",
      "\n",
      "9 12 0.3454\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3060/10000 (31%)\n",
      "\n",
      "9 13 0.306\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2789/10000 (28%)\n",
      "\n",
      "9 14 0.2789\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2502/10000 (25%)\n",
      "\n",
      "9 15 0.2502\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1927/10000 (19%)\n",
      "\n",
      "9 16 0.1927\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 2017/10000 (20%)\n",
      "\n",
      "9 17 0.2017\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 849/10000 (8%)\n",
      "\n",
      "9 18 0.0849\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1627/10000 (16%)\n",
      "\n",
      "9 19 0.1627\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1476/10000 (15%)\n",
      "\n",
      "9 20 0.1476\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 899/10000 (9%)\n",
      "\n",
      "9 21 0.0899\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 995/10000 (10%)\n",
      "\n",
      "9 22 0.0995\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "9 23 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 989/10000 (10%)\n",
      "\n",
      "9 24 0.0989\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "9 25 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "9 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "9 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "10 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "10 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "10 -25 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1172/10000 (12%)\n",
      "\n",
      "10 -24 0.1172\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 794/10000 (8%)\n",
      "\n",
      "10 -23 0.0794\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1315/10000 (13%)\n",
      "\n",
      "10 -22 0.1315\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1440/10000 (14%)\n",
      "\n",
      "10 -21 0.144\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1589/10000 (16%)\n",
      "\n",
      "10 -20 0.1589\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1705/10000 (17%)\n",
      "\n",
      "10 -19 0.1705\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1773/10000 (18%)\n",
      "\n",
      "10 -18 0.1773\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1911/10000 (19%)\n",
      "\n",
      "10 -17 0.1911\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 2018/10000 (20%)\n",
      "\n",
      "10 -16 0.2018\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 2202/10000 (22%)\n",
      "\n",
      "10 -15 0.2202\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2352/10000 (24%)\n",
      "\n",
      "10 -14 0.2352\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2531/10000 (25%)\n",
      "\n",
      "10 -13 0.2531\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2889/10000 (29%)\n",
      "\n",
      "10 -12 0.2889\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3270/10000 (33%)\n",
      "\n",
      "10 -11 0.327\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3863/10000 (39%)\n",
      "\n",
      "10 -10 0.3863\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4287/10000 (43%)\n",
      "\n",
      "10 -9 0.4287\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4609/10000 (46%)\n",
      "\n",
      "10 -8 0.4609\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4994/10000 (50%)\n",
      "\n",
      "10 -7 0.4994\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5407/10000 (54%)\n",
      "\n",
      "10 -6 0.5407\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5608/10000 (56%)\n",
      "\n",
      "10 -5 0.5608\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5840/10000 (58%)\n",
      "\n",
      "10 -4 0.584\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5868/10000 (59%)\n",
      "\n",
      "10 -3 0.5868\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5946/10000 (59%)\n",
      "\n",
      "10 -2 0.5946\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5939/10000 (59%)\n",
      "\n",
      "10 -1 0.5939\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5801/10000 (58%)\n",
      "\n",
      "10 0 0.5801\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5725/10000 (57%)\n",
      "\n",
      "10 1 0.5725\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5618/10000 (56%)\n",
      "\n",
      "10 2 0.5618\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5471/10000 (55%)\n",
      "\n",
      "10 3 0.5471\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5307/10000 (53%)\n",
      "\n",
      "10 4 0.5307\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 5025/10000 (50%)\n",
      "\n",
      "10 5 0.5025\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4781/10000 (48%)\n",
      "\n",
      "10 6 0.4781\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4429/10000 (44%)\n",
      "\n",
      "10 7 0.4429\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4212/10000 (42%)\n",
      "\n",
      "10 8 0.4212\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3964/10000 (40%)\n",
      "\n",
      "10 9 0.3964\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3729/10000 (37%)\n",
      "\n",
      "10 10 0.3729\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3503/10000 (35%)\n",
      "\n",
      "10 11 0.3503\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3240/10000 (32%)\n",
      "\n",
      "10 12 0.324\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2985/10000 (30%)\n",
      "\n",
      "10 13 0.2985\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2678/10000 (27%)\n",
      "\n",
      "10 14 0.2678\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2434/10000 (24%)\n",
      "\n",
      "10 15 0.2434\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1679/10000 (17%)\n",
      "\n",
      "10 16 0.1679\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1953/10000 (20%)\n",
      "\n",
      "10 17 0.1953\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1792/10000 (18%)\n",
      "\n",
      "10 18 0.1792\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1639/10000 (16%)\n",
      "\n",
      "10 19 0.1639\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 770/10000 (8%)\n",
      "\n",
      "10 20 0.077\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1351/10000 (14%)\n",
      "\n",
      "10 21 0.1351\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1001/10000 (10%)\n",
      "\n",
      "10 22 0.1001\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "10 23 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "10 24 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "10 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "10 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 975/10000 (10%)\n",
      "\n",
      "10 27 0.0975\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "11 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "11 -26 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "11 -25 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "11 -24 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1219/10000 (12%)\n",
      "\n",
      "11 -23 0.1219\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1278/10000 (13%)\n",
      "\n",
      "11 -22 0.1278\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 894/10000 (9%)\n",
      "\n",
      "11 -21 0.0894\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1538/10000 (15%)\n",
      "\n",
      "11 -20 0.1538\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1596/10000 (16%)\n",
      "\n",
      "11 -19 0.1596\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "11 -18 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1875/10000 (19%)\n",
      "\n",
      "11 -17 0.1875\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1895/10000 (19%)\n",
      "\n",
      "11 -16 0.1895\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 2138/10000 (21%)\n",
      "\n",
      "11 -15 0.2138\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2383/10000 (24%)\n",
      "\n",
      "11 -14 0.2383\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2577/10000 (26%)\n",
      "\n",
      "11 -13 0.2577\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2798/10000 (28%)\n",
      "\n",
      "11 -12 0.2798\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3258/10000 (33%)\n",
      "\n",
      "11 -11 0.3258\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3689/10000 (37%)\n",
      "\n",
      "11 -10 0.3689\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3986/10000 (40%)\n",
      "\n",
      "11 -9 0.3986\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4418/10000 (44%)\n",
      "\n",
      "11 -8 0.4418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4759/10000 (48%)\n",
      "\n",
      "11 -7 0.4759\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5106/10000 (51%)\n",
      "\n",
      "11 -6 0.5106\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5296/10000 (53%)\n",
      "\n",
      "11 -5 0.5296\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5470/10000 (55%)\n",
      "\n",
      "11 -4 0.547\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5531/10000 (55%)\n",
      "\n",
      "11 -3 0.5531\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5577/10000 (56%)\n",
      "\n",
      "11 -2 0.5577\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5496/10000 (55%)\n",
      "\n",
      "11 -1 0.5496\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5357/10000 (54%)\n",
      "\n",
      "11 0 0.5357\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5279/10000 (53%)\n",
      "\n",
      "11 1 0.5279\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5078/10000 (51%)\n",
      "\n",
      "11 2 0.5078\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5019/10000 (50%)\n",
      "\n",
      "11 3 0.5019\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4837/10000 (48%)\n",
      "\n",
      "11 4 0.4837\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4565/10000 (46%)\n",
      "\n",
      "11 5 0.4565\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4402/10000 (44%)\n",
      "\n",
      "11 6 0.4402\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4130/10000 (41%)\n",
      "\n",
      "11 7 0.413\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 3911/10000 (39%)\n",
      "\n",
      "11 8 0.3911\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3617/10000 (36%)\n",
      "\n",
      "11 9 0.3617\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3436/10000 (34%)\n",
      "\n",
      "11 10 0.3436\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3167/10000 (32%)\n",
      "\n",
      "11 11 0.3167\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 3027/10000 (30%)\n",
      "\n",
      "11 12 0.3027\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2873/10000 (29%)\n",
      "\n",
      "11 13 0.2873\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2578/10000 (26%)\n",
      "\n",
      "11 14 0.2578\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2312/10000 (23%)\n",
      "\n",
      "11 15 0.2312\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1518/10000 (15%)\n",
      "\n",
      "11 16 0.1518\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1980/10000 (20%)\n",
      "\n",
      "11 17 0.198\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1756/10000 (18%)\n",
      "\n",
      "11 18 0.1756\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1623/10000 (16%)\n",
      "\n",
      "11 19 0.1623\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1495/10000 (15%)\n",
      "\n",
      "11 20 0.1495\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1356/10000 (14%)\n",
      "\n",
      "11 21 0.1356\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1020/10000 (10%)\n",
      "\n",
      "11 22 0.102\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "11 23 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "11 24 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "11 25 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "11 26 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "11 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "12 -27 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "12 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "12 -25 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "12 -24 0.1162\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "12 -23 0.1024\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1286/10000 (13%)\n",
      "\n",
      "12 -22 0.1286\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 657/10000 (7%)\n",
      "\n",
      "12 -21 0.0657\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1458/10000 (15%)\n",
      "\n",
      "12 -20 0.1458\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1630/10000 (16%)\n",
      "\n",
      "12 -19 0.163\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1744/10000 (17%)\n",
      "\n",
      "12 -18 0.1744\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1871/10000 (19%)\n",
      "\n",
      "12 -17 0.1871\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1859/10000 (19%)\n",
      "\n",
      "12 -16 0.1859\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2147/10000 (21%)\n",
      "\n",
      "12 -15 0.2147\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2231/10000 (22%)\n",
      "\n",
      "12 -14 0.2231\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2477/10000 (25%)\n",
      "\n",
      "12 -13 0.2477\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2722/10000 (27%)\n",
      "\n",
      "12 -12 0.2722\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3006/10000 (30%)\n",
      "\n",
      "12 -11 0.3006\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3303/10000 (33%)\n",
      "\n",
      "12 -10 0.3303\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3608/10000 (36%)\n",
      "\n",
      "12 -9 0.3608\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4056/10000 (41%)\n",
      "\n",
      "12 -8 0.4056\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4347/10000 (43%)\n",
      "\n",
      "12 -7 0.4347\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4543/10000 (45%)\n",
      "\n",
      "12 -6 0.4543\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4830/10000 (48%)\n",
      "\n",
      "12 -5 0.483\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4971/10000 (50%)\n",
      "\n",
      "12 -4 0.4971\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5071/10000 (51%)\n",
      "\n",
      "12 -3 0.5071\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5130/10000 (51%)\n",
      "\n",
      "12 -2 0.513\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4979/10000 (50%)\n",
      "\n",
      "12 -1 0.4979\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4915/10000 (49%)\n",
      "\n",
      "12 0 0.4915\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4808/10000 (48%)\n",
      "\n",
      "12 1 0.4808\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4705/10000 (47%)\n",
      "\n",
      "12 2 0.4705\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4531/10000 (45%)\n",
      "\n",
      "12 3 0.4531\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4389/10000 (44%)\n",
      "\n",
      "12 4 0.4389\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4198/10000 (42%)\n",
      "\n",
      "12 5 0.4198\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4063/10000 (41%)\n",
      "\n",
      "12 6 0.4063\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3897/10000 (39%)\n",
      "\n",
      "12 7 0.3897\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3583/10000 (36%)\n",
      "\n",
      "12 8 0.3583\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3378/10000 (34%)\n",
      "\n",
      "12 9 0.3378\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3209/10000 (32%)\n",
      "\n",
      "12 10 0.3209\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2953/10000 (30%)\n",
      "\n",
      "12 11 0.2953\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2859/10000 (29%)\n",
      "\n",
      "12 12 0.2859\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2614/10000 (26%)\n",
      "\n",
      "12 13 0.2614\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2405/10000 (24%)\n",
      "\n",
      "12 14 0.2405\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2176/10000 (22%)\n",
      "\n",
      "12 15 0.2176\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1375/10000 (14%)\n",
      "\n",
      "12 16 0.1375\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 937/10000 (9%)\n",
      "\n",
      "12 17 0.0937\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1763/10000 (18%)\n",
      "\n",
      "12 18 0.1763\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1607/10000 (16%)\n",
      "\n",
      "12 19 0.1607\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1453/10000 (15%)\n",
      "\n",
      "12 20 0.1453\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1328/10000 (13%)\n",
      "\n",
      "12 21 0.1328\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 977/10000 (10%)\n",
      "\n",
      "12 22 0.0977\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "12 23 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "12 24 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "12 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "12 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "12 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "13 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "13 -26 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "13 -25 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "13 -24 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "13 -23 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1269/10000 (13%)\n",
      "\n",
      "13 -22 0.1269\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1328/10000 (13%)\n",
      "\n",
      "13 -21 0.1328\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1433/10000 (14%)\n",
      "\n",
      "13 -20 0.1433\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1547/10000 (15%)\n",
      "\n",
      "13 -19 0.1547\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1126/10000 (11%)\n",
      "\n",
      "13 -18 0.1126\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1874/10000 (19%)\n",
      "\n",
      "13 -17 0.1874\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1934/10000 (19%)\n",
      "\n",
      "13 -16 0.1934\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1965/10000 (20%)\n",
      "\n",
      "13 -15 0.1965\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2229/10000 (22%)\n",
      "\n",
      "13 -14 0.2229\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2382/10000 (24%)\n",
      "\n",
      "13 -13 0.2382\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2549/10000 (25%)\n",
      "\n",
      "13 -12 0.2549\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2739/10000 (27%)\n",
      "\n",
      "13 -11 0.2739\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2965/10000 (30%)\n",
      "\n",
      "13 -10 0.2965\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3128/10000 (31%)\n",
      "\n",
      "13 -9 0.3128\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3400/10000 (34%)\n",
      "\n",
      "13 -8 0.34\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3715/10000 (37%)\n",
      "\n",
      "13 -7 0.3715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4053/10000 (41%)\n",
      "\n",
      "13 -6 0.4053\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4217/10000 (42%)\n",
      "\n",
      "13 -5 0.4217\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4379/10000 (44%)\n",
      "\n",
      "13 -4 0.4379\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4578/10000 (46%)\n",
      "\n",
      "13 -3 0.4578\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4580/10000 (46%)\n",
      "\n",
      "13 -2 0.458\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4502/10000 (45%)\n",
      "\n",
      "13 -1 0.4502\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4379/10000 (44%)\n",
      "\n",
      "13 0 0.4379\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4349/10000 (43%)\n",
      "\n",
      "13 1 0.4349\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4277/10000 (43%)\n",
      "\n",
      "13 2 0.4277\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4138/10000 (41%)\n",
      "\n",
      "13 3 0.4138\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3983/10000 (40%)\n",
      "\n",
      "13 4 0.3983\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3853/10000 (39%)\n",
      "\n",
      "13 5 0.3853\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3566/10000 (36%)\n",
      "\n",
      "13 6 0.3566\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3437/10000 (34%)\n",
      "\n",
      "13 7 0.3437\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3241/10000 (32%)\n",
      "\n",
      "13 8 0.3241\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3149/10000 (31%)\n",
      "\n",
      "13 9 0.3149\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2860/10000 (29%)\n",
      "\n",
      "13 10 0.286\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2698/10000 (27%)\n",
      "\n",
      "13 11 0.2698\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2612/10000 (26%)\n",
      "\n",
      "13 12 0.2612\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2438/10000 (24%)\n",
      "\n",
      "13 13 0.2438\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2205/10000 (22%)\n",
      "\n",
      "13 14 0.2205\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2057/10000 (21%)\n",
      "\n",
      "13 15 0.2057\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1994/10000 (20%)\n",
      "\n",
      "13 16 0.1994\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 844/10000 (8%)\n",
      "\n",
      "13 17 0.0844\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1717/10000 (17%)\n",
      "\n",
      "13 18 0.1717\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1541/10000 (15%)\n",
      "\n",
      "13 19 0.1541\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1405/10000 (14%)\n",
      "\n",
      "13 20 0.1405\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1318/10000 (13%)\n",
      "\n",
      "13 21 0.1318\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 888/10000 (9%)\n",
      "\n",
      "13 22 0.0888\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "13 23 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "13 24 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "13 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 960/10000 (10%)\n",
      "\n",
      "13 26 0.096\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "13 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "14 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1027/10000 (10%)\n",
      "\n",
      "14 -26 0.1027\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1020/10000 (10%)\n",
      "\n",
      "14 -25 0.102\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "14 -24 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1023/10000 (10%)\n",
      "\n",
      "14 -23 0.1023\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1240/10000 (12%)\n",
      "\n",
      "14 -22 0.124\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1316/10000 (13%)\n",
      "\n",
      "14 -21 0.1316\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1417/10000 (14%)\n",
      "\n",
      "14 -20 0.1417\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1564/10000 (16%)\n",
      "\n",
      "14 -19 0.1564\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1671/10000 (17%)\n",
      "\n",
      "14 -18 0.1671\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1828/10000 (18%)\n",
      "\n",
      "14 -17 0.1828\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1907/10000 (19%)\n",
      "\n",
      "14 -16 0.1907\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1982/10000 (20%)\n",
      "\n",
      "14 -15 0.1982\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2085/10000 (21%)\n",
      "\n",
      "14 -14 0.2085\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2218/10000 (22%)\n",
      "\n",
      "14 -13 0.2218\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2302/10000 (23%)\n",
      "\n",
      "14 -12 0.2302\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2415/10000 (24%)\n",
      "\n",
      "14 -11 0.2415\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2543/10000 (25%)\n",
      "\n",
      "14 -10 0.2543\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2659/10000 (27%)\n",
      "\n",
      "14 -9 0.2659\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 2842/10000 (28%)\n",
      "\n",
      "14 -8 0.2842\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3146/10000 (31%)\n",
      "\n",
      "14 -7 0.3146\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3362/10000 (34%)\n",
      "\n",
      "14 -6 0.3362\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3657/10000 (37%)\n",
      "\n",
      "14 -5 0.3657\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3969/10000 (40%)\n",
      "\n",
      "14 -4 0.3969\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4068/10000 (41%)\n",
      "\n",
      "14 -3 0.4068\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4074/10000 (41%)\n",
      "\n",
      "14 -2 0.4074\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4100/10000 (41%)\n",
      "\n",
      "14 -1 0.41\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4089/10000 (41%)\n",
      "\n",
      "14 0 0.4089\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4013/10000 (40%)\n",
      "\n",
      "14 1 0.4013\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3789/10000 (38%)\n",
      "\n",
      "14 2 0.3789\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3703/10000 (37%)\n",
      "\n",
      "14 3 0.3703\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3488/10000 (35%)\n",
      "\n",
      "14 4 0.3488\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3372/10000 (34%)\n",
      "\n",
      "14 5 0.3372\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3249/10000 (32%)\n",
      "\n",
      "14 6 0.3249\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3103/10000 (31%)\n",
      "\n",
      "14 7 0.3103\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2872/10000 (29%)\n",
      "\n",
      "14 8 0.2872\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2744/10000 (27%)\n",
      "\n",
      "14 9 0.2744\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2579/10000 (26%)\n",
      "\n",
      "14 10 0.2579\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2485/10000 (25%)\n",
      "\n",
      "14 11 0.2485\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2313/10000 (23%)\n",
      "\n",
      "14 12 0.2313\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2191/10000 (22%)\n",
      "\n",
      "14 13 0.2191\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2079/10000 (21%)\n",
      "\n",
      "14 14 0.2079\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2025/10000 (20%)\n",
      "\n",
      "14 15 0.2025\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1055/10000 (11%)\n",
      "\n",
      "14 16 0.1055\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1835/10000 (18%)\n",
      "\n",
      "14 17 0.1835\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1675/10000 (17%)\n",
      "\n",
      "14 18 0.1675\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1510/10000 (15%)\n",
      "\n",
      "14 19 0.151\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 830/10000 (8%)\n",
      "\n",
      "14 20 0.083\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 604/10000 (6%)\n",
      "\n",
      "14 21 0.0604\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "14 22 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1165/10000 (12%)\n",
      "\n",
      "14 23 0.1165\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "14 24 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "14 25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "14 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "14 27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "15 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "15 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 934/10000 (9%)\n",
      "\n",
      "15 -25 0.0934\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "15 -24 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "15 -23 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "15 -22 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1319/10000 (13%)\n",
      "\n",
      "15 -21 0.1319\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1439/10000 (14%)\n",
      "\n",
      "15 -20 0.1439\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1513/10000 (15%)\n",
      "\n",
      "15 -19 0.1513\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1099/10000 (11%)\n",
      "\n",
      "15 -18 0.1099\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1677/10000 (17%)\n",
      "\n",
      "15 -17 0.1677\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1837/10000 (18%)\n",
      "\n",
      "15 -16 0.1837\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1871/10000 (19%)\n",
      "\n",
      "15 -15 0.1871\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1959/10000 (20%)\n",
      "\n",
      "15 -14 0.1959\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2035/10000 (20%)\n",
      "\n",
      "15 -13 0.2035\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2052/10000 (21%)\n",
      "\n",
      "15 -12 0.2052\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2183/10000 (22%)\n",
      "\n",
      "15 -11 0.2183\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2164/10000 (22%)\n",
      "\n",
      "15 -10 0.2164\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2212/10000 (22%)\n",
      "\n",
      "15 -9 0.2212\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2502/10000 (25%)\n",
      "\n",
      "15 -8 0.2502\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2663/10000 (27%)\n",
      "\n",
      "15 -7 0.2663\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2885/10000 (29%)\n",
      "\n",
      "15 -6 0.2885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3151/10000 (32%)\n",
      "\n",
      "15 -5 0.3151\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3366/10000 (34%)\n",
      "\n",
      "15 -4 0.3366\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3622/10000 (36%)\n",
      "\n",
      "15 -3 0.3622\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3601/10000 (36%)\n",
      "\n",
      "15 -2 0.3601\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3664/10000 (37%)\n",
      "\n",
      "15 -1 0.3664\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3655/10000 (37%)\n",
      "\n",
      "15 0 0.3655\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3520/10000 (35%)\n",
      "\n",
      "15 1 0.352\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3346/10000 (33%)\n",
      "\n",
      "15 2 0.3346\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3100/10000 (31%)\n",
      "\n",
      "15 3 0.31\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3059/10000 (31%)\n",
      "\n",
      "15 4 0.3059\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2956/10000 (30%)\n",
      "\n",
      "15 5 0.2956\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2763/10000 (28%)\n",
      "\n",
      "15 6 0.2763\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2656/10000 (27%)\n",
      "\n",
      "15 7 0.2656\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2542/10000 (25%)\n",
      "\n",
      "15 8 0.2542\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2476/10000 (25%)\n",
      "\n",
      "15 9 0.2476\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2335/10000 (23%)\n",
      "\n",
      "15 10 0.2335\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2253/10000 (23%)\n",
      "\n",
      "15 11 0.2253\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2187/10000 (22%)\n",
      "\n",
      "15 12 0.2187\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2089/10000 (21%)\n",
      "\n",
      "15 13 0.2089\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1882/10000 (19%)\n",
      "\n",
      "15 14 0.1882\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1352/10000 (14%)\n",
      "\n",
      "15 15 0.1352\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 916/10000 (9%)\n",
      "\n",
      "15 16 0.0916\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 693/10000 (7%)\n",
      "\n",
      "15 17 0.0693\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 709/10000 (7%)\n",
      "\n",
      "15 18 0.0709\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 513/10000 (5%)\n",
      "\n",
      "15 19 0.0513\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 675/10000 (7%)\n",
      "\n",
      "15 20 0.0675\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "15 21 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "15 22 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "15 23 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "15 24 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "15 25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "15 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "15 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1016/10000 (10%)\n",
      "\n",
      "16 -25 0.1016\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "16 -24 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "16 -23 0.118\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 996/10000 (10%)\n",
      "\n",
      "16 -22 0.0996\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1289/10000 (13%)\n",
      "\n",
      "16 -21 0.1289\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 885/10000 (9%)\n",
      "\n",
      "16 -20 0.0885\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 875/10000 (9%)\n",
      "\n",
      "16 -19 0.0875\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1561/10000 (16%)\n",
      "\n",
      "16 -18 0.1561\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1668/10000 (17%)\n",
      "\n",
      "16 -17 0.1668\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1685/10000 (17%)\n",
      "\n",
      "16 -16 0.1685\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1762/10000 (18%)\n",
      "\n",
      "16 -15 0.1762\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1807/10000 (18%)\n",
      "\n",
      "16 -14 0.1807\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1893/10000 (19%)\n",
      "\n",
      "16 -13 0.1893\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1974/10000 (20%)\n",
      "\n",
      "16 -12 0.1974\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1943/10000 (19%)\n",
      "\n",
      "16 -11 0.1943\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2064/10000 (21%)\n",
      "\n",
      "16 -10 0.2064\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2107/10000 (21%)\n",
      "\n",
      "16 -9 0.2107\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2189/10000 (22%)\n",
      "\n",
      "16 -8 0.2189\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2386/10000 (24%)\n",
      "\n",
      "16 -7 0.2386\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2580/10000 (26%)\n",
      "\n",
      "16 -6 0.258\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2752/10000 (28%)\n",
      "\n",
      "16 -5 0.2752\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3019/10000 (30%)\n",
      "\n",
      "16 -4 0.3019\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3162/10000 (32%)\n",
      "\n",
      "16 -3 0.3162\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3190/10000 (32%)\n",
      "\n",
      "16 -2 0.319\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3264/10000 (33%)\n",
      "\n",
      "16 -1 0.3264\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3238/10000 (32%)\n",
      "\n",
      "16 0 0.3238\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3097/10000 (31%)\n",
      "\n",
      "16 1 0.3097\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2943/10000 (29%)\n",
      "\n",
      "16 2 0.2943\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2641/10000 (26%)\n",
      "\n",
      "16 3 0.2641\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2536/10000 (25%)\n",
      "\n",
      "16 4 0.2536\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2410/10000 (24%)\n",
      "\n",
      "16 5 0.241\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2371/10000 (24%)\n",
      "\n",
      "16 6 0.2371\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2271/10000 (23%)\n",
      "\n",
      "16 7 0.2271\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2316/10000 (23%)\n",
      "\n",
      "16 8 0.2316\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2263/10000 (23%)\n",
      "\n",
      "16 9 0.2263\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2251/10000 (23%)\n",
      "\n",
      "16 10 0.2251\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2227/10000 (22%)\n",
      "\n",
      "16 11 0.2227\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2124/10000 (21%)\n",
      "\n",
      "16 12 0.2124\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2103/10000 (21%)\n",
      "\n",
      "16 13 0.2103\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1995/10000 (20%)\n",
      "\n",
      "16 14 0.1995\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1973/10000 (20%)\n",
      "\n",
      "16 15 0.1973\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1839/10000 (18%)\n",
      "\n",
      "16 16 0.1839\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1697/10000 (17%)\n",
      "\n",
      "16 17 0.1697\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1560/10000 (16%)\n",
      "\n",
      "16 18 0.156\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1407/10000 (14%)\n",
      "\n",
      "16 19 0.1407\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1331/10000 (13%)\n",
      "\n",
      "16 20 0.1331\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1228/10000 (12%)\n",
      "\n",
      "16 21 0.1228\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "16 22 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "16 23 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "16 24 0.114\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "16 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "17 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "17 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 953/10000 (10%)\n",
      "\n",
      "17 -25 0.0953\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "17 -24 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 772/10000 (8%)\n",
      "\n",
      "17 -23 0.0772\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1206/10000 (12%)\n",
      "\n",
      "17 -22 0.1206\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1253/10000 (13%)\n",
      "\n",
      "17 -21 0.1253\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1289/10000 (13%)\n",
      "\n",
      "17 -20 0.1289\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 829/10000 (8%)\n",
      "\n",
      "17 -19 0.0829\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1455/10000 (15%)\n",
      "\n",
      "17 -18 0.1455\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1518/10000 (15%)\n",
      "\n",
      "17 -17 0.1518\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1577/10000 (16%)\n",
      "\n",
      "17 -16 0.1577\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1711/10000 (17%)\n",
      "\n",
      "17 -15 0.1711\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1774/10000 (18%)\n",
      "\n",
      "17 -14 0.1774\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1894/10000 (19%)\n",
      "\n",
      "17 -13 0.1894\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1970/10000 (20%)\n",
      "\n",
      "17 -12 0.197\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1988/10000 (20%)\n",
      "\n",
      "17 -11 0.1988\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 1991/10000 (20%)\n",
      "\n",
      "17 -10 0.1991\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2098/10000 (21%)\n",
      "\n",
      "17 -9 0.2098\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2196/10000 (22%)\n",
      "\n",
      "17 -8 0.2196\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2355/10000 (24%)\n",
      "\n",
      "17 -7 0.2355\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2419/10000 (24%)\n",
      "\n",
      "17 -6 0.2419\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2551/10000 (26%)\n",
      "\n",
      "17 -5 0.2551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2715/10000 (27%)\n",
      "\n",
      "17 -4 0.2715\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2884/10000 (29%)\n",
      "\n",
      "17 -3 0.2884\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2919/10000 (29%)\n",
      "\n",
      "17 -2 0.2919\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2926/10000 (29%)\n",
      "\n",
      "17 -1 0.2926\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2897/10000 (29%)\n",
      "\n",
      "17 0 0.2897\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2702/10000 (27%)\n",
      "\n",
      "17 1 0.2702\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2581/10000 (26%)\n",
      "\n",
      "17 2 0.2581\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2249/10000 (22%)\n",
      "\n",
      "17 3 0.2249\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2187/10000 (22%)\n",
      "\n",
      "17 4 0.2187\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2026/10000 (20%)\n",
      "\n",
      "17 5 0.2026\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2071/10000 (21%)\n",
      "\n",
      "17 6 0.2071\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2101/10000 (21%)\n",
      "\n",
      "17 7 0.2101\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2166/10000 (22%)\n",
      "\n",
      "17 8 0.2166\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2193/10000 (22%)\n",
      "\n",
      "17 9 0.2193\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2178/10000 (22%)\n",
      "\n",
      "17 10 0.2178\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2179/10000 (22%)\n",
      "\n",
      "17 11 0.2179\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2167/10000 (22%)\n",
      "\n",
      "17 12 0.2167\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 2076/10000 (21%)\n",
      "\n",
      "17 13 0.2076\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1924/10000 (19%)\n",
      "\n",
      "17 14 0.1924\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1891/10000 (19%)\n",
      "\n",
      "17 15 0.1891\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1752/10000 (18%)\n",
      "\n",
      "17 16 0.1752\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1629/10000 (16%)\n",
      "\n",
      "17 17 0.1629\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1469/10000 (15%)\n",
      "\n",
      "17 18 0.1469\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1386/10000 (14%)\n",
      "\n",
      "17 19 0.1386\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1294/10000 (13%)\n",
      "\n",
      "17 20 0.1294\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 860/10000 (9%)\n",
      "\n",
      "17 21 0.086\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 735/10000 (7%)\n",
      "\n",
      "17 22 0.0735\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "17 23 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "17 24 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "17 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "17 26 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 980/10000 (10%)\n",
      "\n",
      "17 27 0.098\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "18 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "18 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "18 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "18 -24 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "18 -23 0.1014\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1192/10000 (12%)\n",
      "\n",
      "18 -22 0.1192\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 844/10000 (8%)\n",
      "\n",
      "18 -21 0.0844\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1005/10000 (10%)\n",
      "\n",
      "18 -20 0.1005\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1309/10000 (13%)\n",
      "\n",
      "18 -19 0.1309\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1393/10000 (14%)\n",
      "\n",
      "18 -18 0.1393\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1445/10000 (14%)\n",
      "\n",
      "18 -17 0.1445\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1353/10000 (14%)\n",
      "\n",
      "18 -16 0.1353\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1598/10000 (16%)\n",
      "\n",
      "18 -15 0.1598\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1714/10000 (17%)\n",
      "\n",
      "18 -14 0.1714\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1822/10000 (18%)\n",
      "\n",
      "18 -13 0.1822\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1837/10000 (18%)\n",
      "\n",
      "18 -12 0.1837\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2004/10000 (20%)\n",
      "\n",
      "18 -11 0.2004\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2002/10000 (20%)\n",
      "\n",
      "18 -10 0.2002\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2068/10000 (21%)\n",
      "\n",
      "18 -9 0.2068\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2152/10000 (22%)\n",
      "\n",
      "18 -8 0.2152\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2250/10000 (22%)\n",
      "\n",
      "18 -7 0.225\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2303/10000 (23%)\n",
      "\n",
      "18 -6 0.2303\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2431/10000 (24%)\n",
      "\n",
      "18 -5 0.2431\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2464/10000 (25%)\n",
      "\n",
      "18 -4 0.2464\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2541/10000 (25%)\n",
      "\n",
      "18 -3 0.2541\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2442/10000 (24%)\n",
      "\n",
      "18 -2 0.2442\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2500/10000 (25%)\n",
      "\n",
      "18 -1 0.25\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2422/10000 (24%)\n",
      "\n",
      "18 0 0.2422\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2285/10000 (23%)\n",
      "\n",
      "18 1 0.2285\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2098/10000 (21%)\n",
      "\n",
      "18 2 0.2098\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1979/10000 (20%)\n",
      "\n",
      "18 3 0.1979\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1804/10000 (18%)\n",
      "\n",
      "18 4 0.1804\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1797/10000 (18%)\n",
      "\n",
      "18 5 0.1797\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1851/10000 (19%)\n",
      "\n",
      "18 6 0.1851\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1896/10000 (19%)\n",
      "\n",
      "18 7 0.1896\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1981/10000 (20%)\n",
      "\n",
      "18 8 0.1981\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2031/10000 (20%)\n",
      "\n",
      "18 9 0.2031\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2094/10000 (21%)\n",
      "\n",
      "18 10 0.2094\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2019/10000 (20%)\n",
      "\n",
      "18 11 0.2019\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1998/10000 (20%)\n",
      "\n",
      "18 12 0.1998\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1910/10000 (19%)\n",
      "\n",
      "18 13 0.191\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1806/10000 (18%)\n",
      "\n",
      "18 14 0.1806\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1759/10000 (18%)\n",
      "\n",
      "18 15 0.1759\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1631/10000 (16%)\n",
      "\n",
      "18 16 0.1631\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1519/10000 (15%)\n",
      "\n",
      "18 17 0.1519\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1416/10000 (14%)\n",
      "\n",
      "18 18 0.1416\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1317/10000 (13%)\n",
      "\n",
      "18 19 0.1317\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1221/10000 (12%)\n",
      "\n",
      "18 20 0.1221\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "18 21 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "18 22 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "18 23 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "18 24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "18 25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "18 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "18 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "19 -27 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "19 -26 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "19 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "19 -24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "19 -23 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "19 -22 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 989/10000 (10%)\n",
      "\n",
      "19 -21 0.0989\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1217/10000 (12%)\n",
      "\n",
      "19 -20 0.1217\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1238/10000 (12%)\n",
      "\n",
      "19 -19 0.1238\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1263/10000 (13%)\n",
      "\n",
      "19 -18 0.1263\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1354/10000 (14%)\n",
      "\n",
      "19 -17 0.1354\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1392/10000 (14%)\n",
      "\n",
      "19 -16 0.1392\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1497/10000 (15%)\n",
      "\n",
      "19 -15 0.1497\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1600/10000 (16%)\n",
      "\n",
      "19 -14 0.16\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1687/10000 (17%)\n",
      "\n",
      "19 -13 0.1687\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1794/10000 (18%)\n",
      "\n",
      "19 -12 0.1794\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1864/10000 (19%)\n",
      "\n",
      "19 -11 0.1864\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1949/10000 (19%)\n",
      "\n",
      "19 -10 0.1949\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1950/10000 (20%)\n",
      "\n",
      "19 -9 0.195\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2014/10000 (20%)\n",
      "\n",
      "19 -8 0.2014\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2049/10000 (20%)\n",
      "\n",
      "19 -7 0.2049\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2109/10000 (21%)\n",
      "\n",
      "19 -6 0.2109\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2112/10000 (21%)\n",
      "\n",
      "19 -5 0.2112\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2184/10000 (22%)\n",
      "\n",
      "19 -4 0.2184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2146/10000 (21%)\n",
      "\n",
      "19 -3 0.2146\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2203/10000 (22%)\n",
      "\n",
      "19 -2 0.2203\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2106/10000 (21%)\n",
      "\n",
      "19 -1 0.2106\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2062/10000 (21%)\n",
      "\n",
      "19 0 0.2062\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1918/10000 (19%)\n",
      "\n",
      "19 1 0.1918\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1852/10000 (19%)\n",
      "\n",
      "19 2 0.1852\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1759/10000 (18%)\n",
      "\n",
      "19 3 0.1759\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1700/10000 (17%)\n",
      "\n",
      "19 4 0.17\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1570/10000 (16%)\n",
      "\n",
      "19 5 0.157\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1659/10000 (17%)\n",
      "\n",
      "19 6 0.1659\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1654/10000 (17%)\n",
      "\n",
      "19 7 0.1654\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1802/10000 (18%)\n",
      "\n",
      "19 8 0.1802\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1813/10000 (18%)\n",
      "\n",
      "19 9 0.1813\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1863/10000 (19%)\n",
      "\n",
      "19 10 0.1863\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1854/10000 (19%)\n",
      "\n",
      "19 11 0.1854\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1755/10000 (18%)\n",
      "\n",
      "19 12 0.1755\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1328/10000 (13%)\n",
      "\n",
      "19 13 0.1328\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1653/10000 (17%)\n",
      "\n",
      "19 14 0.1653\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1547/10000 (15%)\n",
      "\n",
      "19 15 0.1547\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1475/10000 (15%)\n",
      "\n",
      "19 16 0.1475\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1436/10000 (14%)\n",
      "\n",
      "19 17 0.1436\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1334/10000 (13%)\n",
      "\n",
      "19 18 0.1334\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1262/10000 (13%)\n",
      "\n",
      "19 19 0.1262\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "19 20 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "19 21 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1017/10000 (10%)\n",
      "\n",
      "19 22 0.1017\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "19 23 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 982/10000 (10%)\n",
      "\n",
      "19 24 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "19 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "20 -27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "20 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1036/10000 (10%)\n",
      "\n",
      "20 -25 0.1036\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1026/10000 (10%)\n",
      "\n",
      "20 -24 0.1026\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "20 -23 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "20 -22 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "20 -21 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 997/10000 (10%)\n",
      "\n",
      "20 -20 0.0997\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 969/10000 (10%)\n",
      "\n",
      "20 -19 0.0969\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1210/10000 (12%)\n",
      "\n",
      "20 -18 0.121\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 963/10000 (10%)\n",
      "\n",
      "20 -17 0.0963\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1236/10000 (12%)\n",
      "\n",
      "20 -16 0.1236\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1323/10000 (13%)\n",
      "\n",
      "20 -15 0.1323\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1356/10000 (14%)\n",
      "\n",
      "20 -14 0.1356\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1459/10000 (15%)\n",
      "\n",
      "20 -13 0.1459\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1515/10000 (15%)\n",
      "\n",
      "20 -12 0.1515\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1561/10000 (16%)\n",
      "\n",
      "20 -11 0.1561\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1656/10000 (17%)\n",
      "\n",
      "20 -10 0.1656\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1648/10000 (16%)\n",
      "\n",
      "20 -9 0.1648\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1655/10000 (17%)\n",
      "\n",
      "20 -8 0.1655\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1799/10000 (18%)\n",
      "\n",
      "20 -7 0.1799\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1752/10000 (18%)\n",
      "\n",
      "20 -6 0.1752\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1791/10000 (18%)\n",
      "\n",
      "20 -5 0.1791\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1770/10000 (18%)\n",
      "\n",
      "20 -4 0.177\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1738/10000 (17%)\n",
      "\n",
      "20 -3 0.1738\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1748/10000 (17%)\n",
      "\n",
      "20 -2 0.1748\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1702/10000 (17%)\n",
      "\n",
      "20 -1 0.1702\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1632/10000 (16%)\n",
      "\n",
      "20 0 0.1632\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1633/10000 (16%)\n",
      "\n",
      "20 1 0.1633\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1541/10000 (15%)\n",
      "\n",
      "20 2 0.1541\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1406/10000 (14%)\n",
      "\n",
      "20 3 0.1406\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1383/10000 (14%)\n",
      "\n",
      "20 4 0.1383\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1323/10000 (13%)\n",
      "\n",
      "20 5 0.1323\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1373/10000 (14%)\n",
      "\n",
      "20 6 0.1373\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1383/10000 (14%)\n",
      "\n",
      "20 7 0.1383\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1486/10000 (15%)\n",
      "\n",
      "20 8 0.1486\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1472/10000 (15%)\n",
      "\n",
      "20 9 0.1472\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1438/10000 (14%)\n",
      "\n",
      "20 10 0.1438\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1440/10000 (14%)\n",
      "\n",
      "20 11 0.144\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1221/10000 (12%)\n",
      "\n",
      "20 12 0.1221\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1442/10000 (14%)\n",
      "\n",
      "20 13 0.1442\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1391/10000 (14%)\n",
      "\n",
      "20 14 0.1391\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 680/10000 (7%)\n",
      "\n",
      "20 15 0.068\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1365/10000 (14%)\n",
      "\n",
      "20 16 0.1365\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1299/10000 (13%)\n",
      "\n",
      "20 17 0.1299\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1235/10000 (12%)\n",
      "\n",
      "20 18 0.1235\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "20 19 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "20 20 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1023/10000 (10%)\n",
      "\n",
      "20 21 0.1023\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "20 22 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "20 23 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "20 24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "21 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "21 -25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "21 -24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "21 -23 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "21 -22 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "21 -21 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1098/10000 (11%)\n",
      "\n",
      "21 -20 0.1098\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1020/10000 (10%)\n",
      "\n",
      "21 -19 0.102\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "21 -18 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1115/10000 (11%)\n",
      "\n",
      "21 -17 0.1115\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "21 -16 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1097/10000 (11%)\n",
      "\n",
      "21 -15 0.1097\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "21 -14 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "21 -13 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "21 -12 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "21 -11 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1254/10000 (13%)\n",
      "\n",
      "21 -10 0.1254\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "21 -9 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1276/10000 (13%)\n",
      "\n",
      "21 -8 0.1276\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1279/10000 (13%)\n",
      "\n",
      "21 -7 0.1279\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1271/10000 (13%)\n",
      "\n",
      "21 -6 0.1271\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "21 -5 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1312/10000 (13%)\n",
      "\n",
      "21 -4 0.1312\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1675/10000 (17%)\n",
      "\n",
      "21 -3 0.1675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1332/10000 (13%)\n",
      "\n",
      "21 -2 0.1332\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1260/10000 (13%)\n",
      "\n",
      "21 -1 0.126\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1317/10000 (13%)\n",
      "\n",
      "21 0 0.1317\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "21 1 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "21 2 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "21 3 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "21 4 0.114\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1452/10000 (15%)\n",
      "\n",
      "21 5 0.1452\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1418/10000 (14%)\n",
      "\n",
      "21 6 0.1418\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1128/10000 (11%)\n",
      "\n",
      "21 7 0.1128\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1496/10000 (15%)\n",
      "\n",
      "21 8 0.1496\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1210/10000 (12%)\n",
      "\n",
      "21 9 0.121\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1202/10000 (12%)\n",
      "\n",
      "21 10 0.1202\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1364/10000 (14%)\n",
      "\n",
      "21 11 0.1364\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1212/10000 (12%)\n",
      "\n",
      "21 12 0.1212\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1275/10000 (13%)\n",
      "\n",
      "21 13 0.1275\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1251/10000 (13%)\n",
      "\n",
      "21 14 0.1251\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1253/10000 (13%)\n",
      "\n",
      "21 15 0.1253\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1244/10000 (12%)\n",
      "\n",
      "21 16 0.1244\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "21 17 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1191/10000 (12%)\n",
      "\n",
      "21 18 0.1191\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "21 19 0.118\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "21 20 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "21 21 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "21 22 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "21 23 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "22 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "22 -24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 927/10000 (9%)\n",
      "\n",
      "22 -23 0.0927\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
      "\n",
      "22 -22 0.106\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1124/10000 (11%)\n",
      "\n",
      "22 -21 0.1124\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1116/10000 (11%)\n",
      "\n",
      "22 -20 0.1116\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1101/10000 (11%)\n",
      "\n",
      "22 -19 0.1101\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1061/10000 (11%)\n",
      "\n",
      "22 -18 0.1061\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1048/10000 (10%)\n",
      "\n",
      "22 -17 0.1048\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1021/10000 (10%)\n",
      "\n",
      "22 -16 0.1021\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1007/10000 (10%)\n",
      "\n",
      "22 -15 0.1007\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 988/10000 (10%)\n",
      "\n",
      "22 -14 0.0988\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 978/10000 (10%)\n",
      "\n",
      "22 -13 0.0978\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1019/10000 (10%)\n",
      "\n",
      "22 -12 0.1019\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1070/10000 (11%)\n",
      "\n",
      "22 -11 0.107\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1044/10000 (10%)\n",
      "\n",
      "22 -10 0.1044\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1003/10000 (10%)\n",
      "\n",
      "22 -9 0.1003\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "22 -8 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1965/10000 (20%)\n",
      "\n",
      "22 -7 0.1965\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1029/10000 (10%)\n",
      "\n",
      "22 -6 0.1029\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 992/10000 (10%)\n",
      "\n",
      "22 -5 0.0992\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1034/10000 (10%)\n",
      "\n",
      "22 -4 0.1034\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1035/10000 (10%)\n",
      "\n",
      "22 -3 0.1035\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1002/10000 (10%)\n",
      "\n",
      "22 -2 0.1002\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1052/10000 (11%)\n",
      "\n",
      "22 -1 0.1052\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1005/10000 (10%)\n",
      "\n",
      "22 0 0.1005\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 991/10000 (10%)\n",
      "\n",
      "22 1 0.0991\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 973/10000 (10%)\n",
      "\n",
      "22 2 0.0973\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 930/10000 (9%)\n",
      "\n",
      "22 3 0.093\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 941/10000 (9%)\n",
      "\n",
      "22 4 0.0941\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 964/10000 (10%)\n",
      "\n",
      "22 5 0.0964\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 976/10000 (10%)\n",
      "\n",
      "22 6 0.0976\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1035/10000 (10%)\n",
      "\n",
      "22 7 0.1035\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1017/10000 (10%)\n",
      "\n",
      "22 8 0.1017\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 976/10000 (10%)\n",
      "\n",
      "22 9 0.0976\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1046/10000 (10%)\n",
      "\n",
      "22 10 0.1046\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 949/10000 (9%)\n",
      "\n",
      "22 11 0.0949\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1058/10000 (11%)\n",
      "\n",
      "22 12 0.1058\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1083/10000 (11%)\n",
      "\n",
      "22 13 0.1083\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "22 14 0.114\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "22 15 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "22 16 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "22 17 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1037/10000 (10%)\n",
      "\n",
      "22 18 0.1037\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "22 19 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "22 20 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1017/10000 (10%)\n",
      "\n",
      "22 21 0.1017\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "22 22 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "22 24 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "23 -27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "23 -25 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1129/10000 (11%)\n",
      "\n",
      "23 -23 0.1129\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1129/10000 (11%)\n",
      "\n",
      "23 -22 0.1129\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "23 -21 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1113/10000 (11%)\n",
      "\n",
      "23 -20 0.1113\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1107/10000 (11%)\n",
      "\n",
      "23 -19 0.1107\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1088/10000 (11%)\n",
      "\n",
      "23 -18 0.1088\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1070/10000 (11%)\n",
      "\n",
      "23 -17 0.107\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1031/10000 (10%)\n",
      "\n",
      "23 -16 0.1031\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1044/10000 (10%)\n",
      "\n",
      "23 -15 0.1044\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1053/10000 (11%)\n",
      "\n",
      "23 -14 0.1053\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1056/10000 (11%)\n",
      "\n",
      "23 -13 0.1056\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1031/10000 (10%)\n",
      "\n",
      "23 -12 0.1031\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1078/10000 (11%)\n",
      "\n",
      "23 -11 0.1078\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1049/10000 (10%)\n",
      "\n",
      "23 -10 0.1049\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1059/10000 (11%)\n",
      "\n",
      "23 -9 0.1059\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1047/10000 (10%)\n",
      "\n",
      "23 -8 0.1047\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1668/10000 (17%)\n",
      "\n",
      "23 -7 0.1668\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1049/10000 (10%)\n",
      "\n",
      "23 -6 0.1049\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1660/10000 (17%)\n",
      "\n",
      "23 -5 0.166\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1039/10000 (10%)\n",
      "\n",
      "23 -4 0.1039\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1037/10000 (10%)\n",
      "\n",
      "23 -3 0.1037\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1038/10000 (10%)\n",
      "\n",
      "23 -2 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1038/10000 (10%)\n",
      "\n",
      "23 -1 0.1038\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1026/10000 (10%)\n",
      "\n",
      "23 0 0.1026\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 988/10000 (10%)\n",
      "\n",
      "23 1 0.0988\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 994/10000 (10%)\n",
      "\n",
      "23 2 0.0994\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 981/10000 (10%)\n",
      "\n",
      "23 3 0.0981\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 976/10000 (10%)\n",
      "\n",
      "23 4 0.0976\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 987/10000 (10%)\n",
      "\n",
      "23 5 0.0987\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 983/10000 (10%)\n",
      "\n",
      "23 6 0.0983\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1008/10000 (10%)\n",
      "\n",
      "23 7 0.1008\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1605/10000 (16%)\n",
      "\n",
      "23 8 0.1605\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1043/10000 (10%)\n",
      "\n",
      "23 9 0.1043\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1032/10000 (10%)\n",
      "\n",
      "23 10 0.1032\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "23 11 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1050/10000 (10%)\n",
      "\n",
      "23 12 0.105\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1097/10000 (11%)\n",
      "\n",
      "23 13 0.1097\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1113/10000 (11%)\n",
      "\n",
      "23 14 0.1113\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1126/10000 (11%)\n",
      "\n",
      "23 15 0.1126\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "23 16 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "23 17 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "23 18 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "23 19 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "23 20 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "23 21 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "23 22 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1031/10000 (10%)\n",
      "\n",
      "23 23 0.1031\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "24 -25 0.101\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1033/10000 (10%)\n",
      "\n",
      "24 -24 0.1033\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "24 -21 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 -20 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "24 -19 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 -18 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "24 -17 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 982/10000 (10%)\n",
      "\n",
      "24 -16 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 316/10000 (3%)\n",
      "\n",
      "24 -15 0.0316\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "24 -14 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "24 -13 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "24 -12 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "24 -11 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1059/10000 (11%)\n",
      "\n",
      "24 -10 0.1059\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1001/10000 (10%)\n",
      "\n",
      "24 -9 0.1001\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1053/10000 (11%)\n",
      "\n",
      "24 -8 0.1053\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 994/10000 (10%)\n",
      "\n",
      "24 -7 0.0994\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1037/10000 (10%)\n",
      "\n",
      "24 -6 0.1037\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "24 -5 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "24 -4 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1042/10000 (10%)\n",
      "\n",
      "24 -3 0.1042\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "24 -2 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "24 -1 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "24 0 0.115\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "24 1 0.115\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "24 2 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 992/10000 (10%)\n",
      "\n",
      "24 3 0.0992\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "24 4 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "24 5 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "24 6 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "24 7 0.115\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "24 8 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "24 9 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "24 10 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1057/10000 (11%)\n",
      "\n",
      "24 11 0.1057\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "24 12 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "24 13 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "24 14 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "24 15 0.1014\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1018/10000 (10%)\n",
      "\n",
      "24 16 0.1018\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "24 17 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "24 18 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "25 -21 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "25 -20 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 -19 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "25 -18 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "25 -17 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "25 -16 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "25 -15 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1017/10000 (10%)\n",
      "\n",
      "25 -14 0.1017\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "25 -13 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "25 -12 0.114\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "25 -11 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "25 -10 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "25 -9 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "25 -8 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1018/10000 (10%)\n",
      "\n",
      "25 -7 0.1018\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "25 -6 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "25 -5 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "25 -4 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "25 -3 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1019/10000 (10%)\n",
      "\n",
      "25 -2 0.1019\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "25 -1 0.1143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "25 0 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 986/10000 (10%)\n",
      "\n",
      "25 1 0.0986\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1020/10000 (10%)\n",
      "\n",
      "25 3 0.102\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "25 4 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "25 5 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "25 6 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "25 7 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 982/10000 (10%)\n",
      "\n",
      "25 8 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "25 9 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "25 10 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "25 11 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "25 12 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "25 13 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1013/10000 (10%)\n",
      "\n",
      "25 14 0.1013\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1013/10000 (10%)\n",
      "\n",
      "25 15 0.1013\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 824/10000 (8%)\n",
      "\n",
      "25 16 0.0824\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 17 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "25 18 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 982/10000 (10%)\n",
      "\n",
      "25 19 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 20 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "25 21 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "26 -24 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "26 -23 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "26 -15 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "26 -14 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "26 -13 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "26 -12 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 -10 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "26 -8 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "26 -7 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "26 -5 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -4 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "26 -3 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 -1 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 0 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 1 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 3 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 4 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "26 7 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 9 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 10 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 13 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 982/10000 (10%)\n",
      "\n",
      "26 15 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "26 16 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0241, Accuracy: 982/10000 (10%)\n",
      "\n",
      "26 20 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 974/10000 (10%)\n",
      "\n",
      "26 22 0.0974\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "26 25 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "26 26 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "27 -27 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "27 -19 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "27 -18 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -13 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 982/10000 (10%)\n",
      "\n",
      "27 -11 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -10 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -4 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -3 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -1 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 0 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 1 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "27 3 0.101\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "27 4 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1032/10000 (10%)\n",
      "\n",
      "27 10 0.1032\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 13 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "27 24 0.1009\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 980/10000 (10%)\n",
      "\n",
      "27 25 0.098\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 27 0.1135\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    suffix = \"robust_{}_{}_{}_{}_{}\".format(args.sf_0, args.B_sf, args.noise, args.contrast, std)\n",
    "    model_path = \"../data/MNIST_cnn_{}.pt\".format(suffix)\n",
    "    model = torch.load(model_path)\n",
    "    print(args.do_adam)\n",
    "    acc_map = np.zeros((55, 55))\n",
    "    seed = 0\n",
    "    for i_offset in range(-27,28):\n",
    "        for j_offset in range(-27,28):\n",
    "            transform=transforms.Compose([\n",
    "                                   WhatShift(args, i_offset=i_offset, j_offset=j_offset),\n",
    "                                   WhatBackground(contrast = args.contrast,\n",
    "                                                  noise=args.noise, \n",
    "                                                  sf_0=args.sf_0, \n",
    "                                                  B_sf=args.B_sf,\n",
    "                                                  seed = seed),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   #transforms.Normalize((args.mean,), (args.std,))\n",
    "                               ])\n",
    "            dataset_test = MNIST('../data',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transform,\n",
    "                            )\n",
    "            test_loader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                             batch_size=args.minibatch_size,\n",
    "                                             shuffle=True)\n",
    "            whatTrainer = WhatTrainer(args, model = model, test_loader = test_loader, seed = seed)\n",
    "            acc = whatTrainer.test()\n",
    "            print(i_offset, j_offset, acc)\n",
    "            acc_map[i_offset + 27, j_offset + 27] = acc\n",
    "            seed += 1\n",
    "\n",
    "    map_path = \"../data/MNIST_accuracy_{}.npy\".format(suffix)\n",
    "    np.save(map_path, acc_map)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage Accuracy map enregistrée en txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "map_path = \"../data/MNIST_accuracy_{}.npy\".format(suffix)\n",
    "acc_map = np.load(map_path)      \n",
    "fig = plt.figure(figsize=(10,8))\n",
    "for i in range(55):\n",
    "    for j in range(55):\n",
    "        acc_map[i,j] = max(acc_map[i,j], 0.1)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X = np.arange(-27, 28)\n",
    "Y = np.arange(-27, 28)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "surf = ax.plot_surface(X, Y, acc_map, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=True, alpha=0.5)\n",
    "\n",
    "#ax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3)\n",
    "cset = ax.contour(X, Y, acc_map, [0.2, 0.3, 0.4, 0.5, 0.6, 0.7], zdir='z', offset=0, cmap=cm.coolwarm, alpha = 1)\n",
    "cset = ax.contour(X, Y, acc_map, [-20, -10, 0, 10, 20], zdir='x', offset=-27.5, cmap = 'gray')\n",
    "cset = ax.contour(X, Y, acc_map,  [-20, -10, 0, 10, 20], zdir='y', offset=27.5, cmap = 'gray')\n",
    "\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_xlim(-27.5, 27.5)\n",
    "ax.set_zlim(-27.5, 27.5)\n",
    "ax.set_zlim(0, 0.8)\n",
    "ax.zaxis.set_major_locator(LinearLocator(9))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "ax.set_title('Classification accuracy', size=15)\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "cbar = fig.colorbar(surf, shrink=0.5, aspect=5, ticks=[0.2,0.3,0.4,0.5,0.6,0.7,0.8])\n",
    "\n",
    "figname = '../paper/what_map'\n",
    "fig.savefig(figname + '.png', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8039"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(acc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-27, -26, -25, ...,  25,  26,  27],\n",
       "       [-27, -26, -25, ...,  25,  26,  27],\n",
       "       [-27, -26, -25, ...,  25,  26,  27],\n",
       "       ...,\n",
       "       [-27, -26, -25, ...,  25,  26,  27],\n",
       "       [-27, -26, -25, ...,  25,  26,  27],\n",
       "       [-27, -26, -25, ...,  25,  26,  27]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-27, -27, -27, ..., -27, -27, -27],\n",
       "       [-26, -26, -26, ..., -26, -26, -26],\n",
       "       [-25, -25, -25, ..., -25, -25, -25],\n",
       "       ...,\n",
       "       [ 25,  25,  25, ...,  25,  25,  25],\n",
       "       [ 26,  26,  26, ...,  26,  26,  26],\n",
       "       [ 27,  27,  27, ...,  27,  27,  27]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
