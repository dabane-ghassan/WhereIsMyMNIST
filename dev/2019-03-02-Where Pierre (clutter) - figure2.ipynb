{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Fixation Map training (2 layers)\n",
    "with clutter / whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noise\n",
    "import MotionClouds as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LogGabor import LogGabor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SLIP for whitening and PIL for resizing\n",
    "import SLIP\n",
    "import PIL\n",
    "whit = SLIP.Image(pe='https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MotionCloudNoise(sf_0=0.125, B_sf=3., alpha = .5):\n",
    "    mc.N_X, mc.N_Y, mc.N_frame = 128, 128, 1\n",
    "    fx, fy, ft = mc.get_grids(mc.N_X, mc.N_Y, mc.N_frame)\n",
    "    name = 'static'\n",
    "    env = mc.envelope_gabor(fx, fy, ft, sf_0=sf_0, B_sf=B_sf, B_theta=np.inf, V_X=0., V_Y=0., B_V=0, alpha= alpha)\n",
    "    \n",
    "    z = mc.rectif(mc.random_cloud(env))\n",
    "    z = z.reshape((mc.N_X, mc.N_Y))\n",
    "    return z, env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding : N_theta x N_azimuth x N_eccentricity x N_phase  2D filters (to be applied on N_X x N_Y pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: passer les arguments par la ligne de commande\n",
    "N_theta = 6\n",
    "N_azimuth = 16\n",
    "N_eccentricity = 10\n",
    "N_phase = 2\n",
    "N_X = 128\n",
    "N_Y = 128\n",
    "rho = 1.41\n",
    "verbose = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparer l'apprentissage et les fonctions nécessaires au fonctionnement du script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(N_theta=N_theta, N_azimuth=N_azimuth, N_eccentricity=N_eccentricity, N_phase=N_phase, \\\n",
    "                  N_X=N_X, N_Y=N_Y, rho=rho, ecc_max=.8, B_sf=.4, B_theta=np.pi/N_theta/2):\n",
    "    retina = np.zeros((N_theta, N_azimuth, N_eccentricity, N_phase, N_X*N_Y))\n",
    "    parameterfile = 'https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py'\n",
    "    lg = LogGabor(parameterfile)\n",
    "    lg.set_size((N_X, N_Y))\n",
    "    # params = {'sf_0': .1, 'B_sf': lg.pe.B_sf,\n",
    "    #           'theta': np.pi * 5 / 7., 'B_theta': lg.pe.B_theta}\n",
    "    # phase = np.pi/4\n",
    "    # edge = lg.normalize(lg.invert(lg.loggabor(\n",
    "    #     N_X/3, 3*N_Y/4, **params)*np.exp(-1j*phase)))\n",
    "\n",
    "    for i_theta in range(N_theta):\n",
    "        for i_azimuth in range(N_azimuth):\n",
    "            for i_eccentricity in range(N_eccentricity):\n",
    "                ecc = ecc_max * (1/rho)**(N_eccentricity - i_eccentricity)\n",
    "                r = np.sqrt(N_X**2+N_Y**2) / 2 * ecc  # radius\n",
    "                #psi = i_azimuth * np.pi * 2 / N_azimuth\n",
    "                psi = (i_azimuth + 1 * (i_eccentricity % 2)*.5) * np.pi * 2 / N_azimuth\n",
    "                theta_ref = i_theta*np.pi/N_theta\n",
    "                sf_0 = 0.5 * 0.03 / ecc\n",
    "                x = N_X/2 + r * np.cos(psi)\n",
    "                y = N_Y/2 + r * np.sin(psi)\n",
    "                for i_phase in range(N_phase):\n",
    "                    params = {'sf_0': sf_0, 'B_sf': B_sf,\n",
    "                              'theta': theta_ref + psi, 'B_theta': B_theta}\n",
    "                    phase = i_phase * np.pi/2\n",
    "                    # print(r, x, y, phase, params)\n",
    "\n",
    "                    retina[i_theta, i_azimuth, i_eccentricity, i_phase, :] = lg.normalize(\n",
    "                        lg.invert(lg.loggabor(x, y, **params)*np.exp(-1j*phase))).ravel() #* ecc\n",
    "\n",
    "    return retina\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina = vectorization(N_theta, N_azimuth, N_eccentricity, N_phase, N_X, N_Y, rho)\n",
    "print(retina.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_vector = retina.reshape((N_theta*N_azimuth*N_eccentricity*N_phase, N_X*N_Y))\n",
    "print(retina_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_inverse = np.linalg.pinv(retina_vector)\n",
    "print(retina_inverse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orientation invariant power encoding (colliculus??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colliculus = (retina**2).sum(axis=(0, 3))\n",
    "#colliculus = colliculus**.5\n",
    "colliculus /= colliculus.sum(axis=-1)[:, :, None]\n",
    "print(colliculus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colliculus_vector = colliculus.reshape((N_azimuth*N_eccentricity, N_X*N_Y))\n",
    "print(colliculus_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colliculus_inverse = np.linalg.pinv(colliculus_vector)\n",
    "print(colliculus_inverse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = (retina**2).sum(axis=(0,3)) \n",
    "energy /= energy.sum(axis=-1)[:, :, None]\n",
    "energy_vector = energy.reshape((N_azimuth*N_eccentricity, N_X*N_Y))\n",
    "energy_plus = np.linalg.pinv(energy_vector)\n",
    "FIG_WIDTH = 5 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_WIDTH))\n",
    "for i_orient in range(N_azimuth):\n",
    "    for i_scale in range(N_eccentricity):\n",
    "        env = np.sqrt(energy[i_orient, i_scale, :]**2.5).reshape((N_X, N_Y))\n",
    "        ax.contour(energy[i_orient, i_scale, :].reshape((N_X, N_Y)), levels=[env.max()/2], lw=1,\n",
    "                  colors=[plt.cm.rainbow(i_scale * 1.5/N_azimuth)])\n",
    "fig.suptitle('Tiling of visual space using energy')\n",
    "ax.set_xlabel(r'$Y$')\n",
    "ax.set_ylabel(r'$X$')\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST dataset read out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size=100, train=True):\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('/tmp/data',\n",
    "                       train=train,     # def the dataset as training data\n",
    "                       download=True,  # download if dataset not present on disk\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=(0,), std=(1,))])),\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True)\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_data_loader(batch_size=100, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(loader))\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(data[0,0,:,:])\n",
    "plt.subplot(122)\n",
    "_ = plt.plot(data[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"MNIST_accuracy.npy\"\n",
    "if os.path.isfile(path):\n",
    "    accuracy_map =  np.load(path)\n",
    "    if verbose:\n",
    "        print('Loading accuracy... min, max=', accuracy_map.min(), accuracy_map.max())\n",
    "else:\n",
    "    print('No accuracy data found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(accuracy_map)\n",
    "plt.subplot(122)\n",
    "_ = plt.plot(accuracy_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From MNIST encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input vectors encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_fullfield(data, i_offset, j_offset, N_pic=128, CONTRAST=1., NOISE = 1., sf_0 = 0.1, B_sf = 0.1):\n",
    "    N_stim = data.shape[0]\n",
    "    center = (N_pic-N_stim)//2\n",
    "\n",
    "    data_fullfield = (data.min().numpy()) * np.ones((N_pic, N_pic))\n",
    "    data_fullfield[int(center+i_offset):int(center+N_stim+i_offset), int(center+j_offset):int(center+N_stim+j_offset)] = data\n",
    "\n",
    "    # data normalization\n",
    "    # data_fullfield -= data_fullfield.mean()\n",
    "    # data_fullfield /= data_fullfield.std()\n",
    "    # data_fullfield *= std\n",
    "    # data_fullfield += mean\n",
    "    data_fullfield = (data_fullfield - data_fullfield.min())/(data_fullfield.max() - data_fullfield.min())\n",
    "    data_fullfield *= CONTRAST\n",
    "    data_fullfield += 0.5\n",
    "\n",
    "    if NOISE>0.:\n",
    "        im_noise, _ = MotionCloudNoise(sf_0 = sf_0, B_sf = B_sf)\n",
    "        im_noise = NOISE *  im_noise\n",
    "        data_fullfield += im_noise #randomized_perlin_noise() #\n",
    "        #indices_data = np.where(data_fullfield > data_fullfield.mean())\n",
    "        #im_noise[indices_data] = data_fullfield[indices_data]\n",
    "        #data_fullfield = im_noise\n",
    "    \n",
    "    whit.set_size((N_pic,N_pic))\n",
    "    data_fullfield = whit.whitening(data_fullfield)\n",
    "\n",
    "    data_retina = retina_vector @ np.ravel(data_fullfield)\n",
    "    \n",
    "    tensor_retina = data_retina.reshape(N_theta, N_azimuth, N_eccentricity, N_phase)\n",
    "    slice1 = tensor_retina[N_theta - 1,:,:,:].reshape(1,N_azimuth,N_eccentricity,N_phase)\n",
    "    slice2 = tensor_retina[0,:,:,:].reshape(1,N_azimuth,N_eccentricity,N_phase)\n",
    "    tensor_retina = np.concatenate ((slice1, tensor_retina, slice2), axis = 0)\n",
    "    tensor_retina = np.transpose(tensor_retina,(3,0,1,2))\n",
    "\n",
    "    return data_retina, tensor_retina, data_fullfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fullfield(accuracy_map, i_offset, j_offset, N_pic=128):\n",
    "    N_stim = accuracy_map.shape[0]\n",
    "    center = (N_pic-N_stim)//2\n",
    "\n",
    "    accuracy_fullfield = 0.1 * np.ones((N_pic, N_pic))\n",
    "    accuracy_fullfield[int(center+i_offset):int(center+N_stim+i_offset),\n",
    "                 int(center+j_offset):int(center+N_stim+j_offset)] = accuracy_map\n",
    "\n",
    "    accuracy_colliculus = colliculus_vector @ np.ravel(accuracy_fullfield)\n",
    "    #accuracy_colliculus = test_vector @ np.ravel(accuracy_fullfield)\n",
    "\n",
    "    return accuracy_colliculus, accuracy_fullfield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(value, border):\n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return int(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 100  # quantity of examples that'll be processed\n",
    "lr = 1e-4 #1e-3  #0.05\n",
    "\n",
    "OFFSET_STD = 15 #\n",
    "OFFSET_MAX = 30 #\n",
    "NOISE = 1 #0 #\n",
    "CONTRAST = 0.3 #1 #\n",
    "sf_0 = 0.2\n",
    "B_sf = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    i = 4\n",
    "    offset_std=OFFSET_STD\n",
    "    offset_max=OFFSET_MAX\n",
    "    i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    input_vector, _, image = mnist_fullfield(data[i, 0, :, :], i_offset, j_offset, \n",
    "                                    CONTRAST = CONTRAST, NOISE = NOISE,\n",
    "                                    sf_0 = sf_0, B_sf = B_sf)\n",
    "    #plt.imshow(input_test)\n",
    "    plt.figure(figsize = (20,6))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(132)\n",
    "    f = plt.plot(input_vector)\n",
    "    plt.subplot(133)\n",
    "    im = retina_inverse @ input_vector\n",
    "    plt.imshow(im.reshape(128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    i = 4\n",
    "    offset_std=OFFSET_STD\n",
    "    offset_max=OFFSET_MAX\n",
    "    i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    coll_fixmap, image = accuracy_fullfield(accuracy_map, i_offset, j_offset)\n",
    "    #plt.imshow(input_test)\n",
    "    plt.figure(figsize = (20,6))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(132)\n",
    "    f = plt.plot(coll_fixmap)\n",
    "    plt.subplot(133)\n",
    "    im = colliculus_inverse @ coll_fixmap\n",
    "    plt.imshow(im.reshape(128, 128))\n",
    "    print(max(coll_fixmap))\n",
    "    print(max(im))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cuda = False # torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if do_cuda else {}\n",
    "device = torch.cuda.device(\"cuda\" if do_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(batch_size=minibatch_size, train = True)\n",
    "test_loader = get_data_loader(batch_size=1000, train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS_CONV = True\n",
    "BIAS_DECONV = True #True\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #self.bn1= torch.nn.Linear(N_theta*N_azimuth*N_eccentricity*N_phase, 200, bias = BIAS_DECONV)\n",
    "        self.bn1= torch.nn.Linear(N_theta*N_azimuth*N_eccentricity*N_phase, 1000, bias = BIAS_DECONV)\n",
    "        #self.bn2 = torch.nn.Linear(200, 80, bias = BIAS_DECONV)\n",
    "        self.bn2 = torch.nn.Linear(1000, 1000, bias = BIAS_DECONV)\n",
    "        #self.bn3 = torch.nn.Linear(80, N_azimuth*N_eccentricity, bias = BIAS_DECONV)\n",
    "        self.bn3 = torch.nn.Linear(1000, N_azimuth*N_eccentricity, bias = BIAS_DECONV)\n",
    "                \n",
    "    def forward(self, image):\n",
    "       \n",
    "        h_bn1 = F.relu(self.bn1(image))               \n",
    "        h_bn2 = F.relu(self.bn2(h_bn1))\n",
    "        h_bn2_drop = F.dropout(h_bn2, p = .5) \n",
    "        u = self.bn3(h_bn2_drop)\n",
    "        \n",
    "        return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.BCEWithLogitsLoss() #torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_gain(prediction, fixmap_data, batch_size, full_fixmap = None):\n",
    "    #ndices_max = np.zeros(batch_size, dtype = 'int')\n",
    "    acc = [] #np.zeros(batch_size)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        fixmap_coll =  fixmap_data[i,:].data.numpy()\n",
    "        pred_coll = F.sigmoid(prediction[i,:]).data.numpy()\n",
    "        \n",
    "        indice_max_coll = np.where(pred_coll == max(pred_coll))[0][0]\n",
    "        acc_coll = fixmap_coll[indice_max_coll]\n",
    "        \n",
    "        '''masque = 0.1 + np.zeros(fixmap_coll.shape)\n",
    "        masque[indice_max_coll] = 1'''\n",
    "        \n",
    "        test = pred_coll.reshape((N_azimuth, N_eccentricity))\n",
    "        indices_ij = np.where(test == max(test.flatten()))\n",
    "        azimuth = indices_ij[0][0]\n",
    "        eccentricity = indices_ij[1][0]\n",
    "        full_masque = colliculus[azimuth,eccentricity,:] #> 0.0003\n",
    "        \n",
    "        \n",
    "        #print(indices_ij)\n",
    "        '''j_max = indices_ij[1][0]\n",
    "        if j_max > 1:\n",
    "            test[:,:int(j_max*2/3)] = 0.1 \n",
    "        pred_coll_test = test.flatten()'''\n",
    "        \n",
    "        if full_fixmap is not None:\n",
    "            full_ref = full_fixmap[i,:]\n",
    "            #print('OK')\n",
    "        else:\n",
    "            full_ref = colliculus_inverse @ fixmap_coll.flatten()\n",
    "            \n",
    "        full_pred = colliculus_inverse @ pred_coll.flatten()\n",
    "        #full_masque = colliculus_inverse @ masque.flatten()\n",
    "        #masque[np.where(masque < 0.11)] = 0\n",
    "        full_pred *= full_masque\n",
    "        #full_pred = colliculus_inverse @ pred_coll_test.flatten()\n",
    "        \n",
    "        indice_max_full = np.where(full_pred == max(full_pred))[0][0]\n",
    "        #print(indice_max_full)\n",
    "        acc_full = full_ref[indice_max_full] \n",
    "                \n",
    "        #acc[i] = max(acc_full, acc_coll)\n",
    "        if acc_full > acc_coll:\n",
    "            acc += [acc_full]\n",
    "            \n",
    "        #acc[i] = 0.1 + (acc[i] - 0.1) * 2.25\n",
    "    #print(indices_max)\n",
    "    if len(acc) > 0:\n",
    "        acc_mean = np.mean(acc) #fixmap_data.data.numpy()[:,indices_max])\n",
    "    else:\n",
    "        acc_mean = acc_coll\n",
    "    #acc = np.mean(fixmap_data[:,indices_max])\n",
    "    return acc_mean, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, minibatch_size, \\\n",
    "          optimizer=optimizer, \\\n",
    "          vsize = N_theta * N_azimuth * N_eccentricity * N_phase,\\\n",
    "          asize = 1, \\\n",
    "          offset_std=OFFSET_STD, \\\n",
    "          offset_max=OFFSET_MAX, \\\n",
    "          verbose=1, \\\n",
    "          CONTRAST=CONTRAST,\n",
    "          NOISE = NOISE,\n",
    "          sf_0 = sf_0, \n",
    "          B_sf = B_sf):\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    if verbose: print('Starting training...')\n",
    "    \n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        retina_data = np.zeros((minibatch_size, N_phase * N_theta * N_azimuth * N_eccentricity))\n",
    "        fixmap_data = np.zeros((minibatch_size, N_azimuth * N_eccentricity))\n",
    "\n",
    "        for i in range(minibatch_size):\n",
    "            i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "            j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "            retina_data[i, :], _, _  = mnist_fullfield(data[i, 0, :, :], i_offset, j_offset, \n",
    "                                                        CONTRAST = CONTRAST, NOISE = NOISE,\n",
    "                                                        sf_0 = sf_0, B_sf = B_sf) \n",
    "            fixmap_data[i,:], _ = accuracy_fullfield(accuracy_map, i_offset, j_offset)\n",
    "            \n",
    "\n",
    "        retina_data = Variable(torch.FloatTensor(retina_data))\n",
    "        fixmap_data = Variable(torch.FloatTensor(fixmap_data))\n",
    "        \n",
    "        prediction = net(retina_data)\n",
    "        loss = loss_func(prediction, fixmap_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose and batch_idx % 10 == 0:\n",
    "            #indices_max = np.zeros(minibatch_size, dtype = 'int')\n",
    "            #for i in range(minibatch_size):\n",
    "            #    indices_max[i] = np.where(prediction[i,:] == max(prediction[i,:]))[0][0]\n",
    "            #acc = np.mean(fixmap_data.data.numpy()[:,indices_max])\n",
    "            acc, _ = accuracy_gain(prediction, fixmap_data, minibatch_size)\n",
    "            print('[%d/%d] Loss: %.3f Acc : %.3f'%(batch_idx*minibatch_size, len(train_loader.dataset),loss.data.numpy(), acc))\n",
    "            f = open('2019-03-02-Necc-8.txt', 'a')\n",
    "            f.write('%.5f\\t%.5f'%(loss, acc))    \n",
    "            f.close()\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, optimizer=optimizer,\n",
    "         vsize=N_theta*N_azimuth*N_eccentricity*N_phase,\n",
    "         asize=N_azimuth*N_eccentricity, offset_std=OFFSET_STD, offset_max=OFFSET_MAX, \n",
    "         CONTRAST=CONTRAST, NOISE = NOISE,\n",
    "         sf_0 = sf_0, \n",
    "         B_sf = B_sf):\n",
    "    #for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    data, label = next(iter(test_loader))\n",
    "    batch_size = label.shape[0]\n",
    "\n",
    "    retina_data = np.zeros((batch_size, N_phase * N_theta * N_azimuth * N_eccentricity))\n",
    "    fixmap_data = np.zeros((batch_size, N_azimuth * N_eccentricity))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "        j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "        retina_data[i, :], _, _  = mnist_fullfield(data[i, 0, :, :], i_offset, j_offset, \n",
    "                                                    CONTRAST = CONTRAST, NOISE = NOISE,\n",
    "                                                    sf_0 = sf_0, B_sf = B_sf)\n",
    "        fixmap_data[i, :], _ = accuracy_fullfield(accuracy_map, i_offset, j_offset)\n",
    "\n",
    "\n",
    "    retina_data = Variable(torch.FloatTensor(retina_data))\n",
    "    fixmap_data = Variable(torch.FloatTensor(fixmap_data))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = net(retina_data) #.data.numpy()\n",
    "        #indices_max = np.zeros(batch_size, dtype = 'int')\n",
    "        #for i in range(batch_size):\n",
    "        #    indices_max[i] = np.where(output[i,:] == max(output[i,:]))[0][0]\n",
    "        #acc = np.mean(fixmap_data.data.numpy()[:,indices_max])\n",
    "        #acc = 0.1 + (acc - 0.1) * 2.5\n",
    "        acc, _ = accuracy_gain(output, fixmap_data, batch_size)\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anywhere target, with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additive noise + whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    for epoch in range(10):\n",
    "        train(net, minibatch_size)\n",
    "        loss = test(net)\n",
    "        print('Test set: Final Loss: %.3f'%loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test set: Final Loss: %.3f'%loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIC_NAME = \"2019-02-15-anywhere-additive-noise-white-1000-Necc-10\"\n",
    "#FIC_NAME = \"2019-03-02-anywhere-background-noise-white-1000\"\n",
    "if False:\n",
    "    torch.save(net, FIC_NAME + '.npy')\n",
    "else:\n",
    "    net = torch.load(FIC_NAME + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize = N_theta * N_azimuth * N_eccentricity * N_phase\n",
    "asize = N_azimuth * N_eccentricity\n",
    "offset_std=OFFSET_STD\n",
    "offset_max=OFFSET_MAX\n",
    "\n",
    "test_batch_size = 20\n",
    "test_loader = get_data_loader(batch_size=test_batch_size, train = False)\n",
    "\n",
    "data, label = next(iter(test_loader))\n",
    "input_n = np.zeros((test_batch_size, 1, vsize))\n",
    "a_data_n = np.zeros((test_batch_size, 1, asize))\n",
    "full_fixmap_n = np.zeros((test_batch_size, 128, 128))\n",
    "        # target = np.zeros((minibatch_size, asize))\n",
    "\n",
    "for idx in range(test_batch_size):\n",
    "    i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    input_n[idx, 0, :], _, _ = mnist_fullfield(data[idx, 0, :, :], i_offset, j_offset, \n",
    "                                            CONTRAST = CONTRAST, NOISE = NOISE,\n",
    "                                            sf_0 = sf_0, B_sf = B_sf)\n",
    "    a_data_n[idx, 0, :], full_fixmap_n[idx, :, :] = accuracy_fullfield(accuracy_map, i_offset, j_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta = 1/N_azimuth\n",
    "log_r, theta = np.meshgrid(np.linspace(0, 1, N_eccentricity + 1), np.linspace(-np.pi*(.5 + delta), np.pi*(1.5 - delta), N_azimuth + 1))\n",
    "for idx in range(test_batch_size):\n",
    "    im = retina_inverse @ input_n[idx,0,:]\n",
    "    plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(161)\n",
    "    plt.plot(input_n[idx,0,:])\n",
    "    plt.subplot(162)\n",
    "    plt.imshow(im.reshape(128, 128))\n",
    "    plt.plot(63.5, 63.5, 'r+')\n",
    "    plt.title(idx)\n",
    "    plt.subplot(163)\n",
    "    plt.plot(a_data_n[idx,0,:])    \n",
    "    col = colliculus_inverse @ a_data_n[idx,0,:]\n",
    "    ax = plt.subplot(164, projection='polar')\n",
    "    vec_t = Variable(torch.FloatTensor(a_data_n[idx,0,:]))\n",
    "    vec_t = vec_t.reshape((1,N_azimuth * N_eccentricity))\n",
    "    ax.pcolor(theta, log_r, vec_t.reshape((N_azimuth, N_eccentricity)))\n",
    "    #plt.imshow(col.reshape(128, 128))\n",
    "    in_t = Variable(torch.FloatTensor(input_n[idx,0,:]))\n",
    "    out_t = net(in_t)\n",
    "    out_sig = F.sigmoid(out_t).detach().numpy()\n",
    "    out_t = out_t.reshape((1,N_azimuth * N_eccentricity))\n",
    "    #acc, _ = accuracy_gain(out_t.reshape(1,N_azimuth * N_eccentricity), vec_t.reshape(1,N_azimuth * N_eccentricity), 1)\n",
    "    acc, _ = accuracy_gain(out_t, vec_t, 1, full_fixmap = full_fixmap_n[idx, :].reshape((1, -1)))\n",
    "    plt.subplot(165)\n",
    "    plt.plot(out_sig)    \n",
    "    plt.title(acc)\n",
    "    view = colliculus_inverse @ out_sig.flatten()\n",
    "    ax = plt.subplot(166, projection='polar')\n",
    "    ax.pcolor(theta, log_r, out_sig.reshape((N_azimuth, N_eccentricity)))\n",
    "    #plt.imshow(view.reshape(128, 128))\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    i = 0\n",
    "    offset_std=OFFSET_STD\n",
    "    offset_max=OFFSET_MAX\n",
    "    i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    input_vector, _, image = mnist_fullfield(data[i, 0, :, :], i_offset, j_offset, \n",
    "                                    CONTRAST = CONTRAST, NOISE = NOISE,\n",
    "                                    sf_0 = sf_0, B_sf = B_sf)\n",
    "    coll_fixmap, image = accuracy_fullfield(accuracy_map, i_offset, j_offset)\n",
    "    #plt.imshow(input_test)\n",
    "    in_ = Variable(torch.FloatTensor(input_vector))\n",
    "    out = net(in_)\n",
    "    \n",
    "    plt.figure(figsize = (20,6))\n",
    "    plt.subplot(151)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(152)\n",
    "    f = plt.plot(coll_fixmap)\n",
    "    f = plt.plot(F.sigmoid(out.data))\n",
    "    plt.subplot(153)\n",
    "    im = colliculus_inverse @ coll_fixmap\n",
    "    plt.imshow(im.reshape(128, 128))\n",
    "    print(max(coll_fixmap))\n",
    "    print(max(im))\n",
    "    plt.subplot(154)\n",
    "    im_pred = colliculus_inverse @ F.sigmoid(out).data.numpy().flatten()\n",
    "    plt.imshow(im_pred.reshape(128, 128))\n",
    "    ind_pred = np.where(im_pred == max(im_pred))\n",
    "    print(im[ind_pred])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize = N_theta * N_azimuth * N_eccentricity * N_phase\n",
    "asize = N_azimuth * N_eccentricity\n",
    "offset_std=OFFSET_STD\n",
    "offset_max=OFFSET_MAX\n",
    "\n",
    "test_batch_size = 200\n",
    "\n",
    "mem_acc = []\n",
    "mem_acc_data = []\n",
    "mem_ref = []\n",
    "mem_ref_data = []\n",
    "\n",
    "for r in range(28):\n",
    "    print(r)\n",
    "\n",
    "    test_loader_2 = get_data_loader(batch_size=test_batch_size, train = False)\n",
    "\n",
    "    data, label = next(iter(test_loader_2))\n",
    "    input_n = np.zeros((test_batch_size, 1, vsize))\n",
    "    a_data = np.zeros((test_batch_size, asize))\n",
    "    full_fixmap_n = np.zeros((test_batch_size, 128 * 128))\n",
    "    # target = np.zeros((minibatch_size, asize))\n",
    "        \n",
    "    ref_data = np.zeros(test_batch_size)\n",
    "\n",
    "    for idx in range(test_batch_size):\n",
    "        theta = np.random.rand() * 2 * np.pi\n",
    "        i_offset = int(r * np.cos(theta))\n",
    "        j_offset = int(r * np.sin(theta))\n",
    "        #i_offset = i #minmax(np.random.randn() * offset_std, offset_max)\n",
    "        #j_offset = 0 #minmax(np.random.randn() * offset_std, offset_max)\n",
    "        input_n[idx, 0, :], _, _ = mnist_fullfield(data[idx, 0, :, :], i_offset, j_offset, \n",
    "                                                CONTRAST = CONTRAST, NOISE = NOISE,\n",
    "                                                sf_0 = sf_0, B_sf = B_sf)\n",
    "        a_data[idx, :], tmp = accuracy_fullfield(accuracy_map, i_offset, j_offset)\n",
    "        full_fixmap_n[idx,:] = tmp.flatten()\n",
    "        ref_data[idx] = accuracy_map[27 + i_offset, 27 + j_offset]\n",
    "        \n",
    "        \n",
    "        \n",
    "    in_t = Variable(torch.FloatTensor(input_n))\n",
    "    out_t = net(in_t)\n",
    "    a_data_t = Variable(torch.FloatTensor(a_data))\n",
    "    #out_sig = F.sigmoid(out).detach().numpy()\n",
    "    acc, acc_data = accuracy_gain(out_t, a_data_t, test_batch_size, full_fixmap=full_fixmap_n)\n",
    "    mem_acc += [acc]\n",
    "    mem_acc_data += [acc_data]\n",
    "    \n",
    "    mem_ref += [np.mean(ref_data)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fixmap_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in range(28):\n",
    "    plt.figure()\n",
    "    plt.hist(mem_acc_data[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mem_acc)\n",
    "f = plt.plot(mem_ref) #accuracy_map[27,27:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mem_acc)\n",
    "f = plt.plot(mem_ref) #accuracy_map[27,27:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mem_acc)\n",
    "f = plt.plot(mem_ref) #accuracy_map[27,27:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot(mem_acc_data, showfliers=False)\n",
    "f = plt.plot(mem_ref) #accuracy_map[27,27:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.hist(mem_acc_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mem_acc)\n",
    "f = plt.plot(mem_ref) #accuracy_map[27,27:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''im_coll = colliculus[0,0,:].reshape((128,128)) +\\\n",
    "        colliculus[1,0,:].reshape((128,128)) +\\\n",
    "        colliculus[2,0,:].reshape((128,128)) +\\\n",
    "        colliculus[3,0,:].reshape((128,128)) +\\\n",
    "        colliculus[4,0,:].reshape((128,128)) +\\\n",
    "        colliculus[5,0,:].reshape((128,128)) +\\\n",
    "        colliculus[6,0,:].reshape((128,128)) +\\\n",
    "        colliculus[7,0,:].reshape((128,128))'''\n",
    "im_coll = colliculus[4,0,:].reshape((128,128))\n",
    "plt.imshow(im_coll)\n",
    "plt.figure()\n",
    "f = plt.plot(im_coll)\n",
    "print(sum(im_coll.flatten()))\n",
    "f = plt.plot(np.arange(0,55) - 27 + 64, accuracy_map[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.copy(-30 * colliculus[3,0,:].reshape((128,128))) \n",
    "b_inf = 64 - 27\n",
    "im[b_inf:b_inf+55,b_inf:b_inf+55] += accuracy_map\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.copy(-30 * colliculus[3,0,:].reshape((128,128))) \n",
    "b_inf = 64 - 27\n",
    "im[b_inf:b_inf+55,b_inf:b_inf+55] += accuracy_map\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.copy(-30 * colliculus[3,0,:].reshape((128,128))) \n",
    "b_inf = 64 - 27\n",
    "im[b_inf:b_inf+55,b_inf:b_inf+55] += accuracy_map\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.copy(-30 * colliculus[3,0,:].reshape((128,128))) \n",
    "b_inf = 64 - 27\n",
    "im[b_inf:b_inf+55,b_inf:b_inf+55] += accuracy_map\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.plot(im[63,:])\n",
    "plt.plot(range(64-27, 64-27 + 55) , accuracy_map[27,:])\n",
    "im2 = colliculus[3,0,:].reshape((128,128))\n",
    "plt.plot(im2[63,:] * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.plot(im[63,:])\n",
    "plt.plot(range(64-27, 64-27 + 55) , accuracy_map[27,:])\n",
    "im2 = colliculus[3,0,:].reshape((128,128))\n",
    "plt.plot(im2[63,:] * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.plot(im[63,:])\n",
    "plt.plot(range(64-27, 64-27 + 55) , accuracy_map[27,:])\n",
    "im2 = colliculus[3,0,:].reshape((128,128))\n",
    "plt.plot(im2[63,:] * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.plot(im[63,:])\n",
    "plt.plot(range(64-27, 64-27 + 55) , accuracy_map[27,:])\n",
    "im2 = colliculus[3,0,:].reshape((128,128))\n",
    "plt.plot(im2[63,:] * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sum = colliculus[0,0,:].reshape((128,128)) +\\\n",
    "           colliculus[0,1,:].reshape((128,128)) +\\\n",
    "           colliculus[0,3,:].reshape((128,128)) +\\\n",
    "           colliculus[0,4,:].reshape((128,128)) +\\\n",
    "           colliculus[0,5,:].reshape((128,128)) +\\\n",
    "           colliculus[0,6,:].reshape((128,128)) +\\\n",
    "           colliculus[0,7,:].reshape((128,128)) +\\\n",
    "           colliculus[0,8,:].reshape((128,128))\n",
    "f = plt.plot(im_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(colliculus[0,5,:].reshape(128,128) > 0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
