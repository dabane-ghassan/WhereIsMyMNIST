% !TEX root = paper.tex
% !TEX encoding = UTF-8 Unicode
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8
% !TEX spellcheck = en-US


We develop a visuo-motor model that implements visual search as a focal accuracy-seeking policy across a crowded visual display.
Stemming from the active inference framework, saccade-based visual exploration is idealized as an inference process, assuming that the target position and category are independently drawn from a common generative process. 
This independence allows to divide the visual processing in two independent pathways, consistently with the anatomical ``What''/``Where'' separation. 
A biomimetic log-polar treatment of the visual information, that includes the strong compression rate performed at the sensor level by retina and V1 encoding,  
is preserved up to the action selection level.
A dual neural network architecture, that independently learns where to look and what to see, is then trained, 
with the foveal accuracy used as a monitoring signal for action selection.
This allows in particular to interpret the ``áº€here'' as a retinotopic action selection pathway, that drives the fovea toward the target position, in order to increase the recognition accuracy.
A specific approximate Information Gain metric, taken as the difference between central and peripheral accuracy, is used for action selection after training.
The comparison of both accuracies amounts either to select a saccade or to keep the eye focused at the center, so as to identify the target.
Tested on a simple task of finding digits in a large, cluttered image, simulation results demonstrate the benefit of our approach, whose key computational shortcuts finally provide ways to implement visual search in a sub-linear fashion, in contrast with mainstream computer vision. 


% TODO : include whenever we do more than one saccade...
% Without a saccade, the accuracy drops to the baseline at half the width of the target from the center of fixation, while actuating a saccade is beneficial in up to 3 times its size, allowing a much wider covering of the image. The ratio between the marginal accuracies shows that this model is computationally an order of magnitude more efficient than that of a classical brute-force framework. Until the foveal classifier is confident, the system should thus perform saccades to the most likely target position. The different accuracy predictions, such as the ones done in the ``what'' and the ``where'' pathway, may also explain more elaborate decision making, such as the inhibition of return.
%This provides evidence of the importance of identifying ``putative interesting targets'' first and we highlight some possible extensions of our model both in computer vision and modeling.
% TODO: We compared the results of this model with classical psychophysical results in visual search
%This generic visual search problem is of broad interest to machine learning, computer vision and robotics, but also to neuroscience, as it speaks to the mechanisms underlying foveation and more generally to low-level attention mechanisms. From a computer vision perspective, the problem is generally addressed by processing the different hypothesis (categories) at all possible spatial configuration through dedicated parallel hardware. The human visual system, however, seems to employ a different strategy, through a combination of a foveated sensor with the capacity of rapidly moving the center of fixation using saccades.
%Visual processing is done through fast and specialized pathways, one of which mainly conveying information about target position and speed in the peripheral space (the "where" pathway), the other mainly conveying  information about the identity of the target (the "what" pathway). The combination of the two pathways is expected to provide most of the useful knowledge about the external visual scene. Still, it is unknown why such a separation exists.
