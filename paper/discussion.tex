% !TEX root = paper.tex
% !TEX encoding = UTF-8 Unicode
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8
% !TEX spellcheck = en-US
\section{Discussion}
\label{sec:discussion}
%\subsection{Summary}
%## Main results:



In summary, we have proposed a visuo-motor action-selection model that implements a focal accuracy-seeking policy across the image. It relies on an interpretation of the Information Gain metric as a difference between central and peripheral accuracy processing. Each accuracy is predicted through separate processing pathways, namely the ``What'' pathway for the central pixels and the ``Where'' pathway for the periphery.  The comparison of both accuracies amounts either to select a saccade or to keep the eye focused at the center, so as to identify the label. The predicted accuracy map has, in our case, the role of a value-based action selection map, as it is the case in model-free reinforcement learning. However, it also owns a probabilistic interpretation that may be combined with concurrent accuracy predictions (such as the one done through the ``what'' pathway) to bring out more elaborate decision making which are relevant for visual search, such as inhibition of return for instance. 

Our main modelling assumption here is an \emph{accuracy-driven} monitoring of action, stating in short that the ventral classification accuracy drives the dorsal selection of action maps. {\color{magenta} Biological evidence for accuracy-map driven action selection? }

One crucial aspect of vision highlighted by our model is the importance of centering objects in recognition. Despite the robust translation invariance observed on the ``What'' pathway, there is small radius of 2-3 pixels around the target's center that needs to be respected to maximize the classification accuracy. This relates to the idea of finding an absolute referential for an object, for which the recognition is easier. If the center of fixation is fixed, the log-polar encoding of an object class shows invariance to both rotation and scale~\citep{Traver10}. Incorporating this scale and rotation invariance may thus extend the recognition capabilities of the model.


Compared to classical architectures, this approach is energy-efficient. It encompasses a full log-polar processing pathway which induces a high compression rate similar to that performed by retina and V1 encoding up to the action selection level. This finally provides an effective sub-linear visual search scheme (compared to the linear time necessary to scan all positions on a regular grid), that may allow to detect an object in large visual environments at little cost. This should be particularly beneficial when the computing resources are under constraint, such as for drones or mobile robots. 

One limit of our model is the simplicity of the generative model for inputs. This simplicity was important to fully assess the possibility and robustness of implementing a ``where'' module which predicts the map of accuracies from the (degraded) log-polar transformed retinal image.
In future perspectives, more elaborate image categorization, such as the ones performed on natural images using deep convolutional nets, could be considered by replacing the current ``what'' module with a more elaborate one. 
%By preserving a probabilistic interpretation in bio-realistic action selection, 


Finally, our model relies on a strong idealization, assuming the presence of an unique target. The presence of many targets in a scene should be addressed, which amounts to sequentially select targets, in combination with implementing an inhibition of return mechanism. 
%Moreover, inhibition of return mechanism could envisioned by preserving a probabilistic interpretation in bio-realistic action selection. 
This would generate more realistic visual scan-paths over images. %This could be used to provide realistic priors over action selection maps.  
%In particular, identified regions of interest may then be compared with the baseline bottom-up approaches, such as the low-level feature-based saliency maps~\citep{Itti01}. 
Actual visual scan path over images could also be used to provide priors over action selection maps that should improve realism.  %
%It may indeed be possible to consider , and 
Identified regions of interest may then be compared with the baseline bottom-up approaches, such as the low-level feature-based saliency maps~\citep{Itti01}. 
Maximizing the Information Gain over multiple targets needs to be envisioned with a more refined probabilistic framework, including mutual exclusion over overt and covert targets. How the brain may combine and integrate these various probabilities is still an open question, that amounts to the fundamental binding problem. %: How is it possible to meaningfully combine independently extracted features.

