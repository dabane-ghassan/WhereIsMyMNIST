% !TEX root = plos-paper.tex
% !TEX encoding = UTF-8 Unicode
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8
% !TEX spellcheck = en-US
\section{Discussion} \label{sec:discussion}
In summary, we have proposed a visuo-motor action-selection model that implements a focal accuracy-seeking policy across the image. Our main modeling assumption here is an \emph{accuracy-driven} monitoring of action, stating in short that the ventral classification accuracy drives the dorsal selection on an accuracy map. The comparison of both accuracies amounts either to select a saccade or to keep the eye focused at the center, so as to identify the target. The predicted accuracy map has, in our case, the role of a value-based action selection map, as it is the case in model-free reinforcement learning. However, it also owns a probabilistic interpretation that may be combined with concurrent accuracy predictions (such as the one done through the ``What'' pathway) to explain more elaborate aspect of the decision making mprocesses which are relevant for visual search, such as the inhibition of return~\cite{Itti01}, without having to explictly implement such a heursitics. This combination of a scalar drive with action selection is reminiscent of the actor/critic principle proposed for long time in the reinforcement learning community~\cite{sutton1998reinforcement}. In biology, the ventral and the dorsolateral division of the striatum have been suggested to implement such an actor-critic separation~\cite{joel2002actor, takahashi2008silencing}. Consistently with those findings, our central accuracy drive and peripheral action selection map can respectively be considered as the ``critic'' and the ``actor'' of an accuracy-driven action selection scheme, with foveal identification/desambiguation taken as a ``visual reward''.

Moreover, one crucial aspect of vision highlighted by our model is the importance of centering objects in recognition. Despite the robust translation invariance observed on the ``What'' pathway, we found that there is a small tolerance radius of about $4$ pixels around the target's center that needs to be respected to maximize the classification accuracy. This relates to the idea of finding an absolute referential for an object, for which the recognition is easier. If the center of fixation is fixed, the log-polar encoding of an object has the notable properties to map object rotations and scalings toward translations in the radial and angular directions of the visual domain~\cite{Traver10}. The translation invariance found in convolutional processing may thus be extended to both rotation and scale invariance in the log-polar domain. Incorporating this scale and rotation invariance may thus extend the generalization capabilities of the model.

Despite its simplicity, the generative model used to generate our visual display allowed to assess the effectiveness and robustness of our learning scheme, that should be extended to more complex displays and more realistic closed-loop setups. On the one side, the restricted $28\times28$ input used for the foveal processing is a mere placeholder, that should be replaced by more elaborate computer vision frameworks, such as Inception~\cite{szegedy2015going} or VGG-19~\cite{simonyan2014very}, that can handle a more ecological natural image classification. The main advantage of our peripheral image processing is its energy-efficiency. Our full log-polar processing pathway consistently conserves the high compression rate performed by retina and V1 encoding up to the action selection level. The organization of both the visual filters and the action maps in concentric log-polar elements, with radially exponentially growing spatial covering, can thus serve as a baseline for a future sub-linear (logarithmic) visual search in computer vision.
% {\color{red} \textbf{Rev 2} The authors mention “sub-linear (logarithmic) visual search”. As a reader I expected more than just a mention. How will this be achieved? This claim is not substantiated by any means.}
This may allow to detect an object in large visual environments at little cost, which should be particularly beneficial when the computing resources are under constraint, such as for drones or mobile robots.

Finally, our model relies on a strong idealization, assuming the presence of a unique target. This is well adapted to a fast changing visual scene as is demonstarted by our ability to perform as fast as 5 saccades per second to detect faces in a cluttered environment~\cite{Martin18}. However, some visual scenes ---such as when looking at a painting in a museum--- allow for a longer inspection of its details.  The presence of many targets in a scene should be addressed, which amounts to sequentially select targets, in combination with implementing a more elaborate inhibition of return mechanism to account for the trace of the performed saccades. This would generate more realistic visual scan-paths over images. Actual visual scan path over images could also be used to provide priors over action selection maps that should improve realism.  Identified regions of interest may then be compared with the baseline bottom-up approaches, such as the low-level feature-based saliency maps~\cite{Itti01}. Maximizing the Information Gain over multiple targets needs to be envisioned with a more refined probabilistic framework extending previous models~\cite{Friston12}, which would include phenomena such as mutual exclusion over overt and covert targets. How the brain may combine and integrate these various probabilities is still an open question, that amounts to the fundamental binding problem.
