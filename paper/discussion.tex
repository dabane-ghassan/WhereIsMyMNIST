% !TEX root = paper.tex
% !TEX encoding = UTF-8 Unicode
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8
% !TEX spellcheck = en-US
\section{Discussion}
\label{sec:discussion}
%\subsection{Summary}
%## Main results:

In summary, we have proposed a visuo-motor action-selection model that implements a focal accuracy-seeking policy across the image. It relies on an interpretation of the Information Gain metric as a difference between central and peripheral accuracy processing.  The comparison of both accuracies amounts either to select a saccade or to keep the eye focused at the center, so as to identify the label. The predicted accuracy map has, in our case, the role of a value-based action selection map, as it is the case in model-free reinforcement learning. However, it also owns a probabilistic interpretation that may be combined with concurrent accuracy predictions (such as the one done through the ``what'' pathway) to bring out more elaborate decision making which are relevant for visual search, such as inhibition of return for instance. 

One crucial aspect of vision highlighted by our model is the importance of centering objects in recognition. Despite the robust translation invariance observed on the ``What'' pathway, there is small radius of 2-3 pixels around the target's center that needs to be respected to maximize the classification accuracy. This relates to the idea of finding an absolute referential for an object, for which the recognition is easier. If the center of fixation is fixed, the log-polar encoding of an object class shows invariance to both rotation and scale~\citep{Traver10}. Incorporating this scale and rotation invariance may thus extend the recognition capabilities of the model.

Compared to classical architectures, this approach is energy-efficient. It encompasses a full log-polar processing pathway which induces a high compression rate similar to that performed by retina and V1 encoding up to the action selection level. This finally provides an effective sub-linear visual search scheme (compared to the linear time necessary to scan all positions on a regular grid), that may allow to detect an object in large visual environments at little cost. This should be particularly beneficial when the computing resources are under constraint, such as for drones or mobile robots. 

%\subsection{Limits}

% deep learning proves that one solution exists, but what is the visual substrate actually used? 

%## Limits and Open questions
%- Importance of centering objects:
%- Central object referential
%- log polar scale/rotation invariance
%- (feedback) prediction
%- Information Gain-based d√©cision :
%- Sequential info gain converges to zero: in practice 2-3 saccades are enough
%- Pursuit vs. saccade.
%- Maximizing info gain on multiple targets/ddls.
%- Overt/covert attention
%- Inhibition of return

One limit of our model is the simplicity of the generative model for inputs. This simplicity was important to fully assess the possibility and robustness of implementing a ``where'' module which predicts the map of accuracies from the (degraded) log-polar transformed retinal image.
In future perspectives, more elaborate image categorization, such as the ones performed on natural images by the Imagenet dataset using deep convolutional nets, could be envisaged in our model by simply replacing the ``what'' module. 
Finally, our model relies on a strong idealization, assuming the existence of an unique target. The presence of many targets in a scene should be addressed, which amounts to sequentially select targets, in combination with implementing an inhibition of return mechanism. Moreover, inhibition of return mechanism could envisioned by preserving a probabilistic interpretation in bio-realistic action selection. This would generate realistic visual scan-paths over images. This could be used to provide realistic priors over action selection maps.  In particular, identified regions of interest may then be compared with the baseline bottom-up approaches, such as the low-level feature-based saliency maps~\citep{Itti01}. Maximizing the Information Gain over multiple targets needs to be envisaged with a more refined probabilistic framework, including mutual exclusion over overt and covert targets. How the brain may combine and integrate these various probabilities is still an open question, and which may allow answering to the fundamental binding problem. %: How is it possible to meaningfully combine independently extracted features.
%\subsection{Perspectives}
