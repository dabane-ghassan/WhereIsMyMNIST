\section{Methods}


\subssection{Notations}
\begin{itemize}
	\item $\boldsymbol{x}$ : visual field (image)
	\item $\boldsymbol{y}$ : target category (categorical)
	\item $\boldsymbol{u}$ : target position (real coordinates or categorical, retinocentric referential)

\end{itemize}

Generative model :
$$ \boldsymbol{x} \sim P(X|\boldsymbol{y}, \boldsymbol{u}) $$

Full inference (posterior):
$$ P(Y, U|\boldsymbol{x}) \propto  P(\boldsymbol{x}|Y, U) $$

Independence assumptions :
\begin{equation} 
P(Y, U) = P(Y)  P(U) \text{\emph{ (toujours vrai)}}
\label{eq:indep-1}
\end{equation}

\begin{equation}  
P(Y, U|X) = P(Y|X)  P(U|X) \text{\emph{ (faux s'il y a plusieurs cibles)}}
\label{eq:indep-2}
\end{equation}

Partial inference on object category:
$$ P(Y|\boldsymbol{x}, \boldsymbol{u}) \propto  P(\boldsymbol{x}|Y, \boldsymbol{u}) $$

Partial inference on object position:
$$ P(U|\boldsymbol{x}, \boldsymbol{y}) \propto  P(\boldsymbol{x}|U, \boldsymbol{y}) $$

Marginals:
\begin{itemize}
\item $ P(Y|\boldsymbol{x}) = \int P(Y|\boldsymbol{x}, \boldsymbol{u}) d\boldsymbol{u}$
\item $ P(U|\boldsymbol{x}) = \int P(U|\boldsymbol{x}, \boldsymbol{y}) d\boldsymbol{y}$
\end{itemize}

\subsubsection{What we did so far...}

Consider a view $\boldsymbol{x}$ that contains a single target $\boldsymbol{y}$ at unknown retinocentric position $\boldsymbol{u}$. The brain needs to guess both  $\boldsymbol{y}$ and $\boldsymbol{u}$ with limited computational resources. 
   
We assume here that the brain adopts independence assumption (\ref{eq:indep-2}), making a separation between the ``Where'' and the ``What'' pathways, forming separate (and cheaper) inferences :
\begin{itemize}
\item $p(Y|\boldsymbol{x})$
\item $p(U|\boldsymbol{x})$
\end{itemize}

Another assumption is that the category $\boldsymbol{y}$ is \emph{translationally invariant}: given a transformation $\mathcal{T}$,
$$\mathcal{T}(\boldsymbol{u}, \boldsymbol{y}) 
= (\mathcal{T}(\boldsymbol{u}), \boldsymbol{y})$$

Now, given $\boldsymbol{x}$ and the separation assumption, it is sensible to change the viewpoint to better estimate $\boldsymbol{y}$, because  $\boldsymbol{y}$ is invariant to the viewpoint transformation.

This is where \emph{active inference} comes into the play:
\begin{itemize}
\item Consider that the true target is $\hat{\boldsymbol{y}}$
\item Consider that the target current retinocentric position is $\boldsymbol{u}$
\item Then, for any translation $\delta \boldsymbol{u}$, the future posterior on the true target is estimated by:
$\mathbb{E}_{\boldsymbol{x}'\sim p(X|\hat{\boldsymbol{y}}, \boldsymbol{u}+\delta \boldsymbol{u})} p(\hat{\boldsymbol{y}}|\boldsymbol{x}')$
\item And the optimal translation is:  $\underset{\delta\boldsymbol{u}}{\text{ argmax }}  \mathbb{E}_{\boldsymbol{x}'\sim p(X|\hat{\boldsymbol{y}}, \boldsymbol{u}+\delta \boldsymbol{u})} p(\hat{\boldsymbol{y}}|\boldsymbol{x}')$
\end{itemize}

If now $\boldsymbol{u}$ is unknown and needs to be guessed from $\boldsymbol{x}$, the optimal translation is:
$$\underset{\delta\boldsymbol{u}}{\text{ argmax }} \mathbb{E}_{\boldsymbol{u}\sim p(U|\boldsymbol{x})} \mathbb{E}_{\boldsymbol{x}'\sim p(X|\hat{\boldsymbol{y}}, \boldsymbol{u}+\delta \boldsymbol{u})} p(\hat{\boldsymbol{y}}|\boldsymbol{x}')$$
with :
\begin{itemize}
\item $p(U|\boldsymbol{x})$ the inferred target position
\item and $\mathbb{E}_{\boldsymbol{x}'\sim p(X|\hat{\boldsymbol{y}}, \boldsymbol{u}+\delta \boldsymbol{u})} p(\hat{\boldsymbol{y}}|\boldsymbol{x}')$ the expected inference on the actual target.
\end{itemize}

\subsubsection{Accuracy maps}
 
In practice, it is computationally impossible to make exact guesses about the future observation $\boldsymbol{x}'$. Our second assumption is that instead of predicting future inferences on true target, the brain trains a \emph{parametric accuracy map} by experience (trial and error).


In a model-based approach, the \emph{accuracy maps} can be calculated using a parametric classifier : 
 \begin{itemize}
 \item Given a training set $\{(x_1, u_1, y_1), ..., (x_n, u_n, y_n)\}$:
 \begin{itemize}
 \item Train a classifier $p_\theta$ that estimates $p(Y|\boldsymbol{x})$. 
 \end{itemize}
 \item Then, for each class $\hat{\boldsymbol{y}}$, taking $\tilde{\boldsymbol{y}}\sim p_\theta(Y|\boldsymbol{x})$,\emph{ the classification rate $r_\theta(\boldsymbol{u})$ is an estimator of the posterior expectation :}
 \begin{align*}
 r_\theta(\boldsymbol{u}) 
 &= \mathbb{E}_{ \boldsymbol{x} \sim p(X|\hat{\boldsymbol{y}}, \boldsymbol{u})}
 \mathbb{E}_{\tilde{\boldsymbol{y}}\sim p_\theta(Y|\boldsymbol{x})} \delta_{\hat{\boldsymbol{y}}=\tilde{\boldsymbol{y}}}\\
 &= \mathbb{E}_{ \boldsymbol{x} \sim p(X|\hat{\boldsymbol{y}}, \boldsymbol{u})} p_\theta(\hat{\boldsymbol{y}}|\boldsymbol{x})\\
 &\simeq \mathbb{E}_{ \boldsymbol{x} \sim p(X|\hat{\boldsymbol{y}}, \boldsymbol{u})} p(\hat{\boldsymbol{y}}|\boldsymbol{x})
 \end{align*} 
 that forms an \emph{accuracy map} for each target position $\boldsymbol{u}$.\\
 \end{itemize}

\subsubsection{Parametric transformation (Colliculus?) map}

One can now select $\delta\boldsymbol{u}$ with the parametric estimator:
\begin{align*}
\widehat{\delta\boldsymbol{u}} &\simeq \underset{\delta\boldsymbol{u}}{\text{ argmax }} 
\mathbb{E}_{\boldsymbol{u}\sim p(U|\boldsymbol{x})}  
r_\theta(\boldsymbol{u}+\delta\boldsymbol{u})\\
%&= \underset{\boldsymbol{u}' \in \mathcal{U}}{\text{ argmax }} A(\boldsymbol{u}'|\boldsymbol{x}, \boldsymbol{u})
&= \underset{\delta\boldsymbol{u}}{\text{ argmax }} Q(\delta\boldsymbol{u}|\boldsymbol{x})
\end{align*}
with $Q(\delta\boldsymbol{u}|\boldsymbol{x})$ the \emph{transformation} map, given the view $\boldsymbol{x}$ and the marginal posterior estimate $p(U|\boldsymbol{x})$. 

It must be noticed that, given $\hat{\boldsymbol{u}} = \underset{\boldsymbol{u}}{\text{ argmax }} 
r_\theta(\boldsymbol{u}))$,  the transformation map is maximal at $\delta\boldsymbol{u} = \hat{\boldsymbol{u}} - \boldsymbol{u}$. Each initial $\boldsymbol{u}$ provides a different transformation map, that is a shift of the original accuracy map (\emph{Ergodic assumption??}).
 
We assume in the following that a parametric action value map $Q_\psi$ can be trained on top of the parametric classifier $p_\theta$ and its accuracy map $r_\theta$.
The training set is $\{(\boldsymbol{x}_1, \boldsymbol{u}_1), ..., (\boldsymbol{x}_n, \boldsymbol{u}_n)\}$ and the accuracy map classifier learns to associate each $\boldsymbol{x}$ with its full transformation map $Q(.|\boldsymbol{x})$. 



\subsubsection{Algorithms}

Once $p_\theta$ and $Q_\psi$ are trained, the recognition algorithm is straightforward:  

\paragraph{Single saccade algorithm:}
\begin{enumerate}
	\item Read the view $\boldsymbol{x}$
	\item Choose $\delta\boldsymbol{u}$ according to $Q_\psi(.|\boldsymbol{x})$
	\item Move the eye 
	\item Update the view $\boldsymbol{x}'$
	\item Identify the target with $\tilde{\boldsymbol{y}} \sim p_\theta(Y|\boldsymbol{x}')$
\end{enumerate}


\paragraph{Multi saccades algorithm:}
\begin{enumerate}
\item $q(Y) \leftarrow$ uniform distribution
\item Read the view $\boldsymbol{x}$
\item Choose $\delta\boldsymbol{u}$ according to $Q_\psi(.|\boldsymbol{x})$
\item Repeat several times up to some posterior confidence threshold:
	\begin{enumerate}
		\item Move the eye 		
		\item Read $\boldsymbol{x}$
		\item $q(Y) \leftarrow q(Y) \times p_\theta(Y|\boldsymbol{x})$
		\item normalize $q$
		\item Choose $\delta\boldsymbol{u}$ according to $Q_\psi(.|\boldsymbol{x})$ (with some inhibition of return mechanism)
	\end{enumerate}
	\item Identify the target with $\tilde{\boldsymbol{y}} \sim q(Y)$
\end{enumerate}

\subsection{Visual transformation}
\subsubsection{Wavelets}
\subsubsection{Log Gabor}

\subsection{Accuracy map}

\subsection{Network architecture}

