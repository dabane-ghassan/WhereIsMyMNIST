In a large visual display, how do we efficiently find a target whose position and category are unknown? From a computer vision perspective, this visual search problem is generally addressed by inferring the different possible identities at all possible spatial configurations. However, this may be costly in terms of computing time. The human visual system, however, seems to employ a different strategy, through a combination of a foveated sensor with the capacity of rapidly moving the center of fixation using saccades. Physiologically, visual processing is done through two specialized pathways, the ``where'' pathway mainly conveying information about target position and speed in the peripheral space, the ``what'' pathway mainly information about the category of the target. We will propose an active inference process as the ground principles of saccadic exploration, assuming that the position and category of objects are independent. Knowing that the visual sensor is foveated, we consider a hierarchical neural network learning to infer the accuracy of finding targets in retinotopic coordinates, independently to their category. This framework was tested on a simple task of finding digits in a large, cluttered image. With cluttered noise ensuring the category is not readable in the periphery, results demonstrate the benefit of specifically learning where to look and this before actually identifying the target category. In the ``what'' pathway, the accuracy drops to the baseline at mere 5 pixels away from the center of fixation, while actuating a saccade is beneficial in up to 26 pixels around, allowing a much wider covering of the image. The ratio between the marginal accuracies forms an ``accuracy gain'', that quantifies the benefit of the model. %Until the foveal classifier is confident, the system should thus perform saccades to the most likely target position. The different accuracy predictions, such as the ones done in the ``what'' and the ``where'' pathway, may also explain more elaborate decision making, such as the inhibition of return. % TODO : include whenever we do more than one saccade...
The approach is also energy-efficient as it includes the strong compression rate performed by retina and V1 encoding, which is preserved up to the action selection level. The computational cost of this strategy is thus an order of magnitude more efficient than that of a classical brute-force framework.
%This provides evidence of the importance of identifying ``putative interesting targets'' first and we highlight some possible extensions of our model both in computer vision and modeling.
% TODO: We compared the results of this model with classical psychophysical results in visual search
% TODO: ACTIVE INFERENCE? LOGPOLAR ENCODING? SALIENCY MAPS?
%
% the existence of a generative model from which both the target position and category can be inferred through active sampling. We will take for granted
%
% The interplay between both pathways is expected to provide most of the useful knowledge about the external visual scene. Still, it is unknown why such a separation exists.
%
% the overall computational cost of finding a target. This justifies the design of two complementary processing pathways: first a classical image classifier, assuming that the gaze is on the object, and second a peripheral processing pathway
