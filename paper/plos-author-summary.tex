The visual search task consists in extracting a scarce and specific visual information (the ``target'') from a large and crowded visual display. In computer vision, this task is usually implemented by scanning the different possible target identities at all possible spatial positions, hence with strong computational load. The human visual system employs a different strategy, combining a foveated sensor with the capacity to rapidly move the center of fixation using saccades. Then, visual processing is separated in two specialized pathways, the ``where'' pathway mainly conveying information about target position in peripheral space, and the ``what'' pathway mainly conveying information about the category of the target. We take here  inspiration from those principles to provide ways toward implementing resource-efficient visual processing systems.  